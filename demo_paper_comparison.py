#!/usr/bin/env python3
"""
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨paper_comparisoné…ç½®è®­ç»ƒæ‰€æœ‰æ¨¡å‹å¹¶ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
"""

import sys
import argparse
from pathlib import Path

def main():
    parser = argparse.ArgumentParser(description='Paper Comparison Demo')
    parser.add_argument('--data', default='../data/Database_normalized.csv',
                       help='è®­ç»ƒæ•°æ®æ–‡ä»¶')
    parser.add_argument('--test-data', default=None,
                       help='æµ‹è¯•æ•°æ®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--project', default='PaperDemo',
                       help='é¡¹ç›®åç§°')
    parser.add_argument('--quick', action='store_true',
                       help='å¿«é€Ÿæ¨¡å¼ï¼ˆåªè®­ç»ƒ3ä¸ªæ¨¡å‹ï¼‰')
    
    args = parser.parse_args()
    
    print("="*60)
    print("       è®ºæ–‡çº§æ¨¡å‹å¯¹æ¯”æ¼”ç¤º")
    print("="*60)
    print()
    
    # æ„å»ºå‘½ä»¤
    cmd_parts = [
        'python', 'automl.py', 'train',
        'config=paper_comparison',
        f'data={args.data}',
        f'project={args.project}'
    ]
    
    if args.test_data:
        cmd_parts.append(f'test_data={args.test_data}')
    
    if args.quick:
        # å¿«é€Ÿæ¨¡å¼ï¼šåªè®­ç»ƒå‡ ä¸ªå…³é”®æ¨¡å‹
        cmd_parts.extend([
            'optimization.automl_models=[xgboost,catboost,lightgbm]',
            'training.n_folds=5'
        ])
        print("ğŸš€ å¿«é€Ÿæ¨¡å¼ï¼šåªè®­ç»ƒ XGBoost, CatBoost, LightGBM")
    else:
        print("ğŸ“Š å®Œæ•´æ¨¡å¼ï¼šè®­ç»ƒæ‰€æœ‰13ä¸ªæ¨¡å‹")
    
    # æ˜¾ç¤ºå‘½ä»¤
    print("\næ‰§è¡Œå‘½ä»¤:")
    print(" ".join(cmd_parts))
    print()
    
    # æ‰§è¡Œå‘½ä»¤
    import subprocess
    result = subprocess.run(cmd_parts, capture_output=False, text=True)
    
    if result.returncode == 0:
        print("\nâœ… è®­ç»ƒå®Œæˆï¼")
        
        # æŸ¥æ‰¾ç»“æœç›®å½•
        project_dir = Path(args.project)
        if project_dir.exists():
            # æ‰¾åˆ°æœ€æ–°çš„è®­ç»ƒç›®å½•
            train_dirs = sorted(project_dir.glob('train*'), key=lambda x: x.stat().st_mtime)
            if train_dirs:
                latest_dir = train_dirs[-1]
                print(f"\nğŸ“ ç»“æœç›®å½•: {latest_dir}")
                
                # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
                print("\nç”Ÿæˆå¯¹æ¯”è¡¨æ ¼...")
                try:
                    sys.path.append('.')
                    from utils.comparison_table import ComparisonTableGenerator
                    
                    generator = ComparisonTableGenerator(str(latest_dir))
                    exported = generator.export_all_formats()
                    
                    # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹
                    print("\n" + "="*60)
                    print("æœ€ä½³æ¨¡å‹æ€»ç»“")
                    print("="*60)
                    best_models = generator.get_best_models()
                    for target, info in best_models.items():
                        print(f"\n{target}:")
                        print(f"  æœ€ä½³æ¨¡å‹: {info['algorithm']}")
                        print(f"  RÂ²: {info['r2']}")
                        print(f"  RMSE: {info['rmse']}")
                    
                    print("\nğŸ“Š ç”Ÿæˆçš„è¡¨æ ¼æ–‡ä»¶:")
                    for fmt, path in exported.items():
                        print(f"  - {fmt.upper()}: {path}")
                    
                except Exception as e:
                    print(f"âš ï¸ ç”Ÿæˆè¡¨æ ¼æ—¶å‡ºé”™: {e}")
    else:
        print("\nâŒ è®­ç»ƒå¤±è´¥")
        sys.exit(1)


if __name__ == '__main__':
    main()