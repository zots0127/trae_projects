#!/usr/bin/env python3
"""
äº¤äº’å¼CLIç®¡ç†ç•Œé¢
æä¾›ç”¨æˆ·å‹å¥½çš„é¡¹ç›®ç®¡ç†å’Œæ‰¹é‡é¢„æµ‹ç•Œé¢
"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import json
import pandas as pd
from datetime import datetime
import subprocess
import shlex

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# å°è¯•å¯¼å…¥richï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸºç¡€ç‰ˆæœ¬
try:
    from rich.console import Console
    from rich.table import Table
    from rich.panel import Panel
    from rich.prompt import Prompt, Confirm, IntPrompt
    from rich.progress import Progress, SpinnerColumn, TextColumn
    from rich.layout import Layout
    from rich.text import Text
    from rich import print as rprint
    from rich.columns import Columns
    from rich.tree import Tree
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False
    print("âš ï¸ Rich library not installed. Using basic interface.")
    print("Install with: pip install rich")

from utils.project_manager import ProjectManager
from utils.project_predictor import ProjectPredictor


class InteractiveCLI:
    """äº¤äº’å¼CLIç®¡ç†ç•Œé¢"""
    
    def __init__(self):
        """åˆå§‹åŒ–CLI"""
        self.console = Console() if RICH_AVAILABLE else None
        self.manager = ProjectManager()
        self.current_project = None
        self.current_predictor = None
        
    def clear_screen(self):
        """æ¸…å±"""
        os.system('cls' if os.name == 'nt' else 'clear')
    
    def print_header(self):
        """æ‰“å°æ ‡é¢˜"""
        self.clear_screen()
        if RICH_AVAILABLE:
            header = Panel.fit(
                "[bold cyan]AutoML Interactive Manager[/bold cyan]\n"
                "[dim]Project Management & Batch Prediction[/dim]",
                border_style="cyan"
            )
            self.console.print(header)
        else:
            print("=" * 60)
            print("         AutoML Interactive Manager")
            print("    Project Management & Batch Prediction")
            print("=" * 60)
    
    def main_menu(self) -> str:
        """ä¸»èœå•"""
        self.print_header()
        
        if self.current_project:
            if RICH_AVAILABLE:
                self.console.print(f"\nğŸ“¦ Current Project: [bold green]{self.current_project}[/bold green]\n")
            else:
                print(f"\nğŸ“¦ Current Project: {self.current_project}\n")
        
        menu_items = [
            "1. ğŸ“‹ List Projects",
            "2. ğŸ“‚ Select Project",
            "3. ğŸ“Š Project Information",
            "4. ğŸš€ Batch Prediction",
            "5. ğŸ¯ Train New Models",
            "6. ğŸ“ˆ View Comparison Table",
            "7. ğŸ’¾ Export Project",
            "8. ğŸ“Š Generate Comparison Table",
            "9. ğŸ“ Generate Report",
            "10. ğŸ§¹ Clean Project",
            "0. ğŸšª Exit"
        ]
        
        if RICH_AVAILABLE:
            menu = Panel("\n".join(menu_items), title="Main Menu", border_style="blue")
            self.console.print(menu)
            choice = Prompt.ask("\n[bold]Your choice[/bold]", choices=["0","1","2","3","4","5","6","7","8","9","10"])
        else:
            print("\nMain Menu:")
            for item in menu_items:
                print(f"  {item}")
            choice = input("\nYour choice: ")
        
        return choice
    
    def list_projects(self):
        """åˆ—å‡ºæ‰€æœ‰é¡¹ç›®"""
        self.print_header()
        projects = self.manager.list_projects()
        
        if not projects:
            if RICH_AVAILABLE:
                self.console.print("[yellow]No projects found.[/yellow]")
            else:
                print("No projects found.")
            return
        
        if RICH_AVAILABLE:
            table = Table(title="Available Projects", show_header=True, header_style="bold magenta")
            table.add_column("Project", style="cyan", no_wrap=True)
            table.add_column("Created", style="green")
            table.add_column("Models", justify="right", style="yellow")
            table.add_column("Runs", justify="right", style="yellow")
            table.add_column("Path", style="dim")
            
            for p in projects:
                table.add_row(
                    p['name'],
                    p['created'][:19] if p['created'] != 'Unknown' else 'Unknown',
                    str(p['models']),
                    str(p['runs']),
                    str(p['path'])
                )
            
            self.console.print(table)
        else:
            print("\nAvailable Projects:")
            print("-" * 60)
            for i, p in enumerate(projects, 1):
                print(f"{i}. {p['name']}")
                print(f"   Created: {p['created']}")
                print(f"   Models: {p['models']}, Runs: {p['runs']}")
                print(f"   Path: {p['path']}")
                print()
    
    def select_project(self):
        """é€‰æ‹©é¡¹ç›®"""
        self.print_header()
        projects = self.manager.list_projects()
        
        if not projects:
            if RICH_AVAILABLE:
                self.console.print("[yellow]No projects found.[/yellow]")
            else:
                print("No projects found.")
            return
        
        # æ˜¾ç¤ºé¡¹ç›®åˆ—è¡¨
        if RICH_AVAILABLE:
            self.console.print("[bold]Available Projects:[/bold]\n")
            for i, p in enumerate(projects, 1):
                self.console.print(f"  {i}. [cyan]{p['name']}[/cyan] ({p['models']} models)")
            
            choice = IntPrompt.ask("\n[bold]Select project number[/bold]", 
                                  default=1, 
                                  show_default=True)
        else:
            print("\nAvailable Projects:\n")
            for i, p in enumerate(projects, 1):
                print(f"  {i}. {p['name']} ({p['models']} models)")
            
            choice = input("\nSelect project number (default=1): ")
            choice = int(choice) if choice else 1
        
        if 1 <= choice <= len(projects):
            self.current_project = projects[choice - 1]['name']
            self.current_predictor = None  # Reset predictor
            
            if RICH_AVAILABLE:
                self.console.print(f"\nâœ… Selected project: [bold green]{self.current_project}[/bold green]")
            else:
                print(f"\nâœ… Selected project: {self.current_project}")
        else:
            if RICH_AVAILABLE:
                self.console.print("[red]Invalid selection.[/red]")
            else:
                print("Invalid selection.")
    
    def show_project_info(self):
        """æ˜¾ç¤ºé¡¹ç›®ä¿¡æ¯"""
        if not self.current_project:
            if RICH_AVAILABLE:
                self.console.print("[yellow]Please select a project first.[/yellow]")
            else:
                print("Please select a project first.")
            return
        
        self.print_header()
        
        try:
            # è·å–é¡¹ç›®ä¿¡æ¯
            info = self.manager.get_project_info(self.current_project)
            
            # åŠ è½½é¢„æµ‹å™¨è·å–æ¨¡å‹è¯¦æƒ…
            if not self.current_predictor:
                self.current_predictor = ProjectPredictor(self.current_project, verbose=False)
            
            if RICH_AVAILABLE:
                # åŸºæœ¬ä¿¡æ¯
                info_panel = Panel(
                    f"[bold]Name:[/bold] {info['project_name']}\n"
                    f"[bold]Created:[/bold] {info.get('created_at', 'Unknown')[:19]}\n"
                    f"[bold]Path:[/bold] {info['path']}\n"
                    f"[bold]Models:[/bold] {len(self.current_predictor.models)}\n"
                    f"[bold]Targets:[/bold] {', '.join(info.get('targets', []))}",
                    title="Project Information",
                    border_style="green"
                )
                self.console.print(info_panel)
                
                # æ¨¡å‹åˆ—è¡¨
                if self.current_predictor.models:
                    table = Table(title="Trained Models", show_header=True, header_style="bold cyan")
                    table.add_column("Model", style="cyan")
                    table.add_column("Target", style="green")
                    table.add_column("RÂ² (meanÂ±std)", justify="right", style="yellow")
                    table.add_column("RMSE (meanÂ±std)", justify="right", style="yellow")
                    table.add_column("MAE (meanÂ±std)", justify="right", style="yellow")
                    
                    for key, info in self.current_predictor.models.items():
                        perf = info.get('performance', {})
                        
                        # æ ¼å¼åŒ– RÂ² with std
                        r2_str = 'N/A'
                        if isinstance(perf.get('r2'), float):
                            r2_mean = perf.get('r2')
                            r2_std = perf.get('r2_std', 0)
                            if r2_std > 0:
                                r2_str = f"{r2_mean:.4f}Â±{r2_std:.4f}"
                            else:
                                r2_str = f"{r2_mean:.4f}"
                        
                        # æ ¼å¼åŒ– RMSE with std
                        rmse_str = 'N/A'
                        if isinstance(perf.get('rmse'), float):
                            rmse_mean = perf.get('rmse')
                            rmse_std = perf.get('rmse_std', 0)
                            if rmse_std > 0:
                                rmse_str = f"{rmse_mean:.2f}Â±{rmse_std:.2f}"
                            else:
                                rmse_str = f"{rmse_mean:.2f}"
                        
                        # æ ¼å¼åŒ– MAE with std
                        mae_str = 'N/A'
                        if isinstance(perf.get('mae'), float):
                            mae_mean = perf.get('mae')
                            mae_std = perf.get('mae_std', 0)
                            if mae_std > 0:
                                mae_str = f"{mae_mean:.2f}Â±{mae_std:.2f}"
                            else:
                                mae_str = f"{mae_mean:.2f}"
                        
                        table.add_row(
                            info['type'],
                            info.get('original_target', info['target']),
                            r2_str,
                            rmse_str,
                            mae_str
                        )
                    
                    self.console.print(table)
                
                # æœ€ä½³æ¨¡å‹
                if info.get('best_models'):
                    best_panel = Panel(
                        "\n".join([
                            f"[bold]{target}:[/bold] {best['model']} (RÂ²={best['r2']:.4f})"
                            for target, best in info['best_models'].items()
                        ]),
                        title="Best Models",
                        border_style="yellow"
                    )
                    self.console.print(best_panel)
            else:
                # åŸºç¡€æ–‡æœ¬è¾“å‡º
                print("\nProject Information:")
                print("-" * 60)
                print(f"Name: {info['project_name']}")
                print(f"Created: {info.get('created_at', 'Unknown')}")
                print(f"Path: {info['path']}")
                print(f"Models: {len(self.current_predictor.models)}")
                print(f"Targets: {', '.join(info.get('targets', []))}")
                
                print("\nTrained Models:")
                for key, model_info in self.current_predictor.models.items():
                    perf = model_info.get('performance', {})
                    print(f"  - {model_info['type']} on {model_info.get('original_target', model_info['target'])}")
                    if perf:
                        print(f"    RÂ²={perf.get('r2', 'N/A'):.4f}, RMSE={perf.get('rmse', 'N/A'):.4f}")
                
                if info.get('best_models'):
                    print("\nBest Models:")
                    for target, best in info['best_models'].items():
                        print(f"  {target}: {best['model']} (RÂ²={best['r2']:.4f})")
                        
        except Exception as e:
            if RICH_AVAILABLE:
                self.console.print(f"[red]Error: {e}[/red]")
            else:
                print(f"Error: {e}")
    
    def batch_prediction(self):
        """æ‰¹é‡é¢„æµ‹äº¤äº’æµç¨‹"""
        if not self.current_project:
            if RICH_AVAILABLE:
                self.console.print("[yellow]Please select a project first.[/yellow]")
            else:
                print("Please select a project first.")
            return
        
        self.print_header()
        
        # è·å–æ•°æ®æ–‡ä»¶
        if RICH_AVAILABLE:
            self.console.print("[bold]Batch Prediction Setup[/bold]\n")
            data_file = Prompt.ask("Enter data file path", default="data/Database_normalized.csv")
        else:
            print("\nBatch Prediction Setup\n")
            data_file = input("Enter data file path (default=data/Database_normalized.csv): ")
            data_file = data_file or "data/Database_normalized.csv"
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(data_file).exists():
            if RICH_AVAILABLE:
                self.console.print(f"[red]File not found: {data_file}[/red]")
            else:
                print(f"File not found: {data_file}")
            return
        
        # é€‰æ‹©é¢„æµ‹æ¨¡å¼
        modes = {
            "1": ("best", "Use best models only"),
            "2": ("all", "Use all models"),
            "3": ("ensemble", "Ensemble prediction")
        }
        
        if RICH_AVAILABLE:
            self.console.print("\n[bold]Prediction Mode:[/bold]")
            for key, (mode, desc) in modes.items():
                self.console.print(f"  {key}. {desc}")
            
            mode_choice = Prompt.ask("Select mode", choices=["1", "2", "3"], default="1")
        else:
            print("\nPrediction Mode:")
            for key, (mode, desc) in modes.items():
                print(f"  {key}. {desc}")
            
            mode_choice = input("Select mode (1/2/3, default=1): ")
            mode_choice = mode_choice or "1"
        
        mode = modes[mode_choice][0]
        
        # å¦‚æœæ˜¯ensembleï¼Œè¯¢é—®æ–¹æ³•
        method = "mean"
        if mode == "ensemble":
            methods = {"1": "mean", "2": "median", "3": "weighted"}
            if RICH_AVAILABLE:
                self.console.print("\n[bold]Ensemble Method:[/bold]")
                for key, m in methods.items():
                    self.console.print(f"  {key}. {m}")
                method_choice = Prompt.ask("Select method", choices=["1", "2", "3"], default="1")
            else:
                print("\nEnsemble Method:")
                for key, m in methods.items():
                    print(f"  {key}. {m}")
                method_choice = input("Select method (1/2/3, default=1): ")
                method_choice = method_choice or "1"
            method = methods[method_choice]
        
        # è¾“å‡ºæ–‡ä»¶
        default_output = f"{self.current_project}/predictions_{mode}.csv"
        
        if RICH_AVAILABLE:
            output_file = Prompt.ask("Output file", default=default_output)
        else:
            output_file = input(f"Output file (default={default_output}): ")
            output_file = output_file or default_output
        
        # ç¡®è®¤æ‰§è¡Œ
        if RICH_AVAILABLE:
            self.console.print("\n[bold]Summary:[/bold]")
            self.console.print(f"  Project: {self.current_project}")
            self.console.print(f"  Data: {data_file}")
            self.console.print(f"  Mode: {mode}")
            if mode == "ensemble":
                self.console.print(f"  Method: {method}")
            self.console.print(f"  Output: {output_file}")
            
            if not Confirm.ask("\nProceed with prediction?", default=True):
                return
        else:
            print("\nSummary:")
            print(f"  Project: {self.current_project}")
            print(f"  Data: {data_file}")
            print(f"  Mode: {mode}")
            if mode == "ensemble":
                print(f"  Method: {method}")
            print(f"  Output: {output_file}")
            
            proceed = input("\nProceed with prediction? (y/n, default=y): ")
            if proceed.lower() == 'n':
                return
        
        # æ‰§è¡Œé¢„æµ‹
        try:
            if RICH_AVAILABLE:
                with self.console.status("[bold green]Running prediction...", spinner="dots"):
                    self._run_prediction(data_file, mode, output_file, method)
            else:
                print("\nRunning prediction...")
                self._run_prediction(data_file, mode, output_file, method)
            
            if RICH_AVAILABLE:
                self.console.print(f"\nâœ… [green]Prediction completed![/green]")
                self.console.print(f"   Output saved to: {output_file}")
            else:
                print(f"\nâœ… Prediction completed!")
                print(f"   Output saved to: {output_file}")
                
        except Exception as e:
            if RICH_AVAILABLE:
                self.console.print(f"[red]Prediction failed: {e}[/red]")
            else:
                print(f"Prediction failed: {e}")
    
    def _run_prediction(self, data_file: str, mode: str, output_file: str, method: str = "mean"):
        """æ‰§è¡Œé¢„æµ‹"""
        if not self.current_predictor:
            self.current_predictor = ProjectPredictor(self.current_project, verbose=False)
        
        if mode == "best":
            self.current_predictor.predict_best_models(
                data_path=data_file,
                output_path=output_file
            )
        elif mode == "all":
            output_dir = Path(output_file).parent / f"batch_{Path(output_file).stem}"
            self.current_predictor.predict_all_models(
                data_path=data_file,
                output_dir=str(output_dir)
            )
        elif mode == "ensemble":
            self.current_predictor.predict_ensemble(
                data_path=data_file,
                output_path=output_file,
                method=method
            )
    
    def view_comparison_table(self):
        """æŸ¥çœ‹å¯¹æ¯”è¡¨"""
        if not self.current_project:
            if RICH_AVAILABLE:
                self.console.print("[yellow]Please select a project first.[/yellow]")
            else:
                print("Please select a project first.")
            return
        
        self.print_header()
        
        # æŸ¥æ‰¾å¯¹æ¯”è¡¨æ–‡ä»¶
        project_path = Path(self.current_project)
        table_files = list(project_path.glob("comparison_table_*.csv"))
        
        if not table_files:
            # è‹¥æ²¡æœ‰ç°æˆè¡¨æ ¼ï¼Œæç¤ºæ˜¯å¦ç«‹å³ç”Ÿæˆ
            if RICH_AVAILABLE:
                self.console.print("[yellow]No comparison tables found. Let's generate one now.[/yellow]")
                if not Confirm.ask("Generate comparison table now?", default=True):
                    return
            else:
                print("No comparison tables found.")
                proceed = input("Generate comparison table now? (y/n, default=y): ")
                if proceed.lower() == 'n':
                    return

            try:
                self.generate_comparison_table(auto_after_view=True)
            except Exception as e:
                if RICH_AVAILABLE:
                    self.console.print(f"[red]Failed to generate table: {e}[/red]")
                else:
                    print(f"Failed to generate table: {e}")
                return

            # é‡æ–°åŠ è½½
            table_files = list(project_path.glob("comparison_table_*.csv"))
            if not table_files:
                if RICH_AVAILABLE:
                    self.console.print("[yellow]Still no tables found after generation.[/yellow]")
                else:
                    print("Still no tables found after generation.")
                return
        
        # è¯»å–æœ€æ–°çš„è¡¨æ ¼
        latest_table = sorted(table_files)[-1]
        df = pd.read_csv(latest_table)
        
        if RICH_AVAILABLE:
            self.console.print(f"[bold]Comparison Table:[/bold] {latest_table.name}\n")
            
            # è½¬æ¢ä¸ºrichè¡¨æ ¼
            table = Table(show_header=True, header_style="bold magenta", title=f"Model Comparison Table")
            
            # æ™ºèƒ½æ·»åŠ åˆ— - è¯†åˆ«meanå’Œstdåˆ—
            col_groups = {}
            for col in df.columns:
                if '_mean' in col:
                    base_name = col.replace('_mean', '')
                    if base_name not in col_groups:
                        col_groups[base_name] = {}
                    col_groups[base_name]['mean'] = col
                elif '_std' in col:
                    base_name = col.replace('_std', '')
                    if base_name not in col_groups:
                        col_groups[base_name] = {}
                    col_groups[base_name]['std'] = col
            
            # æ·»åŠ åˆ—å¤´
            for col in df.columns:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æˆå¯¹çš„mean/stdåˆ—
                is_metric_col = False
                for base_name, group in col_groups.items():
                    if col == group.get('mean'):
                        # è¿™æ˜¯meanåˆ—ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„std
                        if 'std' in group:
                            table.add_column(f"{base_name} (meanÂ±std)", justify="right", style="yellow")
                        else:
                            table.add_column(col, justify="right", style="yellow")
                        is_metric_col = True
                        break
                    elif col == group.get('std'):
                        # stdåˆ—ä¼šå’Œmeanåˆ—åˆå¹¶ï¼Œè·³è¿‡
                        is_metric_col = True
                        break
                
                if not is_metric_col:
                    # æ™®é€šåˆ—
                    if 'R2' in col or 'RMSE' in col or 'MAE' in col:
                        table.add_column(col, justify="right", style="yellow")
                    else:
                        table.add_column(col, style="cyan")
            
            # æ·»åŠ è¡Œ
            for _, row in df.iterrows():
                row_data = []
                processed_cols = set()
                
                for col in df.columns:
                    if col in processed_cols:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆå¹¶meanå’Œstd
                    merged = False
                    for base_name, group in col_groups.items():
                        if col == group.get('mean') and 'std' in group:
                            mean_val = row[col]
                            std_val = row[group['std']]
                            if isinstance(mean_val, float) and isinstance(std_val, float):
                                row_data.append(f"{mean_val:.4f}Â±{std_val:.4f}")
                            else:
                                row_data.append(str(mean_val))
                            processed_cols.add(col)
                            processed_cols.add(group['std'])
                            merged = True
                            break
                    
                    if not merged and col not in processed_cols:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯å•ç‹¬çš„stdåˆ—ï¼ˆåº”è¯¥å·²è¢«å¤„ç†ï¼‰
                        is_std_col = any(col == g.get('std') for g in col_groups.values())
                        if not is_std_col:
                            val = row[col]
                            if isinstance(val, float):
                                row_data.append(f"{val:.4f}")
                            else:
                                row_data.append(str(val))
                            processed_cols.add(col)
                
                table.add_row(*row_data)
            
            self.console.print(table)
        else:
            print(f"\nComparison Table: {latest_table.name}\n")
            print(df.to_string(index=False))

    def generate_comparison_table(self, auto_after_view: bool = False):
        """ç”Ÿæˆæ¨¡å‹å¯¹æ¯”è¡¨ï¼ˆæ•´åˆåˆ°Managerï¼‰"""
        if not self.current_project:
            if RICH_AVAILABLE:
                self.console.print("[yellow]Please select a project first.[/yellow]")
            else:
                print("Please select a project first.")
            return

        self.print_header()

        output_dir = None
        formats = ['markdown', 'html', 'latex', 'csv']

        if not auto_after_view:
            if RICH_AVAILABLE:
                self.console.print("[bold]Generate Comparison Table[/bold]\n")
                output_dir = Prompt.ask("Output directory (default=project root)", default="")
                fmt_choices = ["markdown","html","latex","csv"]
                fmt_input = Prompt.ask("Formats (comma separated)", default=",".join(fmt_choices))
                formats = [f.strip() for f in fmt_input.split(',') if f.strip()]
            else:
                print("Generate Comparison Table\n")
                output_dir = input("Output directory (default=project root): ")
                fmt_input = input("Formats (comma separated, default=markdown,html,latex,csv): ")
                if fmt_input:
                    formats = [f.strip() for f in fmt_input.split(',') if f.strip()]

        try:
            exported = self.manager.generate_comparison_table(
                self.current_project,
                output_dir=output_dir or None,
                formats=formats
            )

            if RICH_AVAILABLE:
                self.console.print("\nâœ… [green]Comparison table generated.[/green]")
                for k, v in exported.items():
                    self.console.print(f"   - {k}: {v}")
                # ç”Ÿæˆååœ¨å‘½ä»¤è¡Œå†…æ¸²æŸ“å±•ç¤ºä¸€æ¬¡
                try:
                    self.console.print("\n[bold]Preview (rendered in console):[/bold]\n")
                    self.view_comparison_table()
                except Exception:
                    pass
            else:
                print("\nâœ… Comparison table generated.")
                for k, v in exported.items():
                    print(f"   - {k}: {v}")
                # ç”Ÿæˆååœ¨å‘½ä»¤è¡Œå†…æ¸²æŸ“å±•ç¤ºä¸€æ¬¡
                try:
                    print("\nPreview (rendered in console):\n")
                    self.view_comparison_table()
                except Exception:
                    pass
        except Exception as e:
            if RICH_AVAILABLE:
                self.console.print(f"[red]Generation failed: {e}[/red]")
            else:
                print(f"Generation failed: {e}")
    
    def export_project(self):
        """å¯¼å‡ºé¡¹ç›®"""
        if not self.current_project:
            if RICH_AVAILABLE:
                self.console.print("[yellow]Please select a project first.[/yellow]")
            else:
                print("Please select a project first.")
            return
        
        self.print_header()
        
        # é€‰æ‹©æ ¼å¼
        if RICH_AVAILABLE:
            format_choice = Prompt.ask("Export format", choices=["zip", "tar"], default="zip")
            default_output = f"{self.current_project}.{format_choice}"
            output_file = Prompt.ask("Output file", default=default_output)
        else:
            format_choice = input("Export format (zip/tar, default=zip): ")
            format_choice = format_choice or "zip"
            default_output = f"{self.current_project}.{format_choice}"
            output_file = input(f"Output file (default={default_output}): ")
            output_file = output_file or default_output
        
        try:
            self.manager.export_project(self.current_project, output_file, format_choice)
            
            if RICH_AVAILABLE:
                self.console.print(f"âœ… [green]Project exported to: {output_file}[/green]")
            else:
                print(f"âœ… Project exported to: {output_file}")
                
        except Exception as e:
            if RICH_AVAILABLE:
                self.console.print(f"[red]Export failed: {e}[/red]")
            else:
                print(f"Export failed: {e}")
    
    def generate_report(self):
        """ç”ŸæˆæŠ¥å‘Š"""
        if not self.current_project:
            if RICH_AVAILABLE:
                self.console.print("[yellow]Please select a project first.[/yellow]")
            else:
                print("Please select a project first.")
            return
        
        self.print_header()
        
        default_output = f"{self.current_project}/report.md"
        
        if RICH_AVAILABLE:
            output_file = Prompt.ask("Report file", default=default_output)
        else:
            output_file = input(f"Report file (default={default_output}): ")
            output_file = output_file or default_output
        
        try:
            self.manager.generate_project_report(self.current_project, output_file)
            
            if RICH_AVAILABLE:
                self.console.print(f"âœ… [green]Report generated: {output_file}[/green]")
            else:
                print(f"âœ… Report generated: {output_file}")
                
        except Exception as e:
            if RICH_AVAILABLE:
                self.console.print(f"[red]Report generation failed: {e}[/red]")
            else:
                print(f"Report generation failed: {e}")
    
    def train_models(self):
        """è®­ç»ƒæ–°æ¨¡å‹"""
        self.print_header()
        
        if RICH_AVAILABLE:
            self.console.print("[bold]Train New Models[/bold]\n")
            self.console.print("This will launch the training pipeline.\n")
            
            # é…ç½®ç¼–å·é€‰æ‹© - å¢åŠ æ¨¡å‹ä¿¡æ¯æ˜¾ç¤ºå’Œè‡ªå®šä¹‰é€‰é¡¹
            configs = ["xgboost_quick", "xgboost_standard", "automl_quick", "automl", "paper_comparison", "custom"]
            
            # æ¯ä¸ªé…ç½®æ”¯æŒçš„æ¨¡å‹
            config_models = {
                "xgboost_quick": ["XGBoost"],
                "xgboost_standard": ["XGBoost"],
                "automl_quick": ["XGBoost", "LightGBM", "CatBoost", "Random Forest"],
                "automl": ["XGBoost", "LightGBM", "CatBoost", "Random Forest", "Gradient Boosting", 
                          "Extra Trees", "AdaBoost", "Ridge", "Lasso", "Elastic Net", "SVR", "KNN", "Decision Tree"],
                "paper_comparison": ["XGBoost", "LightGBM", "CatBoost", "Random Forest", "Gradient Boosting", 
                                   "Extra Trees", "AdaBoost", "Ridge", "Lasso", "Elastic Net", "SVR", "KNN", "Decision Tree"],
                "custom": []  # Will be filled by user selection
            }
            
            self.console.print("[bold]Select configuration:[/bold]")
            for i, c in enumerate(configs, 1):
                if c == "custom":
                    self.console.print(f"  {i}. [cyan]{c}[/cyan] [dim](Select individual models)[/dim]")
                else:
                    models = config_models.get(c, [])
                    models_str = f"[dim]({len(models)} models: {', '.join(models[:3])}{', ...' if len(models) > 3 else ''})[/dim]"
                    self.console.print(f"  {i}. [cyan]{c}[/cyan] {models_str}")
            
            # æ˜¾ç¤ºè¯¦ç»†çš„æ¨¡å‹åˆ—è¡¨
            self.console.print("\n[bold]Supported models by configuration:[/bold]")
            table = Table(show_header=True, header_style="bold magenta")
            table.add_column("Config", style="cyan")
            table.add_column("Models", style="yellow", overflow="fold")
            table.add_column("Count", justify="center", style="green")
            
            for config in configs:
                models = config_models.get(config, [])
                # æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹ï¼Œä¸æˆªæ–­
                models_display = ", ".join(models)
                table.add_row(config, models_display, str(len(models)))
            
            self.console.print(table)
            
            # é¢å¤–æ˜¾ç¤ºæ‰€æœ‰13ä¸ªå¯ç”¨æ¨¡å‹çš„å®Œæ•´åˆ—è¡¨
            self.console.print("\n[bold]All Available Models (13 total):[/bold]")
            all_models = [
                ("XGBoost", "ğŸš€ Tree-based ensemble"),
                ("LightGBM", "ğŸš€ Tree-based ensemble"),
                ("CatBoost", "ğŸš€ Tree-based ensemble"),
                ("Random Forest", "ğŸŒ² Tree-based ensemble"),
                ("Gradient Boosting", "ğŸŒ² Tree-based ensemble"),
                ("Extra Trees", "ğŸŒ² Tree-based ensemble"),
                ("AdaBoost", "ğŸŒ² Tree-based ensemble"),
                ("Decision Tree", "ğŸŒ³ Single tree"),
                ("Ridge", "ğŸ“Š Linear model"),
                ("Lasso", "ğŸ“Š Linear model"),
                ("Elastic Net", "ğŸ“Š Linear model"),
                ("SVR", "ğŸ”® Support Vector"),
                ("KNN", "ğŸ“ Instance-based")
            ]
            
            # åˆ›å»ºä¸€ä¸ªè¡¨æ ¼æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹
            model_table = Table(show_header=True, header_style="bold cyan", box=None)
            model_table.add_column("#", justify="right", style="dim")
            model_table.add_column("Model", style="yellow")
            model_table.add_column("Type", style="dim")
            
            for i, (model, model_type) in enumerate(all_models, 1):
                model_table.add_row(str(i), model, model_type)
            
            self.console.print(model_table)
            self.console.print()
            
            config_idx = IntPrompt.ask("Configuration number", default=1, show_default=True)
            config_idx = 1 if not isinstance(config_idx, int) else max(1, min(config_idx, len(configs)))
            config = configs[config_idx - 1]
            
            # å¦‚æœé€‰æ‹©äº†customï¼Œè®©ç”¨æˆ·é€‰æ‹©å…·ä½“çš„æ¨¡å‹
            custom_models_list = None
            custom_models_selected = False  # æ ‡è®°æ˜¯å¦é€‰æ‹©äº†è‡ªå®šä¹‰æ¨¡å‹
            if config == "custom":
                self.console.print("\n[bold]Select models to train:[/bold]")
                self.console.print("[dim]Enter model numbers separated by commas (e.g., 1,2,3 or 1-5,7,9)[/dim]\n")
                
                # æ˜¾ç¤ºæ‰€æœ‰å¯é€‰æ¨¡å‹ï¼ˆæ³¨æ„é¡ºåºè¦ä¸æ ‡å‡†æ¨¡å¼ä¸€è‡´ï¼‰
                all_model_names = ["adaboost", "catboost", "decision_tree", "elastic_net", 
                                  "extra_trees", "gradient_boosting", "knn", "lasso", 
                                  "lightgbm", "random_forest", "ridge", "svr", "xgboost"]
                all_model_display = ["AdaBoost", "CatBoost", "Decision Tree", "Elastic Net", 
                                    "Extra Trees", "Gradient Boosting", "KNN", "Lasso", 
                                    "LightGBM", "Random Forest", "Ridge", "SVR", "XGBoost"]
                
                # åˆ›å»ºæ¨¡å‹é€‰æ‹©è¡¨æ ¼
                for i, (name, display) in enumerate(zip(all_model_names, all_model_display), 1):
                    emoji = "ğŸš€" if name in ["xgboost", "lightgbm", "catboost"] else \
                            "ğŸŒ²" if name in ["random_forest", "gradient_boosting", "extra_trees", "adaboost"] else \
                            "ğŸŒ³" if name == "decision_tree" else \
                            "ğŸ“Š" if name in ["ridge", "lasso", "elastic_net"] else \
                            "ğŸ”®" if name == "svr" else "ğŸ“"
                    self.console.print(f"  {i:2}. {emoji} [yellow]{display:20}[/yellow] [dim]({name})[/dim]")
                
                # è·å–ç”¨æˆ·é€‰æ‹©
                selection = Prompt.ask("\nSelect models", default="1,2,3,4")
                
                # è§£æé€‰æ‹©ï¼ˆæ”¯æŒèŒƒå›´å¦‚1-5å’Œå•ä¸ªæ•°å­—ï¼‰
                selected_indices = []
                for part in selection.split(','):
                    part = part.strip()
                    if '-' in part:
                        try:
                            start, end = map(int, part.split('-'))
                            selected_indices.extend(range(start, end + 1))
                        except:
                            pass
                    else:
                        try:
                            selected_indices.append(int(part))
                        except:
                            pass
                
                # è½¬æ¢ä¸ºæ¨¡å‹åç§°
                selected_models = [all_model_names[i-1] for i in selected_indices 
                                 if 1 <= i <= len(all_model_names)]
                
                if not selected_models:
                    selected_models = ["xgboost"]  # é»˜è®¤è‡³å°‘é€‰æ‹©XGBoost
                
                self.console.print(f"\n[green]Selected {len(selected_models)} models:[/green] {', '.join([all_model_display[all_model_names.index(m)] for m in selected_models])}\n")
                
                # è®¾ç½®ä¸ºautomlæ¨¡å¼ä½†åªä½¿ç”¨é€‰å®šçš„æ¨¡å‹
                config = "automl"
                # ä¿å­˜é€‰å®šçš„æ¨¡å‹åˆ—è¡¨ï¼Œç¨ååœ¨æ„å»ºå‘½ä»¤æ—¶å¤„ç†
                custom_models_list = selected_models
                custom_models_selected = True  # æ ‡è®°å·²é€‰æ‹©è‡ªå®šä¹‰æ¨¡å‹
            
            # è·å–æ•°æ®æ–‡ä»¶
            data_file = Prompt.ask("Data file", default="data/Database_normalized.csv")
            
            # è·å–é¡¹ç›®åç§°
            project = Prompt.ask("Project name", default="project")
            
            # äº¤äº’å¼é™„åŠ é€‰é¡¹ï¼ˆç¼–å·é€‰æ‹©ï¼‰
            extra_args = []
            if custom_models_list:
                # ä½¿ç”¨æ–°çš„modelså‚æ•°æ ¼å¼ï¼ˆé€—å·åˆ†éš”ï¼‰
                models_str = ','.join(custom_models_list)
                extra_args.append(f"models={models_str}")

            # ç‰¹å¾ç±»å‹
            feat_options = ["auto", "combined", "morgan", "descriptors", "tabular"]
            self.console.print("\n[bold]Feature type:[/bold]")
            for i, fopt in enumerate(feat_options, 1):
                self.console.print(f"  {i}. {fopt}")
            feat_idx = IntPrompt.ask("Feature type number", default=2)
            feat_idx = 2 if not isinstance(feat_idx, int) else max(1, min(feat_idx, len(feat_options)))
            feat_choice = feat_options[feat_idx - 1]
            extra_args.append(f"feature.feature_type={feat_choice}")

            # åˆ†å­ç‰¹å¾å‚æ•°
            if feat_choice in ["combined", "morgan", "descriptors"]:
                bits_choices = [512, 1024, 2048]
                self.console.print("Morgan bits:")
                for i, b in enumerate(bits_choices, 1):
                    self.console.print(f"  {i}. {b}")
                b_idx = IntPrompt.ask("Bits number", default=2)
                b_idx = 2 if not isinstance(b_idx, int) else max(1, min(b_idx, len(bits_choices)))
                extra_args.append(f"feature.morgan_bits={bits_choices[b_idx-1]}")

                rad_choices = [2, 3]
                self.console.print("Morgan radius:")
                for i, r in enumerate(rad_choices, 1):
                    self.console.print(f"  {i}. {r}")
                r_idx = IntPrompt.ask("Radius number", default=1)
                r_idx = 1 if not isinstance(r_idx, int) else max(1, min(r_idx, len(rad_choices)))
                extra_args.append(f"feature.morgan_radius={rad_choices[r_idx-1]}")

                comb_options = ["mean", "sum", "concat"]
                self.console.print("Combination method:")
                for i, copt in enumerate(comb_options, 1):
                    self.console.print(f"  {i}. {copt}")
                c_idx = IntPrompt.ask("Combination number", default=1)
                c_idx = 1 if not isinstance(c_idx, int) else max(1, min(c_idx, len(comb_options)))
                extra_args.append(f"feature.combination_method={comb_options[c_idx-1]}")

                # SMILES åˆ—ï¼ˆå¯é€‰ï¼‰
                set_smiles_idx = IntPrompt.ask("Custom SMILES columns? [1=Yes, 2=No]", default=2)
                if int(set_smiles_idx) == 1:
                    smiles_cols = Prompt.ask("Enter SMILES columns (comma)", default="L1,L2,L3")
                    cols = [c.strip() for c in smiles_cols.split(',') if c.strip()]
                    extra_args.append(f"data.smiles_columns={json.dumps(cols)}")

            # ç›®æ ‡åˆ—
            self.console.print("\n[bold]Targets:[/bold]")
            self.console.print("  1. Auto detect")
            self.console.print("  2. Single preset (choose)")
            self.console.print("  3. Custom (comma)")
            tgt_mode = IntPrompt.ask("Target mode", default=1)
            if int(tgt_mode) == 2:
                presets = ["Max_wavelength(nm)", "PLQY", "tau(s*10^-6)"]
                for i, p in enumerate(presets, 1):
                    self.console.print(f"    {i}. {p}")
                p_idx = IntPrompt.ask("Preset number", default=2)
                p_idx = 2 if not isinstance(p_idx, int) else max(1, min(p_idx, len(presets)))
                extra_args.append(f"target={presets[p_idx-1]}")
            elif int(tgt_mode) == 3:
                tgt_input = Prompt.ask("Enter targets (comma)", default="")
                if tgt_input.strip():
                    extra_args.append(f"target={tgt_input.strip()}")

            # æŠ˜æ•°ä¸æ—©åœ
            self.console.print("\n[bold]Cross validation folds:[/bold]")
            folds_options = [3, 5, 10]
            for i, f in enumerate(folds_options, 1):
                self.console.print(f"  {i}. {f}")
            f_idx = IntPrompt.ask("Folds number", default=3)
            f_idx = 3 if not isinstance(f_idx, int) else max(1, min(f_idx, len(folds_options)))
            extra_args.append(f"n_folds={folds_options[f_idx-1]}")

            es_idx = IntPrompt.ask("Enable early stopping? [1=Yes, 2=No]", default=2)
            es_enabled = int(es_idx) == 1
            extra_args.append(f"training.early_stopping={'true' if es_enabled else 'false'}")
            if es_enabled:
                rounds_options = [10, 50, 100]
                for i, rr in enumerate(rounds_options, 1):
                    self.console.print(f"  {i}. rounds={rr}")
                rr_idx = IntPrompt.ask("Early stopping rounds", default=2)
                rr_idx = 2 if not isinstance(rr_idx, int) else max(1, min(rr_idx, len(rounds_options)))
                extra_args.append(f"training.early_stopping_rounds={rounds_options[rr_idx-1]}")

            # å¹¶è¡Œ/NUMA
            self.console.print("\n[bold]Parallelism:[/bold]")
            par_choices = [1, 2, 4, 8, 16, 32]
            for i, pc in enumerate(par_choices, 1):
                self.console.print(f"  {i}. parallel={pc}")
            p_idx = IntPrompt.ask("Parallel number", default=1)
            p_idx = 1 if not isinstance(p_idx, int) else max(1, min(p_idx, len(par_choices)))
            extra_args.append(f"parallel={par_choices[p_idx-1]}")

            core_choices = [1, 2, 4, 8]
            for i, cc in enumerate(core_choices, 1):
                self.console.print(f"  {i}. cores/task={cc}")
            c_idx = IntPrompt.ask("Cores per task", default=1)
            c_idx = 1 if not isinstance(c_idx, int) else max(1, min(c_idx, len(core_choices)))
            extra_args.append(f"cores={core_choices[c_idx-1]}")

            numa_idx = IntPrompt.ask("Enable NUMA optimization? [1=Yes, 2=No]", default=2)
            extra_args.append(f"numa={'true' if int(numa_idx)==1 else 'false'}")
            bind_idx = IntPrompt.ask("Bind CPU affinity? [1=Yes, 2=No]", default=2)
            extra_args.append(f"bind_cpu={'true' if int(bind_idx)==1 else 'false'}")

            # æµ‹è¯•é›†ï¼ˆå¯é€‰ï¼‰
            test_idx = IntPrompt.ask("Provide test dataset for evaluation? [1=Yes, 2=No]", default=2)
            if int(test_idx) == 1:
                test_file = Prompt.ask("Test data file", default="data/test.csv")
                extra_args.append(f"data.test_data_path={test_file}")

            # é€šç”¨ä¿å­˜/æŠ¥å‘Šé€‰é¡¹
            self.console.print("\n[bold]Output options:[/bold]")
            save_fold_idx = IntPrompt.ask("Save fold models? [1=Yes, 2=No]", default=2)
            save_fold = int(save_fold_idx) == 1
            extra_args.append(f"training.save_fold_models={'true' if save_fold else 'false'}")

            save_importance_idx = IntPrompt.ask("Save feature importance? [1=Yes, 2=No]", default=1)
            save_importance = int(save_importance_idx) == 1
            extra_args.append(f"training.save_feature_importance={'true' if save_importance else 'false'}")

            gen_report_idx = IntPrompt.ask("Generate analysis report? [1=Yes, 2=No]", default=1)
            gen_report = int(gen_report_idx) == 1
            extra_args.append(f"logging.generate_report={'true' if gen_report else 'false'}")

            # AutoMLç›¸å…³é€‰é¡¹ï¼ˆä»…å½“é€‰æ‹©automlé…ç½®æ—¶æ˜¾ç¤ºï¼‰
            if config.startswith("automl"):
                # åªæœ‰åœ¨æ²¡æœ‰é€‰æ‹©è‡ªå®šä¹‰æ¨¡å‹æ—¶æ‰è¯¢é—®æ˜¯å¦ä½¿ç”¨æ‰€æœ‰æ¨¡å‹
                if not custom_models_selected:
                    use_all_idx = IntPrompt.ask("AutoML use ALL supported models? [1=Yes, 2=No]", default=1)
                    use_all_models = int(use_all_idx) == 1
                    if use_all_models:
                        extra_args.append("--all")
                
                # AutoML trials / folds / metric (è¿™äº›é€‰é¡¹å¯¹è‡ªå®šä¹‰æ¨¡å‹ä¹Ÿé€‚ç”¨)
                trials_choices = [20, 50, 100]
                for i, t in enumerate(trials_choices, 1):
                    self.console.print(f"  {i}. trials/model={t}")
                self.console.print(f"  {len(trials_choices)+1}. custom")
                t_idx = IntPrompt.ask("Automl trials per model (choose or custom)", default=2)
                custom_trials = None
                if isinstance(t_idx, int) and t_idx == len(trials_choices)+1:
                    # Custom input
                    try:
                        custom_trials = int(Prompt.ask("Enter custom trials (positive integer)", default="50"))
                    except Exception:
                        custom_trials = 50
                    if custom_trials <= 0:
                        custom_trials = 50
                if custom_trials is not None:
                    extra_args.append(f"optimization.automl_trials_per_model={custom_trials}")
                else:
                    t_idx = 2 if not isinstance(t_idx, int) else max(1, min(t_idx, len(trials_choices)))
                    extra_args.append(f"optimization.automl_trials_per_model={trials_choices[t_idx-1]}")

                optfold_choices = [3, 5, 10]
                for i, of in enumerate(optfold_choices, 1):
                    self.console.print(f"  {i}. optimization folds={of}")
                of_idx = IntPrompt.ask("Optimization folds", default=2)
                of_idx = 2 if not isinstance(of_idx, int) else max(1, min(of_idx, len(optfold_choices)))
                extra_args.append(f"optimization.n_folds={optfold_choices[of_idx-1]}")

                metric_opts = ["rmse", "mae", "r2", "mape"]
                for i, m in enumerate(metric_opts, 1):
                    self.console.print(f"  {i}. metric={m}")
                m_idx = IntPrompt.ask("Optimization metric", default=1)
                m_idx = 1 if not isinstance(m_idx, int) else max(1, min(m_idx, len(metric_opts)))
                metric_ch = metric_opts[m_idx-1]
                extra_args.append(f"optimization.metric={metric_ch}")
                direction = "minimize" if metric_ch in ["rmse","mae","mape"] else "maximize"
                extra_args.append(f"optimization.direction={direction}")

                gen_comp_idx = IntPrompt.ask("Generate comparison table after training? [1=Yes, 2=No]", default=1)
                gen_comp = int(gen_comp_idx) == 1
                extra_args.append(f"comparison.enable={'true' if gen_comp else 'false'}")
                if gen_comp:
                    fmt_options = ["markdown", "html", "latex", "csv"]
                    self.console.print("\n[bold]Comparison formats:[/bold]")
                    for i, fopt in enumerate(fmt_options, 1):
                        self.console.print(f"  {i}. {fopt}")
                    fmt_nums = Prompt.ask("Select formats (numbers, comma), default=1,2,4", default="1,2,4")
                    try:
                        indices = [int(x.strip()) for x in fmt_nums.split(',') if x.strip().isdigit()]
                        indices = [i for i in indices if 1 <= i <= len(fmt_options)]
                        fmts = [fmt_options[i-1] for i in indices] if indices else ["markdown","html","csv"]
                    except Exception:
                        fmts = ["markdown","html","csv"]
                    extra_args.append(f"comparison.formats={json.dumps(fmts)}")

            # æ„å»ºå‘½ä»¤
            base = [
                "python", "automl.py", "train",
                f"config={config}",
                f"data={data_file}",
                f"project={project}"
            ]
            
            # æ˜¾ç¤ºå‘½ä»¤ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            cmd_display = " ".join(base + extra_args)
            self.console.print(f"\n[bold]Command:[/bold] {cmd_display}")
            
            if Confirm.ask("Execute training?", default=True):
                # ä½¿ç”¨subprocessæ‰§è¡Œï¼Œæ›´å¥½åœ°å¤„ç†å‚æ•°
                try:
                    result = subprocess.run(base + extra_args, check=False)
                    if result.returncode == 0:
                        self.current_project = project
                        self.console.print(f"\nâœ… Training completed. Project: [bold green]{project}[/bold green]")
                    else:
                        self.console.print(f"\nâš ï¸ Training exited with code {result.returncode}")
                except Exception as e:
                    self.console.print(f"\nâŒ Training failed: {e}")
        else:
            print("Train New Models\n")
            print("This will launch the training pipeline.\n")
            
            # æ¯ä¸ªé…ç½®æ”¯æŒçš„æ¨¡å‹
            config_models = {
                "xgboost_quick": ["XGBoost"],
                "xgboost_standard": ["XGBoost"],
                "automl_quick": ["XGBoost", "LightGBM", "CatBoost", "Random Forest"],
                "automl": ["XGBoost", "LightGBM", "CatBoost", "Random Forest", "Gradient Boosting", 
                          "Extra Trees", "AdaBoost", "Ridge", "Lasso", "Elastic Net", "SVR", "KNN", "Decision Tree"],
                "paper_comparison": ["XGBoost", "LightGBM", "CatBoost", "Random Forest", "Gradient Boosting", 
                                   "Extra Trees", "AdaBoost", "Ridge", "Lasso", "Elastic Net", "SVR", "KNN", "Decision Tree"],
                "custom": []  # Will be filled by user selection
            }
            
            print("Available configurations:")
            configs = ["xgboost_quick", "xgboost_standard", "automl_quick", "automl", "paper_comparison", "custom"]
            for i, c in enumerate(configs, 1):
                if c == "custom":
                    print(f"  {i}. {c} (Select individual models)")
                else:
                    models = config_models.get(c, [])
                    if len(models) <= 3:
                        models_str = f"({len(models)} models: {', '.join(models)})"
                    else:
                        models_str = f"({len(models)} models: {', '.join(models[:3])}, ...)"
                    print(f"  {i}. {c} {models_str}")
            
            print("\nSupported models by configuration:")
            print("-" * 80)
            for config in configs:
                models = config_models.get(config, [])
                print(f"{config:20} | Count: {len(models):2}")
                # æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹ï¼Œåˆ†è¡Œæ˜¾ç¤ºä»¥ä¾¿é˜…è¯»
                if len(models) <= 4:
                    print(f"{'':20} | {', '.join(models)}")
                else:
                    # æ¯è¡Œæ˜¾ç¤º4ä¸ªæ¨¡å‹
                    for i in range(0, len(models), 4):
                        chunk = models[i:i+4]
                        if i == 0:
                            print(f"{'':20} | {', '.join(chunk)}")
                        else:
                            print(f"{'':20} | {', '.join(chunk)}")
            print("-" * 80)
            
            print("\nAll Available Models (13 total):")
            print("-" * 80)
            all_models = ["XGBoost", "LightGBM", "CatBoost", "Random Forest", "Gradient Boosting", 
                         "Extra Trees", "AdaBoost", "Ridge", "Lasso", "Elastic Net", "SVR", "KNN", "Decision Tree"]
            
            # æ˜¾ç¤ºä¸ºç¼–å·åˆ—è¡¨ï¼Œæ¯è¡Œ3ä¸ª
            for i in range(0, len(all_models), 3):
                row_models = all_models[i:i+3]
                row_str = "  ".join([f"{j+i+1:2}. {model:20}" for j, model in enumerate(row_models)])
                print(row_str)
            print("-" * 80)
            
            config_idx = input("\nSelect configuration (1-6, default=1): ")
            config_idx = int(config_idx) if config_idx else 1
            config = configs[config_idx - 1] if 1 <= config_idx <= len(configs) else configs[0]
            
            # å¦‚æœé€‰æ‹©äº†customï¼Œè®©ç”¨æˆ·é€‰æ‹©å…·ä½“çš„æ¨¡å‹
            custom_models_list = None
            custom_models_selected = False  # æ ‡è®°æ˜¯å¦é€‰æ‹©äº†è‡ªå®šä¹‰æ¨¡å‹
            if config == "custom":
                print("\nSelect models to train:")
                print("Enter model numbers separated by commas (e.g., 1,2,3 or 1-5,7,9)\n")
                
                # æ˜¾ç¤ºæ‰€æœ‰å¯é€‰æ¨¡å‹ï¼ˆæ³¨æ„é¡ºåºè¦ä¸æ ‡å‡†æ¨¡å¼ä¸€è‡´ï¼‰
                all_model_names = ["adaboost", "catboost", "decision_tree", "elastic_net", 
                                  "extra_trees", "gradient_boosting", "knn", "lasso", 
                                  "lightgbm", "random_forest", "ridge", "svr", "xgboost"]
                all_model_display = ["AdaBoost", "CatBoost", "Decision Tree", "Elastic Net", 
                                    "Extra Trees", "Gradient Boosting", "KNN", "Lasso", 
                                    "LightGBM", "Random Forest", "Ridge", "SVR", "XGBoost"]
                
                # æ˜¾ç¤ºæ¨¡å‹åˆ—è¡¨
                for i, (name, display) in enumerate(zip(all_model_names, all_model_display), 1):
                    print(f"  {i:2}. {display:20} ({name})")
                
                # è·å–ç”¨æˆ·é€‰æ‹©
                selection = input("\nSelect models (default=1,2,3,4): ").strip() or "1,2,3,4"
                
                # è§£æé€‰æ‹©ï¼ˆæ”¯æŒèŒƒå›´å¦‚1-5å’Œå•ä¸ªæ•°å­—ï¼‰
                selected_indices = []
                for part in selection.split(','):
                    part = part.strip()
                    if '-' in part:
                        try:
                            start, end = map(int, part.split('-'))
                            selected_indices.extend(range(start, end + 1))
                        except:
                            pass
                    else:
                        try:
                            selected_indices.append(int(part))
                        except:
                            pass
                
                # è½¬æ¢ä¸ºæ¨¡å‹åç§°
                selected_models = [all_model_names[i-1] for i in selected_indices 
                                 if 1 <= i <= len(all_model_names)]
                
                if not selected_models:
                    selected_models = ["xgboost"]  # é»˜è®¤è‡³å°‘é€‰æ‹©XGBoost
                
                print(f"\nSelected {len(selected_models)} models: {', '.join([all_model_display[all_model_names.index(m)] for m in selected_models])}\n")
                
                # è®¾ç½®ä¸ºautomlæ¨¡å¼ä½†åªä½¿ç”¨é€‰å®šçš„æ¨¡å‹
                config = "automl"
                # ä¿å­˜é€‰å®šçš„æ¨¡å‹åˆ—è¡¨ï¼Œç¨ååœ¨æ„å»ºå‘½ä»¤æ—¶å¤„ç†
                custom_models_list = selected_models
                custom_models_selected = True  # æ ‡è®°å·²é€‰æ‹©è‡ªå®šä¹‰æ¨¡å‹
            
            data_file = input("Data file (default=data/Database_normalized.csv): ")
            data_file = data_file or "data/Database_normalized.csv"
            
            project = input(f"Project name (default=project): ")
            project = project or "project"
            
            # äº¤äº’å¼é™„åŠ é€‰é¡¹ï¼ˆåŸºç¡€ç»ˆç«¯ï¼Œç¼–å·é€‰æ‹©ï¼‰
            def pick_yn(prompt: str, default_yes: bool = True) -> bool:
                default_num = '1' if default_yes else '2'
                s = input(f"{prompt} [1=Yes, 2=No] (default={default_num}): ").strip()
                if not s:
                    return default_yes
                return s == '1'

            extra_args = []
            if custom_models_list:
                # ä½¿ç”¨æ–°çš„modelså‚æ•°æ ¼å¼ï¼ˆé€—å·åˆ†éš”ï¼‰
                models_str = ','.join(custom_models_list)
                extra_args.append(f"models={models_str}")

            # ç‰¹å¾ç±»å‹
            feat_options = ["auto", "combined", "morgan", "descriptors", "tabular"]
            print("\nFeature type:")
            for i, fopt in enumerate(feat_options, 1):
                print(f"  {i}. {fopt}")
            s = input("Feature type number (default=2): ").strip() or "2"
            try:
                idx = max(1, min(int(s), len(feat_options)))
            except Exception:
                idx = 2
            feat_choice = feat_options[idx-1]
            extra_args.append(f"feature.feature_type={feat_choice}")

            if feat_choice in ["combined", "morgan", "descriptors"]:
                bits_choices = [512, 1024, 2048]
                print("Morgan bits:")
                for i, b in enumerate(bits_choices, 1):
                    print(f"  {i}. {b}")
                s = input("Bits number (default=2): ").strip() or "2"
                try:
                    bi = max(1, min(int(s), len(bits_choices)))
                except Exception:
                    bi = 2
                extra_args.append(f"feature.morgan_bits={bits_choices[bi-1]}")

                rad_choices = [2, 3]
                print("Morgan radius:")
                for i, r in enumerate(rad_choices, 1):
                    print(f"  {i}. {r}")
                s = input("Radius number (default=1): ").strip() or "1"
                try:
                    ri = max(1, min(int(s), len(rad_choices)))
                except Exception:
                    ri = 1
                extra_args.append(f"feature.morgan_radius={rad_choices[ri-1]}")

                comb_options = ["mean", "sum", "concat"]
                print("Combination method:")
                for i, copt in enumerate(comb_options, 1):
                    print(f"  {i}. {copt}")
                s = input("Combination number (default=1): ").strip() or "1"
                try:
                    ci = max(1, min(int(s), len(comb_options)))
                except Exception:
                    ci = 1
                extra_args.append(f"feature.combination_method={comb_options[ci-1]}")

                # SMILES åˆ—
                set_smiles = pick_yn("Custom SMILES columns?", default_yes=False)
                if set_smiles:
                    smiles_cols = input("Enter SMILES columns (comma, default=L1,L2,L3): ").strip() or "L1,L2,L3"
                    cols = [c.strip() for c in smiles_cols.split(',') if c.strip()]
                    extra_args.append(f"data.smiles_columns={json.dumps(cols)}")

            # ç›®æ ‡åˆ—
            print("\nTargets:\n  1. Auto detect\n  2. Single preset (choose)\n  3. Custom (comma)")
            s = input("Target mode (default=1): ").strip() or "1"
            if s == '2':
                presets = ["Max_wavelength(nm)", "PLQY", "tau(s*10^-6)"]
                for i, p in enumerate(presets, 1):
                    print(f"  {i}. {p}")
                s2 = input("Preset number (default=2): ").strip() or "2"
                try:
                    pi = max(1, min(int(s2), len(presets)))
                except Exception:
                    pi = 2
                extra_args.append(f"target={presets[pi-1]}")
            elif s == '3':
                tgt_input = input("Enter targets (comma): ").strip()
                if tgt_input:
                    extra_args.append(f"target={tgt_input}")

            # æŠ˜æ•°ä¸æ—©åœ
            folds_options = [3, 5, 10]
            print("\nCross validation folds:")
            for i, f in enumerate(folds_options, 1):
                print(f"  {i}. {f}")
            s = input("Folds number (default=3): ").strip() or "3"
            try:
                fi = max(1, min(int(s), len(folds_options)))
            except Exception:
                fi = 3
            extra_args.append(f"n_folds={folds_options[fi-1]}")

            es_enabled = pick_yn("Enable early stopping?", default_yes=False)
            extra_args.append(f"training.early_stopping={'true' if es_enabled else 'false'}")
            if es_enabled:
                rounds_options = [10, 50, 100]
                print("Early stopping rounds:")
                for i, rr in enumerate(rounds_options, 1):
                    print(f"  {i}. rounds={rr}")
                s = input("Rounds number (default=2): ").strip() or "2"
                try:
                    ri = max(1, min(int(s), len(rounds_options)))
                except Exception:
                    ri = 2
                extra_args.append(f"training.early_stopping_rounds={rounds_options[ri-1]}")

            # å¹¶è¡Œ/NUMA
            par_choices = [1, 2, 4, 8, 16, 32]
            print("\nParallel:")
            for i, pc in enumerate(par_choices, 1):
                print(f"  {i}. parallel={pc}")
            s = input("Parallel number (default=1): ").strip() or "1"
            try:
                pi = max(1, min(int(s), len(par_choices)))
            except Exception:
                pi = 1
            extra_args.append(f"parallel={par_choices[pi-1]}")

            core_choices = [1, 2, 4, 8]
            for i, cc in enumerate(core_choices, 1):
                print(f"  {i}. cores/task={cc}")
            s = input("Cores per task (default=1): ").strip() or "1"
            try:
                ci = max(1, min(int(s), len(core_choices)))
            except Exception:
                ci = 1
            extra_args.append(f"cores={core_choices[ci-1]}")

            numa = pick_yn("Enable NUMA optimization?", default_yes=False)
            extra_args.append(f"numa={'true' if numa else 'false'}")
            bind = pick_yn("Bind CPU affinity?", default_yes=False)
            extra_args.append(f"bind_cpu={'true' if bind else 'false'}")

            # æµ‹è¯•é›†
            provide_test = pick_yn("Provide test dataset for evaluation?", default_yes=False)
            if provide_test:
                test_file = input("Test data file (default=data/test.csv): ").strip() or "data/test.csv"
                extra_args.append(f"data.test_data_path={test_file}")
            save_fold = pick_yn("Save fold models?", default_yes=False)
            extra_args.append(f"training.save_fold_models={'true' if save_fold else 'false'}")
            save_importance = pick_yn("Save feature importance?", default_yes=True)
            extra_args.append(f"training.save_feature_importance={'true' if save_importance else 'false'}")
            gen_report = pick_yn("Generate analysis report?", default_yes=True)
            extra_args.append(f"logging.generate_report={'true' if gen_report else 'false'}")

            if config.startswith("automl"):
                # åªæœ‰åœ¨æ²¡æœ‰é€‰æ‹©è‡ªå®šä¹‰æ¨¡å‹æ—¶æ‰è¯¢é—®æ˜¯å¦ä½¿ç”¨æ‰€æœ‰æ¨¡å‹
                if not custom_models_selected:
                    use_all_models = pick_yn("AutoML use ALL supported models?", default_yes=True)
                    if use_all_models:
                        extra_args.append("--all")
                
                # AutoML trials / folds / metric (è¿™äº›é€‰é¡¹å¯¹è‡ªå®šä¹‰æ¨¡å‹ä¹Ÿé€‚ç”¨)
                trials_choices = [20, 50, 100]
                print("Automl trials per model:")
                for i, t in enumerate(trials_choices, 1):
                    print(f"  {i}. {t}")
                print(f"  {len(trials_choices)+1}. custom")
                s = input("Trials number (choose index or custom, default=2): ").strip() or "2"
                custom_trials = None
                if s.isdigit() and int(s) == len(trials_choices)+1:
                    cs = input("Enter custom trials (positive integer, default=50): ").strip() or "50"
                    try:
                        custom_trials = int(cs)
                    except Exception:
                        custom_trials = 50
                    if custom_trials <= 0:
                        custom_trials = 50
                if custom_trials is not None:
                    extra_args.append(f"optimization.automl_trials_per_model={custom_trials}")
                else:
                    try:
                        ti = max(1, min(int(s), len(trials_choices)))
                    except Exception:
                        ti = 2
                    extra_args.append(f"optimization.automl_trials_per_model={trials_choices[ti-1]}")

                optfold_choices = [3, 5, 10]
                print("Optimization folds:")
                for i, of in enumerate(optfold_choices, 1):
                    print(f"  {i}. {of}")
                s = input("Opt folds number (default=2): ").strip() or "2"
                try:
                    ofi = max(1, min(int(s), len(optfold_choices)))
                except Exception:
                    ofi = 2
                extra_args.append(f"optimization.n_folds={optfold_choices[ofi-1]}")

                metric_opts = ["rmse", "mae", "r2", "mape"]
                print("Optimization metric:")
                for i, m in enumerate(metric_opts, 1):
                    print(f"  {i}. {m}")
                s = input("Metric number (default=1): ").strip() or "1"
                try:
                    mi = max(1, min(int(s), len(metric_opts)))
                except Exception:
                    mi = 1
                metric_ch = metric_opts[mi-1]
                extra_args.append(f"optimization.metric={metric_ch}")
                direction = "minimize" if metric_ch in ["rmse","mae","mape"] else "maximize"
                extra_args.append(f"optimization.direction={direction}")

                gen_comp = pick_yn("Generate comparison table after training?", default_yes=True)
                extra_args.append(f"comparison.enable={'true' if gen_comp else 'false'}")
                if gen_comp:
                    fmt_options = ["markdown", "html", "latex", "csv"]
                    print("\nComparison formats:")
                    for i, fopt in enumerate(fmt_options, 1):
                        print(f"  {i}. {fopt}")
                    fmt_nums = input("Select formats (numbers, comma, default=1,2,4): ").strip() or "1,2,4"
                    try:
                        indices = [int(x.strip()) for x in fmt_nums.split(',') if x.strip().isdigit()]
                        indices = [i for i in indices if 1 <= i <= len(fmt_options)]
                        fmts = [fmt_options[i-1] for i in indices] if indices else ["markdown","html","csv"]
                    except Exception:
                        fmts = ["markdown","html","csv"]
                    extra_args.append(f"comparison.formats={json.dumps(fmts)}")

            base = [
                "python", "automl.py", "train",
                f"config={config}",
                f"data={data_file}",
                f"project={project}"
            ]
            # æ˜¾ç¤ºå‘½ä»¤ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            cmd_display = " ".join(base + extra_args)
            print(f"\nCommand: {cmd_display}")
            
            proceed = input("Execute training? (y/n, default=y): ")
            if proceed.lower() != 'n':
                # ä½¿ç”¨subprocessæ‰§è¡Œï¼Œæ›´å¥½åœ°å¤„ç†å‚æ•°
                try:
                    result = subprocess.run(base + extra_args, check=False)
                    if result.returncode == 0:
                        self.current_project = project
                        print(f"\nâœ… Training completed. Project: {project}")
                    else:
                        print(f"\nâš ï¸ Training exited with code {result.returncode}")
                except Exception as e:
                    print(f"\nâŒ Training failed: {e}")
    
    def clean_project(self):
        """æ¸…ç†é¡¹ç›®"""
        if not self.current_project:
            if RICH_AVAILABLE:
                self.console.print("[yellow]Please select a project first.[/yellow]")
            else:
                print("Please select a project first.")
            return
        
        self.print_header()
        
        if RICH_AVAILABLE:
            self.console.print(f"[bold]Clean Project: {self.current_project}[/bold]\n")
            
            keep_models = Confirm.ask("Keep model files?", default=True)
            keep_results = Confirm.ask("Keep result files?", default=True)
            
            if Confirm.ask(f"\n[red]This will delete intermediate files. Continue?[/red]", default=False):
                try:
                    self.manager.clean_project(self.current_project, keep_models, keep_results)
                    self.console.print("âœ… [green]Project cleaned successfully.[/green]")
                except Exception as e:
                    self.console.print(f"[red]Clean failed: {e}[/red]")
        else:
            print(f"Clean Project: {self.current_project}\n")
            
            keep_models = input("Keep model files? (y/n, default=y): ")
            keep_models = keep_models.lower() != 'n'
            
            keep_results = input("Keep result files? (y/n, default=y): ")
            keep_results = keep_results.lower() != 'n'
            
            confirm = input("\nThis will delete intermediate files. Continue? (y/n): ")
            if confirm.lower() == 'y':
                try:
                    self.manager.clean_project(self.current_project, keep_models, keep_results)
                    print("âœ… Project cleaned successfully.")
                except Exception as e:
                    print(f"Clean failed: {e}")
    
    def run(self):
        """è¿è¡Œäº¤äº’å¼ç•Œé¢"""
        while True:
            choice = self.main_menu()
            
            if choice == "0":
                if RICH_AVAILABLE:
                    self.console.print("\n[bold cyan]Goodbye![/bold cyan] ğŸ‘‹")
                else:
                    print("\nGoodbye! ğŸ‘‹")
                break
            elif choice == "1":
                self.list_projects()
            elif choice == "2":
                self.select_project()
            elif choice == "3":
                self.show_project_info()
            elif choice == "4":
                self.batch_prediction()
            elif choice == "5":
                self.train_models()
            elif choice == "6":
                self.view_comparison_table()
            elif choice == "7":
                self.export_project()
            elif choice == "8":
                self.generate_comparison_table()
            elif choice == "9":
                self.generate_report()
            elif choice == "10":
                self.clean_project()
            
            if choice != "0":
                if RICH_AVAILABLE:
                    self.console.input("\n[dim]Press Enter to continue...[/dim]")
                else:
                    input("\nPress Enter to continue...")


def main():
    """ä¸»å‡½æ•°"""
    cli = InteractiveCLI()
    try:
        cli.run()
    except KeyboardInterrupt:
        if RICH_AVAILABLE:
            cli.console.print("\n\n[yellow]Interrupted by user.[/yellow]")
        else:
            print("\n\nInterrupted by user.")
        sys.exit(0)
    except Exception as e:
        if RICH_AVAILABLE:
            cli.console.print(f"\n[red]Error: {e}[/red]")
        else:
            print(f"\nError: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
