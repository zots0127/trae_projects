AutoML å®Œæ•´å‘½ä»¤å‚è€ƒæŒ‡å—
================================

æœ¬æ–‡æ¡£å®Œæ•´è®°å½•AutoMLç³»ç»Ÿçš„æ‰€æœ‰å‘½ä»¤ã€å‚æ•°å’ŒåŠŸèƒ½ï¼ŒæŒ‰ç…§ä»åŸºç¡€åˆ°é«˜çº§çš„é¡ºåºç»„ç»‡ã€‚

ç›®å½•
--------------------------------
1. [å¿«é€Ÿå…¥é—¨ï¼ˆåŸºç¡€åŠŸèƒ½ï¼‰](#å¿«é€Ÿå…¥é—¨åŸºç¡€åŠŸèƒ½)
2. [æ ¸å¿ƒå‘½ä»¤è¯¦è§£ï¼ˆä¸­çº§åŠŸèƒ½ï¼‰](#æ ¸å¿ƒå‘½ä»¤è¯¦è§£ä¸­çº§åŠŸèƒ½)
3. [é…ç½®æ¨¡æ¿ç³»ç»Ÿ](#é…ç½®æ¨¡æ¿ç³»ç»Ÿ)
4. [é«˜çº§åŠŸèƒ½](#é«˜çº§åŠŸèƒ½)
5. [å®Œæ•´å‚æ•°å‚è€ƒ](#å®Œæ•´å‚æ•°å‚è€ƒ)
6. [å®æˆ˜ç¤ºä¾‹](#å®æˆ˜ç¤ºä¾‹)

================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šå¿«é€Ÿå…¥é—¨ï¼ˆåŸºç¡€åŠŸèƒ½ï¼‰
================================

## ç¯å¢ƒå‡†å¤‡
```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å¦‚éœ€åˆ†å­ç‰¹å¾ï¼Œå®‰è£…RDKitï¼ˆæ¨ècondaï¼‰
conda install -c conda-forge rdkit
```

## æœ€ç®€å•çš„å‘½ä»¤

### 1. è®­ç»ƒæ¨¡å‹ï¼ˆæœ€åŸºç¡€ï¼‰
```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒXGBoost
python automl.py train data=data/Database_normalized.csv

# æŒ‡å®šæ¨¡å‹ç±»å‹
python automl.py train model=lightgbm data=data/Database_normalized.csv

# ä½¿ç”¨é¢„å®šä¹‰æ¨¡æ¿ï¼ˆå¿«é€Ÿè®­ç»ƒï¼‰
python automl.py train config=xgboost_quick
```

### 2. é¢„æµ‹ï¼ˆæœ€åŸºç¡€ï¼‰
```bash
# ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹
python automl.py predict model=models/best.joblib data=test.csv

# é¢„æµ‹å¹¶ä¿å­˜ç»“æœ
python automl.py predict model=models/best.joblib data=test.csv output=predictions.csv
```

### 3. åˆ†æç»“æœï¼ˆæœ€åŸºç¡€ï¼‰
```bash
# åˆ†ææœ€è¿‘ä¸€æ¬¡è®­ç»ƒ
python automl.py analyze dir=last format=html

# åˆ†ææŒ‡å®šç›®å½•
python automl.py analyze dir=runs/train/myproject
```

## åŸºç¡€å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹å€¼ |
|------|------|--------|
| data | è®­ç»ƒæ•°æ®è·¯å¾„ | data/train.csv |
| model | æ¨¡å‹ç±»å‹æˆ–è·¯å¾„ | xgboost, models/best.joblib |
| config | é…ç½®æ¨¡æ¿åç§° | xgboost_quick |
| output | è¾“å‡ºæ–‡ä»¶è·¯å¾„ | predictions.csv |
| dir | ç›®å½•è·¯å¾„ | runs/train/project1 |
| format | è¾“å‡ºæ ¼å¼ | html, text |

================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒå‘½ä»¤è¯¦è§£ï¼ˆä¸­çº§åŠŸèƒ½ï¼‰
================================

## 1. train - è®­ç»ƒå‘½ä»¤

### åŸºæœ¬ç”¨æ³•
```bash
python automl.py train [å‚æ•°]
```

### å¸¸ç”¨å‚æ•°ç»„åˆ
```bash
# æŒ‡å®šé¡¹ç›®åå’Œå®éªŒå
python automl.py train config=xgboost_quick project=myproj name=exp1

# æŒ‡å®šç›®æ ‡åˆ—
python automl.py train data=data.csv target=PLQY

# è®¾ç½®äº¤å‰éªŒè¯æŠ˜æ•°
python automl.py train config=xgboost_quick n_folds=10

# å¸¦æµ‹è¯•é›†è¯„ä¼°
python automl.py train config=xgboost_quick test_data=test.csv
```

### trainå‘½ä»¤å‚æ•°è¡¨

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|--------|------|
| data | è®­ç»ƒæ•°æ®è·¯å¾„ | å¿…éœ€ | data/train.csv |
| model | æ¨¡å‹ç±»å‹ | xgboost | lightgbm, catboost |
| config | é…ç½®æ¨¡æ¿ | - | xgboost_quick |
| project | é¡¹ç›®åç§° | default | my_experiment |
| name | å®éªŒåç§° | è‡ªåŠ¨ç”Ÿæˆ | exp_001 |
| target | ç›®æ ‡åˆ— | è‡ªåŠ¨æ£€æµ‹ | PLQY, Max_wavelength(nm) |
| n_folds | äº¤å‰éªŒè¯æŠ˜æ•° | 10 | 5, 10 |
| test_data | æµ‹è¯•é›†è·¯å¾„ | - | test.csv |
| feature | ç‰¹å¾ç±»å‹ | combined | morgan, descriptors |

## 2. predict - é¢„æµ‹å‘½ä»¤

### åŸºæœ¬ç”¨æ³•
```bash
python automl.py predict model=<æ¨¡å‹è·¯å¾„> data=<æ•°æ®> [å‚æ•°]
```

### é¢„æµ‹æ¨¡å¼

#### A. CSVæ–‡ä»¶é¢„æµ‹
```bash
# åˆ†å­æ•°æ®é¢„æµ‹ï¼ˆè‡ªåŠ¨è¯†åˆ«SMILESåˆ—ï¼‰
python automl.py predict model=models/best.joblib data=test.csv feature=combined

# è¡¨æ ¼æ•°æ®é¢„æµ‹
python automl.py predict model=models/tabular.joblib data=test.csv feature=tabular
```

#### B. ç›´æ¥è¾“å…¥é¢„æµ‹
```bash
# å•ä¸ªSMILESé¢„æµ‹
python automl.py predict model=models/best.joblib input='["CCO","c1ccccc1"]' feature=morgan

# å¤šé…ä½“é¢„æµ‹ï¼ˆL1,L2,L3ï¼‰
python automl.py predict model=models/best.joblib \
    input='[["CCO","c1ccccc1",null],["O","N",null]]' feature=combined

# æ•°å€¼æ•°ç»„é¢„æµ‹
python automl.py predict model=models/tabular.joblib \
    input='[[0.1,0.2,0.3],[0.5,0.6,0.7]]' feature=tabular
```

### predictå‘½ä»¤å‚æ•°è¡¨

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|--------|------|
| model | æ¨¡å‹æ–‡ä»¶è·¯å¾„ | å¿…éœ€ | models/best.joblib |
| data | æ•°æ®æ–‡ä»¶è·¯å¾„ | - | test.csv |
| input | ç›´æ¥è¾“å…¥æ•°æ® | - | '["CCO"]' |
| feature | ç‰¹å¾ç±»å‹ | auto | morgan, descriptors, combined, tabular |
| smiles_columns | SMILESåˆ—å | L1,L2,L3 | mol1,mol2,mol3 |
| morgan_bits | æŒ‡çº¹ä½æ•° | 1024 | 512, 2048 |
| morgan_radius | æŒ‡çº¹åŠå¾„ | 2 | 2, 3 |
| output | è¾“å‡ºæ–‡ä»¶ | predictions.csv | results.csv |

## 3. analyze - åˆ†æå‘½ä»¤

### åŸºæœ¬ç”¨æ³•
```bash
python automl.py analyze dir=<ç›®å½•> [å‚æ•°]
```

### åˆ†æé€‰é¡¹
```bash
# åˆ†ææœ€è¿‘è®­ç»ƒ
python automl.py analyze dir=last format=html

# æ–‡æœ¬æ ¼å¼è¾“å‡ºï¼ˆç»ˆç«¯æŸ¥çœ‹ï¼‰
python automl.py analyze dir=last format=text

# æ¯”è¾ƒå¤šä¸ªå®éªŒ
python automl.py analyze dir=runs/train1,runs/train2

# ç”Ÿæˆè®ºæ–‡å›¾è¡¨
python automl.py analyze dir=last export_for_paper=true
```

### analyzeå‘½ä»¤å‚æ•°è¡¨

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|--------|------|
| dir | å®éªŒç›®å½• | last | runs/train/exp1 |
| format | è¾“å‡ºæ ¼å¼ | html | text, json |
| export_for_paper | å¯¼å‡ºè®ºæ–‡å›¾è¡¨ | false | true |
| compare | æ¯”è¾ƒå¤šä¸ªå®éªŒ | false | true |

## 4. validate - éªŒè¯å‘½ä»¤

### åŸºæœ¬ç”¨æ³•
```bash
# éªŒè¯æ•°æ®æ–‡ä»¶ï¼ˆæ¨èï¼‰
python automl.py validate data=data/train.csv

# éªŒè¯é…ç½®æ–‡ä»¶
python automl.py validate config=configs/myconfig.yaml
```

### æ•°æ®éªŒè¯åŠŸèƒ½
éªŒè¯æ•°æ®æ–‡ä»¶æ—¶ä¼šæ£€æŸ¥ï¼š
- âœ… æ–‡ä»¶æ˜¯å¦å­˜åœ¨å’Œå¯è¯»
- âœ… æ•°æ®è¡Œæ•°å’Œåˆ—æ•°
- âœ… SMILESåˆ—ï¼ˆL1, L2, L3ï¼‰
- âœ… ç›®æ ‡åˆ—ï¼ˆMax_wavelength, PLQY, tauï¼‰
- âœ… æ•°æ®è´¨é‡ï¼ˆç¼ºå¤±å€¼ã€é‡å¤è¡Œï¼‰
- âœ… SMILESæ ¼å¼æœ‰æ•ˆæ€§ï¼ˆå¦‚æœRDKitå¯ç”¨ï¼‰

### ç¤ºä¾‹è¾“å‡º
```
ğŸ“Š éªŒè¯æ•°æ®æ–‡ä»¶: data/Database_normalized.csv
âœ… æ•°æ®åŠ è½½æˆåŠŸ
æ•°æ®ä¿¡æ¯:
è¡Œæ•°: 1667
åˆ—æ•°: 13
âœ… SMILESåˆ—: L1, L2, L3
âœ… ç›®æ ‡åˆ—: Max_wavelength(nm), PLQY, tau(s*10^-6)
ç¼ºå¤±å€¼æ€»æ•°: 2960
é‡å¤è¡Œæ•°: 0
âœ… SMILESæ ¼å¼æ£€æŸ¥é€šè¿‡
âœ… æ•°æ®éªŒè¯å®Œæˆ!
```

## 5. export - å¯¼å‡ºå‘½ä»¤

### åŸºæœ¬ç”¨æ³•
```bash
# å¯¼å‡ºä¸ºONNXæ ¼å¼
python automl.py export model=models/best.joblib format=onnx output=exports/model

# å¯¼å‡ºä¸ºPickleæ ¼å¼
python automl.py export model=models/best.joblib format=pickle output=exports/model
```

## 6. warmup - ç¼“å­˜é¢„çƒ­å‘½ä»¤

### åŸºæœ¬ç”¨æ³•
```bash
# é¢„è®¡ç®—ç‰¹å¾ç¼“å­˜
python automl.py warmup data=data/train.csv feature=combined

# æ¸…ç†ç¼“å­˜
python automl.py warmup clean=true
```

## 7. info - ä¿¡æ¯å‘½ä»¤

### åŸºæœ¬ç”¨æ³•
```bash
# æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
python automl.py info

# æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
python automl.py info models

# æ˜¾ç¤ºå¯ç”¨æ¨¡æ¿
python automl.py info templates
```

================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šé…ç½®æ¨¡æ¿ç³»ç»Ÿ
================================

## é¢„å®šä¹‰æ¨¡æ¿åˆ—è¡¨

ç³»ç»Ÿæä¾›20+é¢„å®šä¹‰é…ç½®æ¨¡æ¿ï¼Œè¦†ç›–ä»è°ƒè¯•åˆ°ç”Ÿäº§çš„å„ç§åœºæ™¯ï¼š

### å¿«é€Ÿè®­ç»ƒæ¨¡æ¿

| æ¨¡æ¿å | è¯´æ˜ | è®­ç»ƒæ—¶é—´ | é€‚ç”¨åœºæ™¯ |
|--------|------|----------|----------|
| debug | æœ€å°åŒ–è°ƒè¯•æ¨¡æ¿ | <1åˆ†é’Ÿ | ä»£ç æµ‹è¯• |
| xgboost_quick | XGBoostå¿«é€Ÿè®­ç»ƒ | ~5åˆ†é’Ÿ | å¿«é€ŸéªŒè¯ |
| lightgbm_quick | LightGBMå¿«é€Ÿè®­ç»ƒ | ~5åˆ†é’Ÿ | å¿«é€ŸéªŒè¯ |
| catboost_quick | CatBoostå¿«é€Ÿè®­ç»ƒ | ~5åˆ†é’Ÿ | å¿«é€ŸéªŒè¯ |

### æ ‡å‡†è®­ç»ƒæ¨¡æ¿

| æ¨¡æ¿å | è¯´æ˜ | è®­ç»ƒæ—¶é—´ | é€‚ç”¨åœºæ™¯ |
|--------|------|----------|----------|
| xgboost_full | XGBoostå®Œæ•´è®­ç»ƒ | ~30åˆ†é’Ÿ | ç”Ÿäº§ç¯å¢ƒ |
| lightgbm_full | LightGBMå®Œæ•´è®­ç»ƒ | ~30åˆ†é’Ÿ | ç”Ÿäº§ç¯å¢ƒ |
| lightgbm | LightGBMåŸºç¡€é…ç½® | ~15åˆ†é’Ÿ | æ ‡å‡†è®­ç»ƒ |

### ä¼˜åŒ–æ¨¡æ¿

| æ¨¡æ¿å | è¯´æ˜ | è®­ç»ƒæ—¶é—´ | é€‚ç”¨åœºæ™¯ |
|--------|------|----------|----------|
| xgboost_optuna | XGBoost+Optunaä¼˜åŒ– | 1-2å°æ—¶ | è¶…å‚æ•°æœç´¢ |
| quick_optimize | å¿«é€Ÿä¼˜åŒ–ï¼ˆ20æ¬¡è¯•éªŒï¼‰ | ~30åˆ†é’Ÿ | å¿«é€Ÿè°ƒä¼˜ |
| automl | å¤šæ¨¡å‹è‡ªåŠ¨é€‰æ‹© | 2-4å°æ—¶ | è‡ªåŠ¨åŒ–ML |

### ç»å…¸ç®—æ³•æ¨¡æ¿

| æ¨¡æ¿å | è¯´æ˜ | æ¨¡å‹ç±»å‹ |
|--------|------|----------|
| random_forest | éšæœºæ£®æ—å›å½’ | é›†æˆå­¦ä¹  |
| gradient_boosting | æ¢¯åº¦æå‡å›å½’ | é›†æˆå­¦ä¹  |
| adaboost | AdaBoostå›å½’ | é›†æˆå­¦ä¹  |
| extra_trees | Extra Treeså›å½’ | é›†æˆå­¦ä¹  |
| svr_rbf | æ”¯æŒå‘é‡å›å½’ï¼ˆRBFæ ¸ï¼‰ | SVM |
| knn | Kè¿‘é‚»å›å½’ | åŸºäºå®ä¾‹ |
| decision_tree | å†³ç­–æ ‘å›å½’ | æ ‘æ¨¡å‹ |
| ridge | Ridgeå›å½’ï¼ˆL2æ­£åˆ™ï¼‰ | çº¿æ€§æ¨¡å‹ |
| lasso | Lassoå›å½’ï¼ˆL1æ­£åˆ™ï¼‰ | çº¿æ€§æ¨¡å‹ |
| elastic_net | ElasticNetå›å½’ | çº¿æ€§æ¨¡å‹ |

## ä½¿ç”¨æ¨¡æ¿ç¤ºä¾‹

```bash
# è°ƒè¯•æ¨¡å¼ï¼ˆæœ€å¿«ï¼‰
python automl.py train config=debug

# å¿«é€Ÿè®­ç»ƒ
python automl.py train config=xgboost_quick

# æ ‡å‡†è®­ç»ƒ
python automl.py train config=xgboost_full

# å¸¦ä¼˜åŒ–çš„è®­ç»ƒ
python automl.py train config=xgboost_optuna

# AutoMLï¼ˆæµ‹è¯•æ‰€æœ‰æ¨¡å‹ï¼‰
python automl.py train config=automl

# ä½¿ç”¨æ¨¡æ¿å¹¶è¦†ç›–å‚æ•°
python automl.py train config=random_forest \
    model.hyperparameters.n_estimators=500
```

================================
# ç¬¬å››éƒ¨åˆ†ï¼šé«˜çº§åŠŸèƒ½
================================

## 1. è¶…å‚æ•°ä¼˜åŒ–ï¼ˆOptunaï¼‰

### åŸºç¡€ä¼˜åŒ–
```bash
# å¯ç”¨ä¼˜åŒ–ï¼Œ100æ¬¡è¯•éªŒ
python automl.py train model=xgboost optimization=true n_trials=100

# ä½¿ç”¨é¢„å®šä¹‰ä¼˜åŒ–æ¨¡æ¿
python automl.py train config=xgboost_optuna
```

### é«˜çº§ä¼˜åŒ–é…ç½®
```bash
python automl.py train model=xgboost \
    optimization.enable=true \
    optimization.n_trials=200 \
    optimization.n_folds=5 \
    optimization.metric=r2 \
    optimization.direction=maximize \
    optimization.timeout=3600
```

### ä¼˜åŒ–å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | å¯é€‰å€¼ |
|------|------|--------|--------|
| optimization.enable | å¯ç”¨ä¼˜åŒ– | false | true/false |
| optimization.n_trials | è¯•éªŒæ¬¡æ•° | 100 | ä»»æ„æ­£æ•´æ•° |
| optimization.n_folds | ä¼˜åŒ–æ—¶æŠ˜æ•° | 5 | 2-10 |
| optimization.metric | ä¼˜åŒ–æŒ‡æ ‡ | rmse | rmse, mae, r2, mape |
| optimization.direction | ä¼˜åŒ–æ–¹å‘ | minimize | minimize/maximize |
| optimization.timeout | è¶…æ—¶ï¼ˆç§’ï¼‰ | None | ä»»æ„æ­£æ•´æ•° |

## 2. AutoML - è‡ªåŠ¨æ¨¡å‹é€‰æ‹©

### åŸºç¡€AutoML
```bash
# ä½¿ç”¨AutoMLæ¨¡æ¿
python automl.py train config=automl

# è‡ªå®šä¹‰AutoMLé…ç½®
python automl.py train \
    optimization.automl=true \
    optimization.automl_models='["xgboost","lightgbm","catboost"]' \
    optimization.automl_trials_per_model=50
```

### å®Œæ•´AutoMLï¼ˆæ‰€æœ‰13ä¸ªæ¨¡å‹ï¼‰
```bash
python automl.py train config=automl \
    data=data/Database_normalized.csv \
    test_data=test.csv \
    optimization.automl_models='["xgboost","lightgbm","catboost","random_forest","gradient_boosting","adaboost","extra_trees","svr","knn","decision_tree","ridge","lasso","elastic_net"]' \
    optimization.automl_trials_per_model=50 \
    optimization.n_folds=10
```

## 3. NUMAä¼˜åŒ–å’Œå¹¶è¡Œè®­ç»ƒ

### åŸºç¡€å¹¶è¡Œ
```bash
# å¯ç”¨NUMAä¼˜åŒ–ï¼Œ2ä¸ªå¹¶è¡Œä»»åŠ¡ï¼Œæ¯ä¸ª2æ ¸å¿ƒ
python automl.py train config=automl \
    numa=true parallel=2 cores=2
```

### å¤§è§„æ¨¡å¹¶è¡Œ
```bash
# 256æ ¸æœåŠ¡å™¨é…ç½®
python automl.py train config=automl \
    numa=true \
    parallel=32 \
    cores=8 \
    bind_cpu=true \
    project=large_scale
```

### NUMAå‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|--------|------|
| numa | å¯ç”¨NUMAä¼˜åŒ– | false | true |
| parallel | å¹¶è¡Œä»»åŠ¡æ•° | 1 | 8, 16, 32 |
| cores | æ¯ä»»åŠ¡æ ¸å¿ƒæ•° | 1 | 4, 8 |
| bind_cpu | CPUäº²å’Œæ€§ç»‘å®š | false | true |

## 4. ç‰¹å¾å·¥ç¨‹é…ç½®

### åˆ†å­ç‰¹å¾é…ç½®
```bash
# MorganæŒ‡çº¹ï¼ˆ1024ä½ï¼ŒåŠå¾„2ï¼‰
python automl.py train data=data.csv \
    feature.feature_type=morgan \
    feature.morgan_bits=1024 \
    feature.morgan_radius=2

# åˆ†å­æè¿°ç¬¦
python automl.py train data=data.csv \
    feature.feature_type=descriptors

# ç»„åˆç‰¹å¾ï¼ˆæŒ‡çº¹+æè¿°ç¬¦ï¼‰
python automl.py train data=data.csv \
    feature.feature_type=combined \
    feature.combination_method=mean
```

### å¤šé…ä½“ç»„åˆæ–¹æ³•
```bash
# å¹³å‡å€¼ç»„åˆ
feature.combination_method=mean

# æ±‚å’Œç»„åˆ
feature.combination_method=sum  

# æ‹¼æ¥ç»„åˆ
feature.combination_method=concat
```

## 5. æ•°æ®å¤„ç†é…ç½®

### æ•°æ®åˆ†å‰²
```bash
python automl.py train data=data.csv \
    data.train_ratio=0.7 \
    data.val_ratio=0.2 \
    data.test_ratio=0.1
```

### ç›®æ ‡åˆ—é…ç½®
```bash
# å•ç›®æ ‡
python automl.py train data=data.csv target=PLQY

# å¤šç›®æ ‡ï¼ˆè‡ªåŠ¨åˆ†åˆ«è®­ç»ƒï¼‰
python automl.py train data=data.csv \
    target='Max_wavelength(nm),PLQY,tau(s*10^-6)'
```

### SMILESåˆ—é…ç½®
```bash
python automl.py train data=data.csv \
    data.smiles_columns='mol1,mol2,mol3'
```

================================
# ç¬¬äº”éƒ¨åˆ†ï¼šå®Œæ•´å‚æ•°å‚è€ƒ
================================

## æ•°æ®å‚æ•°ï¼ˆdata.*ï¼‰

| å‚æ•° | è¯´æ˜ | ç±»å‹ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|------|--------|------|
| data | æ•°æ®æ–‡ä»¶è·¯å¾„ | str | å¿…éœ€ | data/train.csv |
| data.data_path | åŒdata | str | - | data/train.csv |
| data.test_data_path | æµ‹è¯•é›†è·¯å¾„ | str | None | data/test.csv |
| data.smiles_columns | SMILESåˆ—å | list | [L1,L2,L3] | mol1,mol2,mol3 |
| data.target_columns | ç›®æ ‡åˆ—å | list | è‡ªåŠ¨æ£€æµ‹ | PLQY,wavelength |
| data.train_ratio | è®­ç»ƒé›†æ¯”ä¾‹ | float | 0.8 | 0.7 |
| data.val_ratio | éªŒè¯é›†æ¯”ä¾‹ | float | 0.2 | 0.2 |
| data.test_ratio | æµ‹è¯•é›†æ¯”ä¾‹ | float | 0.0 | 0.1 |
| data.random_seed | éšæœºç§å­ | int | 42 | 123 |

## ç‰¹å¾å‚æ•°ï¼ˆfeature.*ï¼‰

| å‚æ•° | è¯´æ˜ | ç±»å‹ | é»˜è®¤å€¼ | å¯é€‰å€¼ |
|------|------|------|--------|---------|
| feature | ç‰¹å¾ç±»å‹ | str | combined | morgan/descriptors/combined/tabular/auto |
| feature.feature_type | åŒfeature | str | combined | åŒä¸Š |
| feature.morgan_bits | MorganæŒ‡çº¹ä½æ•° | int | 1024 | 512/1024/2048 |
| feature.morgan_radius | MorganæŒ‡çº¹åŠå¾„ | int | 2 | 2/3 |
| feature.combination_method | å¤šé…ä½“ç»„åˆæ–¹æ³• | str | mean | mean/sum/concat |
| feature.use_cache | ä½¿ç”¨ç‰¹å¾ç¼“å­˜ | bool | true | true/false |
| feature.cache_dir | ç¼“å­˜ç›®å½• | str | feature_cache | ä»»æ„è·¯å¾„ |

## æ¨¡å‹å‚æ•°ï¼ˆmodel.*ï¼‰

| å‚æ•° | è¯´æ˜ | ç±»å‹ | é»˜è®¤å€¼ | å¯é€‰å€¼ |
|------|------|------|--------|---------|
| model | æ¨¡å‹ç±»å‹ | str | xgboost | 13ç§æ¨¡å‹ |
| model.model_type | åŒmodel | str | xgboost | åŒä¸Š |
| model.hyperparameters.* | æ¨¡å‹è¶…å‚æ•° | dict | æ¨¡å‹ç›¸å…³ | è§å„æ¨¡å‹æ–‡æ¡£ |

### æ”¯æŒçš„13ç§æ¨¡å‹
- **æ¢¯åº¦æå‡**: xgboost, lightgbm, catboost
- **é›†æˆå­¦ä¹ **: random_forest, gradient_boosting, adaboost, extra_trees
- **ç»å…¸ç®—æ³•**: svr, knn, decision_tree
- **çº¿æ€§æ¨¡å‹**: ridge, lasso, elastic_net

## è®­ç»ƒå‚æ•°ï¼ˆtraining.*ï¼‰

| å‚æ•° | è¯´æ˜ | ç±»å‹ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|------|--------|------|
| n_folds | äº¤å‰éªŒè¯æŠ˜æ•° | int | 10 | 5, 10 |
| training.n_folds | åŒn_folds | int | 10 | 5, 10 |
| training.metrics | è¯„ä¼°æŒ‡æ ‡ | list | [rmse,mae,r2,mape] | rmse,r2 |
| training.early_stopping | æ—©åœ | bool | false | true |
| training.early_stopping_rounds | æ—©åœè½®æ•° | int | 10 | 50 |
| training.verbose | è¯¦ç»†è¾“å‡º | int | 1 | 0/1/2 |
| training.save_fold_models | ä¿å­˜æŠ˜æ¨¡å‹ | bool | true | true/false |
| training.save_final_model | ä¿å­˜æœ€ç»ˆæ¨¡å‹ | bool | true | true/false |

## ä¼˜åŒ–å‚æ•°ï¼ˆoptimization.*ï¼‰

| å‚æ•° | è¯´æ˜ | ç±»å‹ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|------|--------|------|
| optimization | å¯ç”¨ä¼˜åŒ– | bool | false | true |
| optimization.enable | åŒoptimization | bool | false | true |
| optimization.optimizer | ä¼˜åŒ–å™¨ç±»å‹ | str | optuna | optuna/grid/random |
| optimization.n_trials | è¯•éªŒæ¬¡æ•° | int | 100 | 50, 200 |
| optimization.n_folds | ä¼˜åŒ–æŠ˜æ•° | int | 5 | 3, 5 |
| optimization.timeout | è¶…æ—¶(ç§’) | int | None | 3600 |
| optimization.metric | ä¼˜åŒ–æŒ‡æ ‡ | str | rmse | rmse/mae/r2/mape |
| optimization.direction | ä¼˜åŒ–æ–¹å‘ | str | minimize | minimize/maximize |
| optimization.automl | å¯ç”¨AutoML | bool | false | true |
| optimization.automl_models | AutoMLæ¨¡å‹åˆ—è¡¨ | list | [xgboost,lightgbm,catboost] | æ‰€æœ‰13ç§æ¨¡å‹ |
| optimization.automl_trials_per_model | æ¯æ¨¡å‹è¯•éªŒæ•° | int | 50 | 20, 100 |

## é¡¹ç›®ç®¡ç†å‚æ•°

| å‚æ•° | è¯´æ˜ | ç±»å‹ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|------|--------|------|
| project | é¡¹ç›®åç§° | str | default | my_project |
| name | å®éªŒåç§° | str | è‡ªåŠ¨ç”Ÿæˆ | exp_001 |
| output_dir | è¾“å‡ºç›®å½• | str | runs/ | experiments/ |
| config | é…ç½®æ¨¡æ¿ | str | None | xgboost_quick |

## æ—¥å¿—å‚æ•°ï¼ˆlogging.*ï¼‰

| å‚æ•° | è¯´æ˜ | ç±»å‹ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|------|--------|------|
| logging.log_level | æ—¥å¿—çº§åˆ« | str | INFO | DEBUG/INFO/WARNING |
| logging.save_plots | ä¿å­˜å›¾è¡¨ | bool | true | true/false |
| logging.generate_report | ç”ŸæˆæŠ¥å‘Š | bool | true | true/false |
| logging.export_for_paper | å¯¼å‡ºè®ºæ–‡å›¾è¡¨ | bool | false | true |

================================
# ç¬¬å…­éƒ¨åˆ†ï¼šå®æˆ˜ç¤ºä¾‹
================================

## ç¤ºä¾‹1ï¼šæœ€ç®€å•çš„è®­ç»ƒ
```bash
# ä½¿ç”¨é»˜è®¤é…ç½®
python automl.py train data=data/Database_normalized.csv
```

## ç¤ºä¾‹2ï¼šå¿«é€Ÿå®éªŒ
```bash
# ä½¿ç”¨å¿«é€Ÿæ¨¡æ¿ï¼Œ5æŠ˜äº¤å‰éªŒè¯
python automl.py train config=xgboost_quick \
    data=data/Database_normalized.csv \
    n_folds=5 \
    project=quick_test
```

## ç¤ºä¾‹3ï¼šæ ‡å‡†ç”Ÿäº§è®­ç»ƒ
```bash
# å®Œæ•´è®­ç»ƒé…ç½®
python automl.py train config=xgboost_full \
    data=data/Database_normalized.csv \
    test_data=data/test.csv \
    project=production \
    name=final_model \
    n_folds=10 \
    training.early_stopping=true \
    training.early_stopping_rounds=50
```

## ç¤ºä¾‹4ï¼šè¶…å‚æ•°ä¼˜åŒ–
```bash
# Optunaä¼˜åŒ–
python automl.py train config=xgboost_optuna \
    data=data/Database_normalized.csv \
    target=PLQY \
    optimization.n_trials=100 \
    optimization.metric=r2 \
    optimization.direction=maximize
```

## ç¤ºä¾‹5ï¼šAutoMLå®Œæ•´æµç¨‹
```bash
# æµ‹è¯•æ‰€æœ‰æ¨¡å‹ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜
python automl.py train config=automl \
    data=data/Database_normalized.csv \
    test_data=test.csv \
    optimization.automl_models='["xgboost","lightgbm","catboost","random_forest"]' \
    optimization.automl_trials_per_model=50 \
    optimization.n_folds=10
```

## ç¤ºä¾‹6ï¼šå¤§è§„æ¨¡å¹¶è¡Œè®­ç»ƒ
```bash
# NUMAä¼˜åŒ– + å¹¶è¡Œè®­ç»ƒ
python automl.py train config=automl \
    data=data/Database_normalized.csv \
    numa=true \
    parallel=8 \
    cores=4 \
    bind_cpu=true \
    project=parallel_exp
```

## ç¤ºä¾‹7ï¼šåˆ†å­ç‰¹å¾é…ç½®
```bash
# é«˜ç»´MorganæŒ‡çº¹
python automl.py train model=xgboost \
    data=data/molecules.csv \
    feature.feature_type=morgan \
    feature.morgan_bits=2048 \
    feature.morgan_radius=3 \
    target=activity
```

## ç¤ºä¾‹8ï¼šå®Œæ•´çš„ç”Ÿäº§æµæ°´çº¿
```bash
# åŒ…å«æ‰€æœ‰é«˜çº§ç‰¹æ€§çš„å®Œæ•´å‘½ä»¤
python automl.py train \
    config=automl \
    data=data/Database_normalized.csv \
    data.test_data_path=test_set.csv \
    data.smiles_columns='L1,L2,L3' \
    data.target_columns='Max_wavelength(nm),PLQY,tau(s*10^-6)' \
    feature.feature_type=combined \
    feature.morgan_bits=2048 \
    feature.morgan_radius=2 \
    feature.combination_method=mean \
    optimization.enable=true \
    optimization.automl=true \
    optimization.automl_models='["xgboost","lightgbm","catboost","random_forest","gradient_boosting"]' \
    optimization.automl_trials_per_model=100 \
    optimization.n_folds=10 \
    optimization.metric=r2 \
    optimization.direction=maximize \
    training.n_folds=10 \
    training.early_stopping=true \
    training.early_stopping_rounds=50 \
    numa=true \
    parallel=16 \
    cores=8 \
    bind_cpu=true \
    project=production_v1 \
    name=final_ensemble \
    logging.generate_report=true \
    logging.export_for_paper=true
```

## ç¤ºä¾‹9ï¼šæ‰¹é‡é¢„æµ‹æµæ°´çº¿
```bash
# æ­¥éª¤1ï¼šè®­ç»ƒæœ€ä¼˜æ¨¡å‹
python automl.py train config=xgboost_optuna \
    data=data/train.csv \
    project=batch_pred

# æ­¥éª¤2ï¼šæ‰¹é‡é¢„æµ‹
python automl.py predict \
    model=runs/train/batch_pred/models/best_model.joblib \
    data=data/new_molecules.csv \
    feature=combined \
    morgan_bits=2048 \
    output=predictions_batch.csv

# æ­¥éª¤3ï¼šåˆ†æé¢„æµ‹ç»“æœ
python automl.py analyze dir=runs/train/batch_pred format=html
```

## ç¤ºä¾‹10ï¼šè¿‡æ‹Ÿåˆç¼“è§£é…ç½®
```bash
# é’ˆå¯¹PLQYè¿‡æ‹Ÿåˆçš„ä¼˜åŒ–é…ç½®
python automl.py train config=xgboost_quick \
    data=data/Database_normalized.csv \
    target=PLQY \
    feature.feature_type=morgan \
    feature.morgan_bits=512 \
    feature.morgan_radius=2 \
    n_folds=10 \
    training.early_stopping=true \
    training.early_stopping_rounds=50 \
    model.hyperparameters.max_depth=5 \
    model.hyperparameters.min_child_weight=8 \
    model.hyperparameters.gamma=0.3 \
    model.hyperparameters.subsample=0.7 \
    model.hyperparameters.colsample_bytree=0.7 \
    model.hyperparameters.reg_alpha=0.6 \
    model.hyperparameters.reg_lambda=1.0 \
    model.hyperparameters.learning_rate=0.05 \
    model.hyperparameters.n_estimators=600
```

================================
# é™„å½•ï¼šå¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ
================================

## Q1: RDKitæœªå®‰è£…å¯¼è‡´åˆ†å­ç‰¹å¾æŠ¥é”™
**è§£å†³**: ä½¿ç”¨condaå®‰è£…RDKit
```bash
conda install -c conda-forge rdkit
```
æˆ–åˆ‡æ¢åˆ°è¡¨æ ¼ç‰¹å¾ï¼š
```bash
python automl.py train data=data.csv feature=tabular
```

## Q2: é¢„æµ‹ç»´åº¦ä¸åŒ¹é…
**è§£å†³**: ç¡®ä¿é¢„æµ‹æ—¶ç‰¹å¾å‚æ•°ä¸è®­ç»ƒæ—¶ä¸€è‡´
```bash
# è®­ç»ƒæ—¶
python automl.py train feature.morgan_bits=2048 feature.morgan_radius=2

# é¢„æµ‹æ—¶å¿…é¡»ä½¿ç”¨ç›¸åŒå‚æ•°
python automl.py predict morgan_bits=2048 morgan_radius=2
```

## Q3: RÂ²ä»0.8+é™è‡³0.1+
**å¯èƒ½åŸå› ä¸è§£å†³**:
1. ç‰¹å¾å‚æ•°ä¸ä¸€è‡´ - æ£€æŸ¥morgan_bits/morgan_radius
2. æ•°æ®é¢„å¤„ç†ä¸åŒ - ç¡®è®¤PLQYå•ä½å¤„ç†
3. éšæœºç§å­å˜åŒ– - å›ºå®šrandom_seed=42
4. ä½¿ç”¨é™ç»´å’Œæ­£åˆ™åŒ–ç¼“è§£è¿‡æ‹Ÿåˆ

## Q4: å†…å­˜ä¸è¶³
**è§£å†³**: 
- å‡å°‘n_foldsæ•°é‡
- ä½¿ç”¨è¾ƒå°çš„morgan_bits
- å‡å°‘parallelä»»åŠ¡æ•°
- ä½¿ç”¨feature=morganä»£æ›¿combined

## Q5: è®­ç»ƒæ—¶é—´è¿‡é•¿
**è§£å†³**:
- ä½¿ç”¨å¿«é€Ÿæ¨¡æ¿ï¼šconfig=xgboost_quick
- å‡å°‘n_trialsæ•°é‡
- å¯ç”¨early_stopping
- ä½¿ç”¨NUMAå¹¶è¡ŒåŠ é€Ÿ

================================
# å‘½ä»¤é€ŸæŸ¥è¡¨
================================

```bash
# ===== è®­ç»ƒ =====
python automl.py train model=xgboost data=data.csv
python automl.py train config=xgboost_quick project=test
python automl.py train config=automl test_data=test.csv

# ===== é¢„æµ‹ =====
python automl.py predict model=model.joblib data=test.csv
python automl.py predict model=model.joblib input='["CCO"]' feature=morgan

# ===== åˆ†æ =====
python automl.py analyze dir=last format=html
python automl.py analyze dir=runs/exp1,runs/exp2 compare=true

# ===== éªŒè¯ =====
python automl.py validate config=config.yaml
python automl.py validate data=data.csv

# ===== å¯¼å‡º =====
python automl.py export model=model.joblib format=onnx

# ===== ç³»ç»Ÿä¿¡æ¯ =====
python automl.py info
python automl.py info models
python automl.py info templates

# ===== ç‰¹å¾ç¼“å­˜ =====
python automl.py warmup data=data.csv feature=combined
python automl.py warmup clean=true
```

================================
# ç¬¬ä¸ƒéƒ¨åˆ†ï¼šè‡ªé€‚åº”ç”Ÿäº§ç¯å¢ƒè®­ç»ƒè„šæœ¬ï¼ˆ8æ ¸åˆ°256æ ¸ï¼‰
================================

## æ™ºèƒ½è‡ªé€‚åº”è®­ç»ƒè„šæœ¬

è‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶é…ç½®ï¼Œä»8æ ¸å¼€å‘æœºåˆ°256æ ¸æœåŠ¡å™¨éƒ½èƒ½ä¼˜åŒ–è¿è¡Œï¼Œå…ˆæµ‹è¯•æ‰€æœ‰åŠŸèƒ½å†æ‰§è¡Œè®­ç»ƒã€‚

### è„šæœ¬ç‰¹æ€§
- âœ… **è‡ªåŠ¨ç¡¬ä»¶æ£€æµ‹**ï¼šæ ¹æ®CPUæ ¸å¿ƒæ•°è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜é…ç½®
- âœ… **å®Œæ•´åŠŸèƒ½æµ‹è¯•**ï¼šè®­ç»ƒå‰æµ‹è¯•æ‰€æœ‰åŠŸèƒ½ï¼Œç¡®ä¿ç¯å¢ƒæ­£å¸¸
- âœ… **å››ç§è¿è¡Œæ¨¡å¼**ï¼šdebug/development/standard/production
- âœ… **æ™ºèƒ½å¹¶è¡Œé…ç½®**ï¼šæ ¹æ®æ ¸å¿ƒæ•°è‡ªåŠ¨è°ƒæ•´å¹¶è¡Œå‚æ•°
- âœ… **å…¨é¢é”™è¯¯å¤„ç†**ï¼šæµ‹è¯•å¤±è´¥æ—¶æä¾›è¯¦ç»†è¯Šæ–­ä¿¡æ¯
- âœ… **ç¾è§‚HTMLæŠ¥å‘Š**ï¼šè‡ªåŠ¨ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š

### è¿è¡Œæ¨¡å¼

| æ¨¡å¼ | CPUæ ¸å¿ƒ | é€‚ç”¨åœºæ™¯ | è®­ç»ƒè§„æ¨¡ |
|------|---------|----------|----------|
| **Debug** | 8æ ¸ä»¥ä¸‹ | å¼€å‘æµ‹è¯• | æœ€å°åŒ–è®­ç»ƒï¼Œå¿«é€ŸéªŒè¯ |
| **Development** | 16-32æ ¸ | æ—¥å¸¸å¼€å‘ | æ ‡å‡†è®­ç»ƒï¼Œ5æŠ˜CV |
| **Standard** | 64-128æ ¸ | æ ‡å‡†æœåŠ¡å™¨ | å®Œæ•´è®­ç»ƒï¼Œ10æŠ˜CV |
| **Production** | 256æ ¸+ | ç”Ÿäº§ç¯å¢ƒ | å…¨é‡è®­ç»ƒ+AutoML |

### ä½¿ç”¨æ–¹æ³•

```bash
# 1. èµ‹äºˆæ‰§è¡Œæƒé™
chmod +x production_train_adaptive.sh

# 2. è‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶å¹¶é€‰æ‹©æœ€ä¼˜æ¨¡å¼
./production_train_adaptive.sh

# 3. å¼ºåˆ¶ä½¿ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆ8æ ¸å¼€å‘æœºï¼‰
./production_train_adaptive.sh --debug

# 4. å¼ºåˆ¶ä½¿ç”¨ç”Ÿäº§æ¨¡å¼ï¼ˆ256æ ¸æœåŠ¡å™¨ï¼‰
./production_train_adaptive.sh --production

# 5. æŸ¥çœ‹ç»“æœ
firefox production_runs/*/reports/index.html
```

### è„šæœ¬æ‰§è¡Œæµç¨‹

#### ç¬¬1é˜¶æ®µï¼šå¿«é€ŸéªŒè¯ï¼ˆ5åˆ†é’Ÿï¼‰
- æ•°æ®éªŒè¯
- é…ç½®æ£€æŸ¥
- 2æŠ˜å¿«é€Ÿæµ‹è¯•

#### ç¬¬2é˜¶æ®µï¼šä¸»è¦æ¨¡å‹è®­ç»ƒï¼ˆ30-60åˆ†é’Ÿï¼‰
```bash
# XGBoostå®Œæ•´è®­ç»ƒï¼ˆ32å¹¶è¡ŒÃ—8æ ¸ï¼‰
parallel=32 cores=8 â†’ 256æ ¸å¿ƒ

# LightGBMå®Œæ•´è®­ç»ƒï¼ˆ32å¹¶è¡ŒÃ—8æ ¸ï¼‰
parallel=32 cores=8 â†’ 256æ ¸å¿ƒ  

# CatBoostå®Œæ•´è®­ç»ƒï¼ˆ16å¹¶è¡ŒÃ—8æ ¸ï¼‰
parallel=16 cores=8 â†’ 128æ ¸å¿ƒ
```

#### ç¬¬3é˜¶æ®µï¼šè¶…å‚æ•°ä¼˜åŒ–ï¼ˆ1-2å°æ—¶ï¼‰
- XGBoost Optunaï¼ˆ200æ¬¡è¯•éªŒï¼‰
- LightGBM Optunaï¼ˆ200æ¬¡è¯•éªŒï¼‰
- è‡ªåŠ¨é€‰æ‹©æœ€ä½³å‚æ•°

#### ç¬¬4é˜¶æ®µï¼šAutoMLå…¨æ¨¡å‹æµ‹è¯•ï¼ˆ2-3å°æ—¶ï¼‰
- æµ‹è¯•å…¨éƒ¨13ä¸ªæ¨¡å‹
- æ¯æ¨¡å‹50æ¬¡è¯•éªŒ
- è‡ªåŠ¨æ¨¡å‹é€‰æ‹©

#### ç¬¬5é˜¶æ®µï¼šåˆ†ææŠ¥å‘Šç”Ÿæˆ
- HTMLå¯è§†åŒ–æŠ¥å‘Š
- æ–‡æœ¬åˆ†ææŠ¥å‘Š
- JSONæ•°æ®å¯¼å‡º

#### ç¬¬6é˜¶æ®µï¼šæµ‹è¯•é›†é¢„æµ‹å’Œå¯¹æ¯”
- ä½¿ç”¨æœ€ä½³æ¨¡å‹é¢„æµ‹æµ‹è¯•æ•°æ®
- **ç”Ÿæˆé¢„æµ‹å€¼ä¸çœŸå®å€¼å¯¹æ¯”æŠ¥å‘Š**
- è®¡ç®—RÂ²ã€MAEã€RMSEã€MAPEæŒ‡æ ‡
- ç”Ÿæˆäº¤äº’å¼æ•£ç‚¹å›¾ï¼ˆPlotlyï¼‰
- è¯¦ç»†å¯¹æ¯”è¡¨æ˜¾ç¤ºæ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹è¯¯å·®

#### ç¬¬7é˜¶æ®µï¼šç»¼åˆæŠ¥å‘Š
- ç”Ÿæˆindex.htmlä¸»é¡µ
- æ±‡æ€»æ‰€æœ‰ç»“æœ
- æ€§èƒ½ç»Ÿè®¡
- **åŒ…å«é¢„æµ‹å¯¹æ¯”åˆ†æé“¾æ¥**

#### ç¬¬8é˜¶æ®µï¼šæ‰“åŒ…å½’æ¡£
- å‹ç¼©æ‰€æœ‰ç»“æœ
- æ¸…ç†ä¸´æ—¶æ–‡ä»¶
- ç”Ÿæˆæœ€ç»ˆåŒ…

### è¾“å‡ºç›®å½•ç»“æ„

```
production_runs/production_YYYYMMDD_HHMMSS/
â”œâ”€â”€ logs/                      # æ—¥å¿—æ–‡ä»¶
â”‚   â”œâ”€â”€ main_*.log            # ä¸»æ—¥å¿—
â”‚   â”œâ”€â”€ errors_*.log          # é”™è¯¯æ—¥å¿—
â”‚   â”œâ”€â”€ performance_*.log     # æ€§èƒ½æ—¥å¿—
â”‚   â”œâ”€â”€ xgboost_full.log     # XGBoostè®­ç»ƒæ—¥å¿—
â”‚   â”œâ”€â”€ lightgbm_full.log    # LightGBMè®­ç»ƒæ—¥å¿—
â”‚   â””â”€â”€ catboost_full.log    # CatBoostè®­ç»ƒæ—¥å¿—
â”œâ”€â”€ reports/                   # åˆ†ææŠ¥å‘Š
â”‚   â”œâ”€â”€ index.html            # ç»¼åˆæŠ¥å‘Šä¸»é¡µ
â”‚   â”œâ”€â”€ prediction_comparison.html  # ğŸ¯ é¢„æµ‹å¯¹æ¯”åˆ†ææŠ¥å‘Š
â”‚   â”œâ”€â”€ prediction_comparison.csv   # é¢„æµ‹å¯¹æ¯”æ•°æ®
â”‚   â”œâ”€â”€ *_report.html         # HTMLæŠ¥å‘Š
â”‚   â”œâ”€â”€ *_report.txt          # æ–‡æœ¬æŠ¥å‘Š
â”‚   â””â”€â”€ *_results.json        # JSONæ•°æ®
â”œâ”€â”€ exports/                   # å¯¼å‡ºæ–‡ä»¶
â”‚   â”œâ”€â”€ best_model.pkl        # æœ€ä½³æ¨¡å‹
â”‚   â””â”€â”€ test_predictions.csv  # é¢„æµ‹ç»“æœ
â”œâ”€â”€ visualizations/            # å¯è§†åŒ–å›¾è¡¨
â”‚   â”œâ”€â”€ feature_importance/   # ç‰¹å¾é‡è¦æ€§
â”‚   â”œâ”€â”€ learning_curves/      # å­¦ä¹ æ›²çº¿
â”‚   â””â”€â”€ predictions/          # é¢„æµ‹æ•£ç‚¹å›¾
â””â”€â”€ production_*/              # å„å®éªŒå­ç›®å½•
    â”œâ”€â”€ xgboost_full/         # XGBoostå®Œæ•´è®­ç»ƒ
    â”œâ”€â”€ lightgbm_full/        # LightGBMå®Œæ•´è®­ç»ƒ
    â”œâ”€â”€ catboost_full/        # CatBoostå®Œæ•´è®­ç»ƒ
    â”œâ”€â”€ xgboost_optuna/       # XGBoostä¼˜åŒ–
    â”œâ”€â”€ lightgbm_optuna/      # LightGBMä¼˜åŒ–
    â””â”€â”€ automl_complete/      # AutoMLç»“æœ
```

### ç¡¬ä»¶é…ç½®å»ºè®®

#### 256æ ¸æœåŠ¡å™¨é…ç½®
```bash
# CPUé…ç½®
CPU: AMD EPYC æˆ– Intel Xeon (256æ ¸å¿ƒ)
å†…å­˜: 512GB+ DDR4 ECC
å­˜å‚¨: NVMe SSD 2TB+

# NUMAé…ç½®
NUMAèŠ‚ç‚¹: 8ä¸ª
æ¯èŠ‚ç‚¹æ ¸å¿ƒ: 32ä¸ª
æ¯èŠ‚ç‚¹å†…å­˜: 64GB

# å¹¶è¡Œé…ç½®
æ¨èå¹¶è¡Œæ•°: 32
æ¯ä»»åŠ¡æ ¸å¿ƒ: 8
æ€»ä½¿ç”¨æ ¸å¿ƒ: 256
```

### æ€§èƒ½ä¼˜åŒ–å‚æ•°

```bash
# NUMAä¼˜åŒ–
numa=true              # å¯ç”¨NUMAæ„ŸçŸ¥
bind_cpu=true         # CPUäº²å’Œæ€§ç»‘å®š

# å¹¶è¡Œè®­ç»ƒ
parallel=32           # 32ä¸ªå¹¶è¡Œä»»åŠ¡
cores=8              # æ¯ä»»åŠ¡8æ ¸å¿ƒ

# å†…å­˜ä¼˜åŒ–
export OMP_NUM_THREADS=8
export MKL_NUM_THREADS=8
export NUMEXPR_NUM_THREADS=8
```

### ç›‘æ§å’Œè°ƒè¯•

```bash
# å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦
tail -f production_runs/*/logs/main_*.log

# æŸ¥çœ‹é”™è¯¯
tail -f production_runs/*/logs/errors_*.log

# ç›‘æ§ç³»ç»Ÿèµ„æº
htop -d 1
nvidia-smi -l 1  # å¦‚æœæœ‰GPU

# æŸ¥çœ‹NUMAçŠ¶æ€
numactl --hardware
numastat
```

### å®šåˆ¶åŒ–é…ç½®

#### ä¿®æ”¹æ¨¡å‹å‚æ•°
```bash
# ç¼–è¾‘è„šæœ¬ä¸­çš„æ¨¡å‹é…ç½®
model.hyperparameters.n_estimators=2000
model.hyperparameters.max_depth=10
model.hyperparameters.learning_rate=0.05
```

#### ä¿®æ”¹å¹¶è¡Œé…ç½®
```bash
# 128æ ¸é…ç½®
parallel=16 cores=8

# 64æ ¸é…ç½®  
parallel=8 cores=8

# 32æ ¸é…ç½®
parallel=4 cores=8
```

#### ä¿®æ”¹ä¼˜åŒ–é…ç½®
```bash
# æ›´å¤šä¼˜åŒ–è¯•éªŒ
optimization.n_trials=500

# æ›´å¤šäº¤å‰éªŒè¯æŠ˜æ•°
optimization.n_folds=10

# ä¸åŒä¼˜åŒ–æŒ‡æ ‡
optimization.metric=mape
optimization.direction=minimize
```

### é¢„è®¡è¿è¡Œæ—¶é—´

| é˜¶æ®µ | æ—¶é—´ä¼°è®¡ | è¯´æ˜ |
|------|---------|------|
| å¿«é€ŸéªŒè¯ | 5åˆ†é’Ÿ | æ•°æ®å’Œé…ç½®æ£€æŸ¥ |
| ä¸»è¦æ¨¡å‹è®­ç»ƒ | 30-60åˆ†é’Ÿ | 3ä¸ªä¸»è¦æ¨¡å‹å¹¶è¡Œ |
| è¶…å‚æ•°ä¼˜åŒ– | 1-2å°æ—¶ | 200æ¬¡è¯•éªŒÃ—2æ¨¡å‹ |
| AutoML | 2-3å°æ—¶ | 13æ¨¡å‹Ã—50è¯•éªŒ |
| æŠ¥å‘Šç”Ÿæˆ | 10-20åˆ†é’Ÿ | åˆ†æå’Œå¯è§†åŒ– |
| **æ€»è®¡** | **4-6å°æ—¶** | å®Œæ•´æµç¨‹ |

### æ•…éšœæ’é™¤

#### å†…å­˜ä¸è¶³
```bash
# å‡å°‘å¹¶è¡Œæ•°
parallel=16 cores=8

# å‡å°‘äº¤å‰éªŒè¯æŠ˜æ•°
n_folds=5
```

#### è®­ç»ƒå¤ªæ…¢
```bash
# å‡å°‘ä¼˜åŒ–è¯•éªŒ
optimization.n_trials=50

# ä½¿ç”¨å¿«é€Ÿæ¨¡æ¿
config=xgboost_quick
```

#### NUMAé—®é¢˜
```bash
# ç¦ç”¨NUMAä¼˜åŒ–
numa=false
bind_cpu=false
```

### æœ€ä½³å®è·µ

1. **æ•°æ®å‡†å¤‡**
   - ç¡®ä¿æ•°æ®å·²æ¸…æ´—å’Œæ ‡å‡†åŒ–
   - ä½¿ç”¨feature_cacheåŠ é€Ÿç‰¹å¾æå–
   - é¢„å…ˆåˆ†å‰²è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†

2. **èµ„æºåˆ†é…**
   - ä¸ºæ“ä½œç³»ç»Ÿä¿ç•™10-20%èµ„æº
   - ç›‘æ§å†…å­˜ä½¿ç”¨é˜²æ­¢OOM
   - ä½¿ç”¨niceå‘½ä»¤è°ƒæ•´ä¼˜å…ˆçº§

3. **ç»“æœç®¡ç†**
   - å®šæœŸå¤‡ä»½é‡è¦æ¨¡å‹
   - ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ç®¡ç†é…ç½®
   - è®°å½•å®éªŒå‚æ•°å’Œç»“æœ

4. **ç”Ÿäº§éƒ¨ç½²**
   - é€‰æ‹©æœ€ä½³æ¨¡å‹éƒ¨ç½²
   - ä½¿ç”¨ONNXæ ¼å¼æé«˜å…¼å®¹æ€§
   - å®æ–½A/Bæµ‹è¯•éªŒè¯æ•ˆæœ

================================
# æ›´æ–°æ—¥å¿—
================================

- v3.0: å®Œæ•´çš„AutoMLç³»ç»Ÿï¼Œæ”¯æŒ13ç§æ¨¡å‹
- v3.1: æ·»åŠ NUMAä¼˜åŒ–å’Œå¹¶è¡Œè®­ç»ƒæ”¯æŒ
- v3.2: å¢å¼ºç‰¹å¾å·¥ç¨‹å’Œè¿‡æ‹Ÿåˆç¼“è§£
- v3.3: å®Œå–„æ–‡æ¡£å’Œç¤ºä¾‹
- v3.4: æ·»åŠ 256æ ¸ç”Ÿäº§ç¯å¢ƒè®­ç»ƒè„šæœ¬

---
æ–‡æ¡£ç‰ˆæœ¬ï¼š2024.01
ä½œè€…ï¼šAutoML Development Team