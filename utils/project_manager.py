#!/usr/bin/env python3
"""
é¡¹ç›®ç®¡ç†å™¨
ç”¨äºç®¡ç†AutoMLé¡¹ç›®çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸ
"""

import json
import yaml
import shutil
import zipfile
from pathlib import Path
from typing import Dict, List, Optional, Union
from datetime import datetime
import pandas as pd

from .comparison_table import ComparisonTableGenerator

class ProjectManager:
    """é¡¹ç›®ç®¡ç†å™¨"""
    
    def __init__(self, base_dir: str = "."):
        """
        åˆå§‹åŒ–é¡¹ç›®ç®¡ç†å™¨
        
        Args:
            base_dir: åŸºç¡€ç›®å½•
        """
        self.base_dir = Path(base_dir)
    
    def create_project_metadata(self, project_dir: str) -> Dict:
        """
        åˆ›å»ºé¡¹ç›®å…ƒæ•°æ®
        
        Args:
            project_dir: é¡¹ç›®ç›®å½•
        
        Returns:
            å…ƒæ•°æ®å­—å…¸
        """
        project_path = Path(project_dir)
        if not project_path.exists():
            raise ValueError(f"é¡¹ç›®ç›®å½•ä¸å­˜åœ¨: {project_dir}")
        
        metadata = {
            'project_name': project_path.name,
            'created_at': datetime.now().isoformat(),
            'path': str(project_path.absolute()),
            'models_trained': [],
            'targets': [],
            'best_models': {},
            'data_info': {},
            'comparison_tables': [],
            'training_runs': []
        }
        
        # æ‰«æè®­ç»ƒè¿è¡Œ
        for run_dir in project_path.iterdir():
            if run_dir.is_dir() and not run_dir.name.startswith('.'):
                run_info = self._analyze_run(run_dir)
                if run_info:
                    metadata['training_runs'].append(run_info)
                    
                    # æ”¶é›†æ¨¡å‹ç±»å‹
                    if run_info['model'] not in metadata['models_trained']:
                        metadata['models_trained'].append(run_info['model'])
                    
                    # æ”¶é›†ç›®æ ‡
                    for target in run_info.get('targets', []):
                        if target not in metadata['targets']:
                            metadata['targets'].append(target)
                    
                    # æ›´æ–°æœ€ä½³æ¨¡å‹
                    for target, perf in run_info.get('performance', {}).items():
                        if target not in metadata['best_models'] or \
                           perf.get('r2', 0) > metadata['best_models'][target].get('r2', 0):
                            metadata['best_models'][target] = {
                                'model': run_info['model'],
                                'run': run_info['name'],
                                'r2': perf.get('r2', 0),
                                'rmse': perf.get('rmse', 0),
                                'path': str(run_dir / 'models')
                            }
        
        # æŸ¥æ‰¾å¯¹æ¯”è¡¨æ ¼
        for table_file in project_path.glob('comparison_table_*'):
            metadata['comparison_tables'].append(table_file.name)
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata_file = project_path / 'project_metadata.json'
        with open(metadata_file, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"âœ… é¡¹ç›®å…ƒæ•°æ®å·²åˆ›å»º: {metadata_file}")
        
        return metadata
    
    def _analyze_run(self, run_dir: Path) -> Optional[Dict]:
        """åˆ†æå•ä¸ªè®­ç»ƒè¿è¡Œ"""
        run_info = {
            'name': run_dir.name,
            'path': str(run_dir),
            'model': None,
            'targets': [],
            'performance': {}
        }
        
        # è¯»å–é…ç½®
        config_file = run_dir / 'config.yaml'
        if config_file.exists():
            with open(config_file, 'r') as f:
                config = yaml.safe_load(f)
                run_info['model'] = config.get('model', {}).get('model_type')
                run_info['targets'] = config.get('data', {}).get('target_columns', [])
        
        # è¯»å–è¿è¡Œä¿¡æ¯
        run_info_file = run_dir / 'run_info.json'
        if run_info_file.exists():
            with open(run_info_file, 'r') as f:
                info = json.load(f)
                run_info['timestamp'] = info.get('timestamp')
                run_info['command'] = info.get('command')
        
        # æ”¶é›†æ€§èƒ½æŒ‡æ ‡
        for summary_file in (run_dir / 'exports').glob('*_summary.json'):
            with open(summary_file, 'r') as f:
                summary = json.load(f)
                target = summary.get('target')
                if target:
                    run_info['performance'][target] = {
                        'r2': summary.get('mean_r2', 0),
                        'rmse': summary.get('mean_rmse', 0),
                        'mae': summary.get('mean_mae', 0)
                    }
        
        return run_info if run_info['model'] else None
    
    def generate_comparison_table(self, project_name: str, output_dir: Optional[str] = None,
                                  formats: Optional[List[str]] = None,
                                  decimal_places: Optional[Dict[str, int]] = None) -> Dict[str, str]:
        """
        ä¸ºé¡¹ç›®ç”Ÿæˆæ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨æ ¼ï¼ˆè‡ªåŠ¨æ‰«æé¡¹ç›®ç›®å½•ä¸­çš„ *_summary.jsonï¼‰
        
        Args:
            project_name: é¡¹ç›®åç§°æˆ–è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤å†™å…¥é¡¹ç›®æ ¹ç›®å½•ï¼‰
            formats: è¾“å‡ºæ ¼å¼åˆ—è¡¨ï¼ˆmarkdown, html, latex, csvï¼‰
            decimal_places: å°æ•°ä½æ§åˆ¶ï¼Œå¦‚ {'r2': 4, 'rmse': 4, 'mae': 4}
        
        Returns:
            å„æ ¼å¼æ–‡ä»¶çš„è¾“å‡ºè·¯å¾„å­—å…¸
        """
        # è§£æé¡¹ç›®è·¯å¾„
        project_path = Path(project_name)
        if not project_path.exists():
            project_path = self.base_dir / project_name
        if not project_path.exists():
            raise ValueError(f"é¡¹ç›®ä¸å­˜åœ¨: {project_name}")

        # åˆ›å»ºç”Ÿæˆå™¨å¹¶å¯¼å‡º
        generator = ComparisonTableGenerator(results_dir=str(project_path))
        exported_files = generator.export_all_formats(
            output_dir=output_dir if output_dir else str(project_path),
            formats=formats if formats else ['markdown', 'html', 'latex', 'csv'],
            decimal_places=decimal_places
        )

        # æ›´æ–°/å†™å…¥é¡¹ç›®å…ƒæ•°æ®ä¸­çš„ comparison_tables åˆ—è¡¨
        metadata_file = project_path / 'project_metadata.json'
        metadata = None
        if metadata_file.exists():
            try:
                with open(metadata_file, 'r') as f:
                    metadata = json.load(f)
            except Exception:
                metadata = None
        if not metadata:
            metadata = self.create_project_metadata(str(project_path))

        # åˆå¹¶æ–°è¡¨æ ¼æ–‡ä»¶åï¼ˆä»…ä¿å­˜æ–‡ä»¶åï¼Œé¿å…ç»å¯¹è·¯å¾„å·®å¼‚ï¼‰
        new_names = [Path(p).name for p in exported_files.values()]
        existing = set(metadata.get('comparison_tables', []))
        for name in new_names:
            if name not in existing:
                metadata['comparison_tables'].append(name)
                existing.add(name)

        with open(metadata_file, 'w') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)

        print(f"âœ… å¯¹æ¯”è¡¨å·²ç”Ÿæˆï¼Œæ–‡ä»¶æ•°: {len(exported_files)}")
        for k, v in exported_files.items():
            print(f"   - {k}: {v}")

        return exported_files

    def list_projects(self) -> List[Dict]:
        """
        åˆ—å‡ºæ‰€æœ‰é¡¹ç›®
        
        Returns:
            é¡¹ç›®åˆ—è¡¨
        """
        projects = []
        
        # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«project_metadata.jsonçš„ç›®å½•
        for metadata_file in self.base_dir.rglob('project_metadata.json'):
            try:
                with open(metadata_file, 'r') as f:
                    metadata = json.load(f)
                    projects.append({
                        'name': metadata['project_name'],
                        'path': metadata_file.parent,
                        'created': metadata.get('created_at', 'Unknown'),
                        'models': len(metadata.get('models_trained', [])),
                        'runs': len(metadata.get('training_runs', []))
                    })
            except Exception as e:
                continue
        
        # ä¹ŸæŸ¥æ‰¾æ²¡æœ‰å…ƒæ•°æ®ä½†æœ‰æ¨¡å‹çš„ç›®å½•
        for model_file in self.base_dir.rglob('*.joblib'):
            project_dir = model_file.parent
            while project_dir != self.base_dir and project_dir.parent != self.base_dir:
                project_dir = project_dir.parent
            
            if not (project_dir / 'project_metadata.json').exists():
                # æ£€æŸ¥æ˜¯å¦å·²ç»æ·»åŠ 
                if not any(p['path'] == project_dir for p in projects):
                    projects.append({
                        'name': project_dir.name,
                        'path': project_dir,
                        'created': 'Unknown',
                        'models': '?',
                        'runs': '?'
                    })
        
        return projects
    
    def get_project_info(self, project_name: str) -> Dict:
        """
        è·å–é¡¹ç›®è¯¦ç»†ä¿¡æ¯
        
        Args:
            project_name: é¡¹ç›®åç§°æˆ–è·¯å¾„
        
        Returns:
            é¡¹ç›®ä¿¡æ¯å­—å…¸
        """
        # æŸ¥æ‰¾é¡¹ç›®
        project_path = Path(project_name)
        if not project_path.exists():
            # å°è¯•åœ¨base_dirä¸­æŸ¥æ‰¾
            project_path = self.base_dir / project_name
        
        if not project_path.exists():
            raise ValueError(f"é¡¹ç›®ä¸å­˜åœ¨: {project_name}")
        
        # æ£€æŸ¥å…ƒæ•°æ®
        metadata_file = project_path / 'project_metadata.json'
        if metadata_file.exists():
            with open(metadata_file, 'r') as f:
                return json.load(f)
        else:
            # åŠ¨æ€ç”Ÿæˆå…ƒæ•°æ®
            return self.create_project_metadata(str(project_path))
    
    def export_project(self, project_name: str, output_path: str = None,
                      format: str = 'zip') -> str:
        """
        å¯¼å‡ºé¡¹ç›®
        
        Args:
            project_name: é¡¹ç›®åç§°æˆ–è·¯å¾„
            output_path: è¾“å‡ºè·¯å¾„
            format: å¯¼å‡ºæ ¼å¼ ('zip', 'tar')
        
        Returns:
            å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        # æŸ¥æ‰¾é¡¹ç›®
        project_path = Path(project_name)
        if not project_path.exists():
            project_path = self.base_dir / project_name
        
        if not project_path.exists():
            raise ValueError(f"é¡¹ç›®ä¸å­˜åœ¨: {project_name}")
        
        # ç¡®ä¿æœ‰å…ƒæ•°æ®
        self.create_project_metadata(str(project_path))
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        if output_path is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_path = f"{project_path.name}_{timestamp}.{format}"
        
        # å¯¼å‡º
        if format == 'zip':
            with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file in project_path.rglob('*'):
                    if file.is_file():
                        arcname = file.relative_to(project_path.parent)
                        zipf.write(file, arcname)
        elif format == 'tar':
            import tarfile
            with tarfile.open(output_path, 'w:gz') as tar:
                tar.add(project_path, arcname=project_path.name)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}")
        
        print(f"âœ… é¡¹ç›®å·²å¯¼å‡º: {output_path}")
        return output_path
    
    def clean_project(self, project_name: str, keep_models: bool = True,
                     keep_results: bool = True) -> None:
        """
        æ¸…ç†é¡¹ç›®ï¼ˆåˆ é™¤ä¸­é—´æ–‡ä»¶ï¼‰
        
        Args:
            project_name: é¡¹ç›®åç§°æˆ–è·¯å¾„
            keep_models: æ˜¯å¦ä¿ç•™æ¨¡å‹æ–‡ä»¶
            keep_results: æ˜¯å¦ä¿ç•™ç»“æœæ–‡ä»¶
        """
        # æŸ¥æ‰¾é¡¹ç›®
        project_path = Path(project_name)
        if not project_path.exists():
            project_path = self.base_dir / project_name
        
        if not project_path.exists():
            raise ValueError(f"é¡¹ç›®ä¸å­˜åœ¨: {project_name}")
        
        # æ¸…ç†è§„åˆ™
        patterns_to_delete = [
            '**/checkpoints/*',
            '**/predictions/*',
            '**/feature_importance/*' if not keep_results else None,
            '**/plots/*' if not keep_results else None,
            '**/models/*' if not keep_models else None,
        ]
        
        deleted_count = 0
        for pattern in patterns_to_delete:
            if pattern:
                for file in project_path.glob(pattern):
                    if file.is_file():
                        file.unlink()
                        deleted_count += 1
        
        print(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªæ–‡ä»¶")
    
    def generate_project_report(self, project_name: str, output_path: str = None) -> str:
        """
        ç”Ÿæˆé¡¹ç›®æŠ¥å‘Š
        
        Args:
            project_name: é¡¹ç›®åç§°æˆ–è·¯å¾„
            output_path: è¾“å‡ºè·¯å¾„
        
        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        # è·å–é¡¹ç›®ä¿¡æ¯
        info = self.get_project_info(project_name)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        report = f"# é¡¹ç›®æŠ¥å‘Š: {info['project_name']}\n\n"
        report += f"**åˆ›å»ºæ—¶é—´**: {info.get('created_at', 'Unknown')}\n\n"
        
        # æ¨¡å‹ä¿¡æ¯
        report += "## è®­ç»ƒçš„æ¨¡å‹\n\n"
        if info.get('models_trained'):
            for model in info['models_trained']:
                report += f"- {model}\n"
        else:
            report += "æ— æ¨¡å‹ä¿¡æ¯\n"
        
        report += "\n## é¢„æµ‹ç›®æ ‡\n\n"
        if info.get('targets'):
            for target in info['targets']:
                report += f"- {target}\n"
                if target in info.get('best_models', {}):
                    best = info['best_models'][target]
                    report += f"  - æœ€ä½³æ¨¡å‹: {best['model']} (RÂ²={best.get('r2', 'N/A'):.4f})\n"
        
        report += "\n## è®­ç»ƒè¿è¡Œ\n\n"
        if info.get('training_runs'):
            report += "| è¿è¡Œ | æ¨¡å‹ | ç›®æ ‡æ•° | å¹³å‡RÂ² |\n"
            report += "|------|------|--------|--------|\n"
            for run in info['training_runs']:
                avg_r2 = 0
                if run.get('performance'):
                    r2_values = [p.get('r2', 0) for p in run['performance'].values()]
                    avg_r2 = sum(r2_values) / len(r2_values) if r2_values else 0
                report += f"| {run['name']} | {run.get('model', 'Unknown')} | "
                report += f"{len(run.get('targets', []))} | {avg_r2:.4f} |\n"
        
        # ä¿å­˜æŠ¥å‘Š
        if output_path is None:
            project_path = Path(info['path'])
            output_path = project_path / f"project_report_{datetime.now().strftime('%Y%m%d')}.md"
        
        with open(output_path, 'w') as f:
            f.write(report)
        
        print(f"âœ… é¡¹ç›®æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        return str(output_path)


def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºæµ‹è¯•"""
    import argparse
    
    parser = argparse.ArgumentParser(description='é¡¹ç›®ç®¡ç†å™¨')
    subparsers = parser.add_subparsers(dest='command', help='å‘½ä»¤')
    
    # listå‘½ä»¤
    list_parser = subparsers.add_parser('list', help='åˆ—å‡ºæ‰€æœ‰é¡¹ç›®')
    
    # infoå‘½ä»¤
    info_parser = subparsers.add_parser('info', help='è·å–é¡¹ç›®ä¿¡æ¯')
    info_parser.add_argument('project', help='é¡¹ç›®åç§°æˆ–è·¯å¾„')
    
    # exportå‘½ä»¤
    export_parser = subparsers.add_parser('export', help='å¯¼å‡ºé¡¹ç›®')
    export_parser.add_argument('project', help='é¡¹ç›®åç§°æˆ–è·¯å¾„')
    export_parser.add_argument('--output', help='è¾“å‡ºè·¯å¾„')
    export_parser.add_argument('--format', default='zip', choices=['zip', 'tar'])
    
    # cleanå‘½ä»¤
    clean_parser = subparsers.add_parser('clean', help='æ¸…ç†é¡¹ç›®')
    clean_parser.add_argument('project', help='é¡¹ç›®åç§°æˆ–è·¯å¾„')
    clean_parser.add_argument('--keep-models', action='store_true')
    clean_parser.add_argument('--keep-results', action='store_true')
    
    # reportå‘½ä»¤
    report_parser = subparsers.add_parser('report', help='ç”Ÿæˆé¡¹ç›®æŠ¥å‘Š')
    report_parser.add_argument('project', help='é¡¹ç›®åç§°æˆ–è·¯å¾„')
    report_parser.add_argument('--output', help='è¾“å‡ºè·¯å¾„')

    # tableå‘½ä»¤
    table_parser = subparsers.add_parser('table', help='ç”Ÿæˆæ¨¡å‹å¯¹æ¯”è¡¨')
    table_parser.add_argument('project', help='é¡¹ç›®åç§°æˆ–è·¯å¾„')
    table_parser.add_argument('--output', help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤é¡¹ç›®æ ¹ç›®å½•ï¼‰')
    table_parser.add_argument('--formats', nargs='+', default=['markdown','html','latex','csv'],
                              help='è¾“å‡ºæ ¼å¼åˆ—è¡¨')
    
    args = parser.parse_args()
    
    manager = ProjectManager()
    
    if args.command == 'list':
        projects = manager.list_projects()
        if projects:
            print("\nğŸ“ é¡¹ç›®åˆ—è¡¨:")
            for p in projects:
                print(f"  - {p['name']} ({p['path']})")
                print(f"    åˆ›å»º: {p['created']}")
                print(f"    æ¨¡å‹: {p['models']}, è¿è¡Œ: {p['runs']}")
        else:
            print("æ²¡æœ‰æ‰¾åˆ°é¡¹ç›®")
    
    elif args.command == 'info':
        info = manager.get_project_info(args.project)
        print(json.dumps(info, indent=2, ensure_ascii=False))
    
    elif args.command == 'export':
        manager.export_project(args.project, args.output, args.format)
    
    elif args.command == 'clean':
        manager.clean_project(args.project, args.keep_models, args.keep_results)
    
    elif args.command == 'report':
        manager.generate_project_report(args.project, args.output)
    
    else:
        parser.print_help()


if __name__ == '__main__':
    main()