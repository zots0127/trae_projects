#!/usr/bin/env python3
"""
ä½¿ç”¨è®­ç»ƒå¥½çš„XGBoostæ¨¡å‹é¢„æµ‹æµ‹è¯•æ•°æ®é›†
è¾“å…¥: Database_ours_0903update_normalized.csv
è¾“å‡º: test_predict.csv
"""

import pandas as pd
import numpy as np
import joblib
from pathlib import Path
import argparse
from datetime import datetime
import time
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.feature_extractor import FeatureExtractor

def load_models(project_dir, model_name='xgboost', use_intersection=False):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    
    Args:
        project_dir: é¡¹ç›®ç›®å½•
        model_name: æ¨¡å‹åç§°
        use_intersection: æ˜¯å¦ä½¿ç”¨äº¤é›†è®­ç»ƒçš„æ¨¡å‹
    """
    print("\n" + "="*80)
    print("åŠ è½½é¢„è®­ç»ƒæ¨¡å‹")
    print("-"*80)
    
    models = {}
    
    # æ ¹æ®æ˜¯å¦ä½¿ç”¨äº¤é›†é€‰æ‹©æ¨¡å‹ç›®å½•
    if use_intersection:
        # äº¤é›†è®­ç»ƒçš„æ¨¡å‹é€šå¸¸åœ¨ intersection å­ç›®å½•
        model_dir = Path(project_dir) / model_name / 'intersection' / f'{model_name}_intersection' / 'models'
        if not model_dir.exists():
            # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
            model_dir = Path(project_dir) / model_name / 'intersection' / 'models'
            if not model_dir.exists():
                model_dir = Path(project_dir) / f'{model_name}_intersection' / 'models'
        print(f"  ğŸ“Œ ä½¿ç”¨äº¤é›†è®­ç»ƒæ¨¡å‹")
    else:
        # å°è¯•å¤šç§å¯èƒ½çš„æ¨¡å‹è·¯å¾„
        model_dir = Path(project_dir) / 'all_models' / 'automl_train' / model_name / 'models'
        if not model_dir.exists():
            # å°è¯•æ—§ç‰ˆè·¯å¾„
            model_dir = Path(project_dir) / model_name / 'models'
        print(f"  ğŸ“Œ ä½¿ç”¨å®Œæ•´æ•°æ®è®­ç»ƒæ¨¡å‹")
    
    if not model_dir.exists():
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}")
        return models
    
    print(f"  ğŸ“ æ¨¡å‹ç›®å½•: {model_dir}")
    
    # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶ï¼ˆåªåŠ è½½wavelengthå’ŒPLQYï¼‰
    for model_file in model_dir.glob("*.joblib"):
        filename = model_file.stem
        if 'wavelength' in filename.lower():
            models['wavelength'] = joblib.load(model_file)
            print(f"  âœ… æ³¢é•¿æ¨¡å‹: {model_file.name}")
        elif 'plqy' in filename.lower():
            models['PLQY'] = joblib.load(model_file)
            print(f"  âœ… PLQYæ¨¡å‹: {model_file.name}")
    
    print(f"\næˆåŠŸåŠ è½½ {len(models)} ä¸ªæ¨¡å‹")
    return models

def extract_features_for_test(df, feature_type='combined', combination_method='mean', descriptor_count=115):
    """æå–æµ‹è¯•æ•°æ®ç‰¹å¾"""
    print("\n" + "="*80)
    print("ç‰¹å¾æå–")
    print("-"*80)
    print(f"  â€¢ æ ·æœ¬æ•°: {len(df):,}")
    print(f"  â€¢ ç‰¹å¾ç±»å‹: {feature_type}")
    
    extractor = FeatureExtractor(
        feature_type=feature_type,
        morgan_radius=2,
        morgan_bits=1024,
        use_cache=True,
        descriptor_count=descriptor_count
    )
    
    features_list = []
    valid_indices = []
    failed_count = 0
    
    start_time = time.time()
    
    # æå–ç‰¹å¾
    for idx, row in df.iterrows():
        try:
            # æå–ç»„åˆç‰¹å¾
            smiles_list = [row['L1'], row['L2'], row['L3']]
            features = extractor.extract_combination(
                smiles_list,
                feature_type=feature_type,
                combination_method=combination_method
            )
            
            if features is not None:
                features_list.append(features)
                valid_indices.append(idx)
            else:
                failed_count += 1
                print(f"  âš ï¸ è¡Œ {idx}: ç‰¹å¾æå–å¤±è´¥")
        except Exception as e:
            failed_count += 1
            print(f"  âš ï¸ è¡Œ {idx}: {str(e)}")
    
    elapsed = time.time() - start_time
    
    if features_list:
        X = np.vstack(features_list)
        df_valid = df.iloc[valid_indices].copy()
        print(f"\nâœ… ç‰¹å¾æå–å®Œæˆ:")
        print(f"  â€¢ æˆåŠŸ: {len(X):,} ä¸ªæ ·æœ¬")
        print(f"  â€¢ å¤±è´¥: {failed_count:,} ä¸ªæ ·æœ¬")
        print(f"  â€¢ ç”¨æ—¶: {elapsed:.2f} ç§’")
        return X, df_valid
    else:
        print(f"\nâŒ ç‰¹å¾æå–å¤±è´¥")
        return None, None

def predict_test(models, X, df_valid):
    """é¢„æµ‹æµ‹è¯•æ•°æ®"""
    print("\n" + "="*80)
    print("æ‰¹é‡é¢„æµ‹")
    print("-"*80)
    print(f"  â€¢ æ ·æœ¬æ•°: {len(X):,}")
    
    predictions = {}
    
    # é¢„æµ‹æ¯ä¸ªç›®æ ‡
    for target, model in models.items():
        print(f"\né¢„æµ‹ {target}...")
        start_time = time.time()
        
        preds = model.predict(X)
        predictions[target] = preds
        
        elapsed = time.time() - start_time
        print(f"  âœ… å®Œæˆ:")
        print(f"    â€¢ æœ€å°å€¼: {preds.min():.6f}")
        print(f"    â€¢ æœ€å¤§å€¼: {preds.max():.6f}")
        print(f"    â€¢ å¹³å‡å€¼: {preds.mean():.6f}")
        print(f"    â€¢ æ ‡å‡†å·®: {preds.std():.6f}")
        print(f"    â€¢ ç”¨æ—¶: {elapsed:.3f} ç§’")
    
    # æ·»åŠ é¢„æµ‹åˆ°DataFrame
    if 'wavelength' in predictions:
        df_valid['Predicted_wavelength'] = predictions['wavelength']
    if 'PLQY' in predictions:
        df_valid['Predicted_PLQY'] = predictions['PLQY']
    
    return df_valid

def compare_with_actual(df):
    """å¦‚æœå­˜åœ¨å®é™…å€¼ï¼Œè¿›è¡Œæ¯”è¾ƒ"""
    print("\n" + "="*80)
    print("é¢„æµ‹ç»“æœåˆ†æ")
    print("-"*80)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…å€¼
    has_actual_wavelength = 'Max_wavelength(nm)' in df.columns and not df['Max_wavelength(nm)'].isna().all()
    has_actual_plqy = 'PLQY' in df.columns and not df['PLQY'].isna().all()
    
    if has_actual_wavelength and 'Predicted_wavelength' in df.columns:
        actual = df['Max_wavelength(nm)'].dropna()
        pred = df.loc[actual.index, 'Predicted_wavelength']
        
        if len(actual) > 0:
            mae = np.abs(actual - pred).mean()
            rmse = np.sqrt(((actual - pred) ** 2).mean())
            r2 = 1 - ((actual - pred) ** 2).sum() / ((actual - actual.mean()) ** 2).sum()
            
            print(f"\nğŸ“Š æ³¢é•¿é¢„æµ‹æ€§èƒ½:")
            print(f"  â€¢ æ ·æœ¬æ•°: {len(actual)}")
            print(f"  â€¢ MAE: {mae:.2f} nm")
            print(f"  â€¢ RMSE: {rmse:.2f} nm")
            print(f"  â€¢ RÂ²: {r2:.4f}")
    
    if has_actual_plqy and 'Predicted_PLQY' in df.columns:
        # å¤„ç†PLQYå•ä½ï¼ˆå¦‚æœæ˜¯ç™¾åˆ†æ¯”è½¬æ¢ä¸ºå°æ•°ï¼‰
        actual = df['PLQY'].dropna()
        if actual.max() > 1.5:  # å¯èƒ½æ˜¯ç™¾åˆ†æ¯”
            actual = actual / 100
        
        pred = df.loc[actual.index, 'Predicted_PLQY']
        
        if len(actual) > 0:
            mae = np.abs(actual - pred).mean()
            rmse = np.sqrt(((actual - pred) ** 2).mean())
            r2 = 1 - ((actual - pred) ** 2).sum() / ((actual - actual.mean()) ** 2).sum()
            
            print(f"\nğŸ“Š PLQYé¢„æµ‹æ€§èƒ½:")
            print(f"  â€¢ æ ·æœ¬æ•°: {len(actual)}")
            print(f"  â€¢ MAE: {mae:.4f}")
            print(f"  â€¢ RMSE: {rmse:.4f}")
            print(f"  â€¢ RÂ²: {r2:.4f}")
    
    # PLQYåˆ†å¸ƒ
    if 'Predicted_PLQY' in df.columns:
        plqy = df['Predicted_PLQY']
        print(f"\nğŸ“Š PLQYé¢„æµ‹åˆ†å¸ƒ:")
        print(f"  â€¢ æœ€å°å€¼: {plqy.min():.4f}")
        print(f"  â€¢ 25åˆ†ä½: {plqy.quantile(0.25):.4f}")
        print(f"  â€¢ ä¸­ä½æ•°: {plqy.median():.4f}")
        print(f"  â€¢ 75åˆ†ä½: {plqy.quantile(0.75):.4f}")
        print(f"  â€¢ æœ€å¤§å€¼: {plqy.max():.4f}")
        print(f"  â€¢ å¹³å‡å€¼: {plqy.mean():.4f}")
        
        # èŒƒå›´åˆ†å¸ƒ
        ranges = [(0.8, 1.0), (0.6, 0.8), (0.4, 0.6), (0.2, 0.4), (0.0, 0.2)]
        print(f"\n  PLQYèŒƒå›´åˆ†å¸ƒ:")
        for min_val, max_val in ranges:
            count = ((plqy >= min_val) & (plqy < max_val)).sum()
            pct = 100 * count / len(plqy)
            print(f"    [{min_val:.1f}, {max_val:.1f}): {count:4d} ({pct:5.1f}%)")
    
    # Top 5é«˜PLQYæ ·æœ¬
    if 'Predicted_PLQY' in df.columns:
        print(f"\nğŸ† Top 5 é«˜PLQYé¢„æµ‹:")
        top5 = df.nlargest(5, 'Predicted_PLQY')
        for i, (idx, row) in enumerate(top5.iterrows(), 1):
            print(f"\n  #{i} (è¡Œå·: {idx}):")
            print(f"    PLQYé¢„æµ‹: {row['Predicted_PLQY']:.4f}")
            if 'Predicted_wavelength' in df.columns:
                print(f"    æ³¢é•¿é¢„æµ‹: {row['Predicted_wavelength']:.1f} nm")
            if 'PLQY' in row and pd.notna(row['PLQY']):
                actual_plqy = row['PLQY']
                if actual_plqy > 1.5:
                    actual_plqy = actual_plqy / 100
                print(f"    PLQYå®é™…: {actual_plqy:.4f}")
            if 'Max_wavelength(nm)' in row and pd.notna(row['Max_wavelength(nm)']):
                print(f"    æ³¢é•¿å®é™…: {row['Max_wavelength(nm)']:.1f} nm")

def main():
    parser = argparse.ArgumentParser(description='é¢„æµ‹æµ‹è¯•æ•°æ®é›†')
    parser.add_argument('--project', '-p',
                       help='æ¨¡å‹é¡¹ç›®ç›®å½• (é»˜è®¤: paper_table)')
    parser.add_argument('--input', '-i', 
                       default='Database_ours_0903update_normalized.csv',
                       help='æµ‹è¯•æ•°æ®æ–‡ä»¶')
    parser.add_argument('--output', '-o',
                       help='è¾“å‡ºæ–‡ä»¶ (é»˜è®¤: PROJECT/test_predict.csv)')
    parser.add_argument('--model', '-m',
                       default='xgboost',
                       help='æ¨¡å‹ç±»å‹')
    parser.add_argument('--intersection', action='store_true',
                       help='ä½¿ç”¨äº¤é›†è®­ç»ƒçš„æ¨¡å‹ï¼ˆåªç”¨ä¸‰ä¸ªç›®æ ‡éƒ½æœ‰å€¼çš„æ•°æ®è®­ç»ƒï¼‰')
    parser.add_argument('--combination-method', default='mean',
                       choices=['mean', 'sum', 'concat'],
                       help='å¤šä¸ªé…ä½“ç‰¹å¾çš„åˆå¹¶æ–¹å¼')
    parser.add_argument('--descriptor-count', type=int, default=115,
                       help='åˆ†å­æè¿°ç¬¦æ•°é‡')
    
    args = parser.parse_args()
    
    # è®¾ç½®é»˜è®¤é¡¹ç›®ç›®å½•ä¸ºå›ºå®šåç§°
    if not args.project:
        args.project = 'paper_table'
    
    # è®¾ç½®é»˜è®¤è¾“å‡ºè·¯å¾„
    if not args.output:
        if args.intersection:
            args.output = f"{args.project}/test_predict_intersection.csv"
        else:
            args.output = f"{args.project}/test_predict.csv"
    
    print("="*80)
    print("æµ‹è¯•æ•°æ®é¢„æµ‹")
    print("="*80)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"\né…ç½®:")
    print(f"  â€¢ è¾“å…¥æ–‡ä»¶: {args.input}")
    print(f"  â€¢ æ¨¡å‹ç›®å½•: {args.project}/{args.model}")
    print(f"  â€¢ æ¨¡å‹ç±»å‹: {'äº¤é›†è®­ç»ƒæ¨¡å‹' if args.intersection else 'å®Œæ•´æ•°æ®è®­ç»ƒæ¨¡å‹'}")
    print(f"  â€¢ è¾“å‡ºæ–‡ä»¶: {args.output}")
    print(f"  â€¢ ç‰¹å¾åˆå¹¶: {args.combination_method}")
    print(f"  â€¢ æè¿°ç¬¦æ•°é‡: {args.descriptor_count}")
    
    start_time = time.time()
    
    # 1. åŠ è½½æµ‹è¯•æ•°æ®
    print(f"\nåŠ è½½æµ‹è¯•æ•°æ®...")
    df = pd.read_csv(args.input)
    print(f"  âœ… åŠ è½½ {len(df):,} ä¸ªæ ·æœ¬")
    print(f"  âœ… åˆ—: {', '.join(df.columns[:10])}")
    
    # 2. åŠ è½½æ¨¡å‹
    models = load_models(args.project, args.model, use_intersection=args.intersection)
    if not models:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹")
        return
    
    # 3. æå–ç‰¹å¾
    X, df_valid = extract_features_for_test(
        df,
        combination_method=args.combination_method,
        descriptor_count=args.descriptor_count
    )
    if X is None:
        print("âŒ ç‰¹å¾æå–å¤±è´¥")
        return
    
    # 4. é¢„æµ‹
    df_predicted = predict_test(models, X, df_valid)
    
    # 5. åˆ†æç»“æœ
    compare_with_actual(df_predicted)
    
    # 6. ä¿å­˜ç»“æœ
    print(f"\nä¿å­˜é¢„æµ‹ç»“æœ...")
    
    # ä¿å­˜åŒ…å«æ‰€æœ‰åŸå§‹åˆ—å’Œé¢„æµ‹åˆ—çš„å®Œæ•´æ•°æ®
    output_df = df.copy()
    
    # å°†é¢„æµ‹ç»“æœåˆå¹¶å›åŸå§‹æ•°æ®æ¡†
    if 'Predicted_wavelength' in df_predicted.columns:
        output_df.loc[df_predicted.index, 'Predicted_wavelength'] = df_predicted['Predicted_wavelength']
    if 'Predicted_PLQY' in df_predicted.columns:
        output_df.loc[df_predicted.index, 'Predicted_PLQY'] = df_predicted['Predicted_PLQY']
    
    # ä¿å­˜æ–‡ä»¶
    output_df.to_csv(args.output, index=False)
    print(f"  âœ… ä¿å­˜åˆ°: {args.output}")
    print(f"  âœ… è¡Œæ•°: {len(output_df):,}")
    print(f"  âœ… æˆåŠŸé¢„æµ‹: {len(df_predicted):,}")
    
    # ä¿å­˜åªåŒ…å«é¢„æµ‹æˆåŠŸçš„æ ·æœ¬
    valid_output = args.output.replace('.csv', '_valid_only.csv')
    df_predicted.to_csv(valid_output, index=False)
    print(f"  âœ… æœ‰æ•ˆé¢„æµ‹: {valid_output}")
    
    # å¦‚æœä½¿ç”¨äº¤é›†æ¨¡å‹ï¼Œè¯´æ˜æ•°æ®ç‰¹ç‚¹
    if args.intersection:
        print(f"\n  ğŸ“Œ æ³¨æ„: ä½¿ç”¨äº†äº¤é›†è®­ç»ƒçš„æ¨¡å‹")
        print(f"     è¿™äº›æ¨¡å‹åªç”¨ä¸‰ä¸ªç›®æ ‡éƒ½æœ‰å€¼çš„æ ·æœ¬è®­ç»ƒ")
        print(f"     é€šå¸¸å…·æœ‰æ›´å¥½çš„ä¸€è‡´æ€§ä½†å¯èƒ½æ³›åŒ–èƒ½åŠ›ç•¥ä½")
    
    # æ€»ç»“
    total_time = time.time() - start_time
    print("\n" + "="*80)
    print("âœ… é¢„æµ‹å®Œæˆ!")
    print(f"  â€¢ æ€»ç”¨æ—¶: {total_time:.2f} ç§’")
    print(f"  â€¢ å¤„ç†é€Ÿåº¦: {len(df)/total_time:.0f} samples/s")
    print(f"  â€¢ å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)

if __name__ == "__main__":
    main()
