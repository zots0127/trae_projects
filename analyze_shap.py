#!/usr/bin/env python3
"""
SHAPå¯è§£é‡Šæ€§åˆ†æå·¥å…· - åå¤„ç†è„šæœ¬
ç”¨äºåˆ†æå·²è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œä¸ä¼šç ´ååŸæœ‰é¡¹ç›®

ä½¿ç”¨æ–¹æ³•:
    python analyze_shap.py Paper_0930_222051
    python analyze_shap.py Paper_0930_222051 --models xgboost lightgbm
    python analyze_shap.py Paper_0930_222051 --sample-size 200
"""

import sys
import os
from pathlib import Path
import argparse
import joblib
import pandas as pd
import numpy as np
import json
from datetime import datetime
import shap
import matplotlib.pyplot as plt
import warnings

warnings.filterwarnings('ignore')

# æ·»åŠ è·¯å¾„ï¼ˆç”¨äºå¯¼å…¥RDKitç›¸å…³ï¼‰
sys.path.insert(0, str(Path(__file__).parent.parent / 'ir2025'))

# SHAPåº“ç›´æ¥ä½¿ç”¨ï¼Œä¸ä¾èµ–é¡¹ç›®å†…éƒ¨æ¨¡å—
print("âœ… SHAPåˆ†æå·¥å…·å·²åŠ è½½")


class ModelShapAnalyzer:
    """å·²è®­ç»ƒæ¨¡å‹çš„SHAPåˆ†æå™¨"""

    def __init__(self, paper_dir):
        self.paper_dir = Path(paper_dir)
        self.models_dir = self.paper_dir / 'all_models' / 'automl_train'
        self.output_dir = self.paper_dir / 'shap_analysis'
        self.output_dir.mkdir(exist_ok=True)

        # è¯»å–æ•°æ®
        self.load_data()

    def load_data(self):
        """åŠ è½½è®­ç»ƒæ•°æ®ç”¨äºSHAPèƒŒæ™¯"""
        print("\nğŸ“‚ åŠ è½½æ•°æ®...")

        # å°è¯•ä»å¤šä¸ªä½ç½®åŠ è½½æ•°æ®
        data_paths = [
            Path('/Users/kanshan/IR/ir2025/data/Database_normalized.csv'),
            Path('../ir2025/data/Database_normalized.csv'),
            Path('data/Database_normalized.csv')
        ]

        for data_path in data_paths:
            if data_path.exists():
                self.df = pd.read_csv(data_path)
                print(f"  âœ… æ•°æ®åŠ è½½æˆåŠŸ: {data_path}")
                print(f"  ğŸ“Š æ•°æ®ç»´åº¦: {self.df.shape}")
                return

        raise FileNotFoundError("âŒ æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶")

    def extract_features(self, smiles_list):
        """æå–åˆ†å­ç‰¹å¾"""
        from rdkit import Chem
        from rdkit.Chem import rdMolDescriptors, Descriptors

        features_list = []
        feature_dim = None

        for smiles in smiles_list:
            mol = Chem.MolFromSmiles(smiles)
            if mol is None:
                continue

            # MorganæŒ‡çº¹
            fp = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=2048)
            fp_array = np.array(fp)

            # åˆ†å­æè¿°ç¬¦ - ä½¿ç”¨å›ºå®šçš„æè¿°ç¬¦åˆ—è¡¨
            desc_values = []
            for desc_name in Descriptors._descList:
                func = desc_name[1]
                try:
                    value = func(mol)
                    if np.isfinite(value):
                        desc_values.append(value)
                    else:
                        desc_values.append(0.0)
                except:
                    desc_values.append(0.0)

            # åˆå¹¶ç‰¹å¾
            combined = np.concatenate([fp_array, np.array(desc_values)])

            # æ£€æŸ¥ç»´åº¦ä¸€è‡´æ€§
            if feature_dim is None:
                feature_dim = len(combined)
            elif len(combined) != feature_dim:
                print(f"âš ï¸ ç‰¹å¾ç»´åº¦ä¸ä¸€è‡´: {len(combined)} vs {feature_dim}")
                continue

            features_list.append(combined)

        if not features_list:
            return np.array([])

        return np.vstack(features_list)

    def get_feature_names(self):
        """è·å–ç‰¹å¾åç§°"""
        # MorganæŒ‡çº¹ä½
        fp_names = [f'Morgan_{i}' for i in range(2048)]

        # æè¿°ç¬¦åç§°
        from rdkit.Chem import Descriptors
        desc_names = [desc[0] for desc in Descriptors._descList]

        return fp_names + desc_names

    def find_models(self, model_filter=None):
        """æŸ¥æ‰¾æ‰€æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹"""
        print("\nğŸ” æœç´¢å·²è®­ç»ƒæ¨¡å‹...")

        models_info = []

        if not self.models_dir.exists():
            print(f"  âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {self.models_dir}")
            return models_info

        # éå†æ‰€æœ‰æ¨¡å‹ç›®å½•
        for model_dir in self.models_dir.iterdir():
            if not model_dir.is_dir():
                continue

            model_name = model_dir.name

            # è¿‡æ»¤æ¨¡å‹
            if model_filter and model_name not in model_filter:
                continue

            # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
            model_files_dir = model_dir / 'models'
            if not model_files_dir.exists():
                continue

            for model_file in model_files_dir.glob('*.joblib'):
                # è§£æç›®æ ‡åç§°
                filename = model_file.stem
                if 'Max_wavelength' in filename:
                    target = 'Max_wavelength(nm)'
                    target_clean = 'Wavelength'
                elif 'PLQY' in filename:
                    target = 'PLQY'
                    target_clean = 'PLQY'
                else:
                    continue

                models_info.append({
                    'model_name': model_name,
                    'model_path': model_file,
                    'target': target,
                    'target_clean': target_clean
                })

        print(f"  âœ… æ‰¾åˆ° {len(models_info)} ä¸ªæ¨¡å‹")
        for info in models_info:
            print(f"     - {info['model_name']:20s} | {info['target_clean']}")

        return models_info

    def analyze_model(self, model_info, sample_size=100):
        """åˆ†æå•ä¸ªæ¨¡å‹"""
        model_name = model_info['model_name']
        target = model_info['target']
        target_clean = model_info['target_clean']

        print(f"\n{'='*70}")
        print(f"ğŸ”¬ åˆ†ææ¨¡å‹: {model_name} - {target_clean}")
        print(f"{'='*70}")

        # åŠ è½½æ¨¡å‹
        try:
            model = joblib.load(model_info['model_path'])
            print(f"  âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"  âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None

        # å‡†å¤‡æ•°æ®
        print(f"  ğŸ“Š å‡†å¤‡ç‰¹å¾æ•°æ®...")
        valid_df = self.df.dropna(subset=[target])
        smiles_cols = ['L1', 'L2', 'L3']

        # åˆå¹¶SMILES
        smiles_combined = valid_df[smiles_cols].apply(
            lambda row: '.'.join(row.values), axis=1
        )

        # æå–ç‰¹å¾
        print(f"     æ­£åœ¨æå–åˆ†å­ç‰¹å¾...")
        X = self.extract_features(smiles_combined.tolist())

        if len(X) == 0:
            print(f"  âŒ ç‰¹å¾æå–å¤±è´¥")
            return None

        print(f"     âœ… ç‰¹å¾ç»´åº¦: {X.shape}")

        # é‡‡æ ·ï¼ˆSHAPè®¡ç®—è¾ƒæ…¢ï¼‰
        if len(X) > sample_size:
            print(f"  âš¡ é‡‡æ · {sample_size} ä¸ªæ ·æœ¬è¿›è¡ŒSHAPåˆ†æ")
            sample_idx = np.random.choice(len(X), sample_size, replace=False)
            X_sample = X[sample_idx]
        else:
            X_sample = X

        # åˆ›å»ºSHAPåˆ†æå™¨
        print(f"  ğŸ§® è®¡ç®—SHAPå€¼...")
        try:
            # ç¡®å®šæ¨¡å‹ç±»å‹
            model_type_map = {
                'xgboost': 'tree',
                'lightgbm': 'tree',
                'catboost': 'tree',
                'random_forest': 'tree',
                'gradient_boosting': 'tree',
                'decision_tree': 'tree',
                'adaboost': 'tree',
                'ridge': 'linear',
                'lasso': 'linear',
                'elastic_net': 'linear'
            }

            shap_model_type = model_type_map.get(model_name, 'kernel')

            # åˆ›å»ºexplainer
            if shap_model_type == 'tree':
                explainer = shap.TreeExplainer(model)
            elif shap_model_type == 'linear':
                explainer = shap.LinearExplainer(model, X_sample)
            else:
                # å¯¹äºå…¶ä»–æ¨¡å‹ï¼Œä½¿ç”¨KernelExplainerï¼ˆè¾ƒæ…¢ï¼‰
                print(f"     âš ï¸ ä½¿ç”¨é€šç”¨Kernelè§£é‡Šå™¨ï¼ˆè¾ƒæ…¢ï¼‰")
                explainer = shap.KernelExplainer(model.predict, shap.sample(X_sample, 50))

            # è®¡ç®—SHAPå€¼
            shap_values = explainer.shap_values(X_sample)

            print(f"     âœ… SHAPå€¼è®¡ç®—å®Œæˆ")

        except Exception as e:
            print(f"  âŒ SHAPåˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

        # åˆ†æç‰¹å¾é‡è¦æ€§
        feature_names = self.get_feature_names()

        # ç¡®ä¿ç‰¹å¾ç»´åº¦åŒ¹é…
        if len(feature_names) > X_sample.shape[1]:
            feature_names = feature_names[:X_sample.shape[1]]
        elif len(feature_names) < X_sample.shape[1]:
            feature_names = feature_names + [f'Feature_{i}' for i in range(len(feature_names), X_sample.shape[1])]

        # è®¡ç®—ç‰¹å¾é‡è¦æ€§
        importance = np.abs(shap_values).mean(axis=0)
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importance
        }).sort_values('importance', ascending=False)

        # ä¿å­˜ç»“æœ
        output_subdir = self.output_dir / model_name / target_clean
        output_subdir.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜ç‰¹å¾é‡è¦æ€§CSV
        csv_path = output_subdir / 'shap_feature_importance.csv'
        importance_df.to_csv(csv_path, index=False)
        print(f"  ğŸ’¾ ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜: {csv_path}")

        # ä¿å­˜Top 30ç‰¹å¾
        top30 = importance_df.head(30)

        # åˆ›å»ºå¯è§†åŒ–
        print(f"  ğŸ“Š ç”Ÿæˆå¯è§†åŒ–...")

        # 1. ç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾
        plt.figure(figsize=(12, 8))
        plt.barh(range(len(top30)), top30['importance'].values)
        plt.yticks(range(len(top30)), top30['feature'].values)
        plt.xlabel('Mean |SHAP value|')
        plt.title(f'Top 30 Feature Importance - {model_name} ({target_clean})')
        plt.gca().invert_yaxis()
        plt.tight_layout()

        fig_path = output_subdir / 'feature_importance_bar.png'
        plt.savefig(fig_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"     âœ… æ¡å½¢å›¾: {fig_path.name}")

        # 2. SHAP summary plot
        try:
            plt.figure(figsize=(12, 8))
            shap.summary_plot(
                shap_values,
                X_sample,
                feature_names=feature_names,
                max_display=30,
                show=False
            )
            summary_path = output_subdir / 'shap_summary_plot.png'
            plt.savefig(summary_path, dpi=150, bbox_inches='tight')
            plt.close()
            print(f"     âœ… Summaryå›¾: {summary_path.name}")
        except Exception as e:
            print(f"     âš ï¸ Summaryå›¾ç”Ÿæˆå¤±è´¥: {e}")

        # ä¿å­˜å…ƒæ•°æ®
        metadata = {
            'model_name': model_name,
            'target': target_clean,
            'sample_size': len(X_sample),
            'n_features': X_sample.shape[1],
            'top_10_features': top30.head(10).to_dict('records'),
            'analysis_time': datetime.now().isoformat()
        }

        json_path = output_subdir / 'shap_metadata.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)

        print(f"  âœ… åˆ†æå®Œæˆ")

        return {
            'model': model_name,
            'target': target_clean,
            'top_features': top30.head(10)
        }

    def generate_summary_report(self, results):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        print(f"\n{'='*70}")
        print(f"ğŸ“ ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š")
        print(f"{'='*70}")

        html = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>SHAPå¯è§£é‡Šæ€§åˆ†ææŠ¥å‘Š</title>
    <style>
        body {{
            font-family: 'Segoe UI', Arial, sans-serif;
            margin: 40px;
            background: #f5f5f5;
        }}
        .container {{
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        h1 {{
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }}
        h2 {{
            color: #34495e;
            margin-top: 30px;
            padding-left: 10px;
            border-left: 4px solid #3498db;
        }}
        .model-section {{
            margin: 30px 0;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 5px;
            border-left: 4px solid #3498db;
        }}
        .model-title {{
            font-size: 20px;
            font-weight: bold;
            color: #2c3e50;
            margin-bottom: 15px;
        }}
        .feature-table {{
            width: 100%;
            border-collapse: collapse;
            margin-top: 15px;
        }}
        .feature-table th {{
            background: #3498db;
            color: white;
            padding: 12px;
            text-align: left;
        }}
        .feature-table td {{
            padding: 10px;
            border-bottom: 1px solid #ddd;
        }}
        .feature-table tr:hover {{
            background: #f0f0f0;
        }}
        .images {{
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-top: 20px;
        }}
        .images img {{
            width: 100%;
            border: 1px solid #ddd;
            border-radius: 5px;
        }}
        .summary-box {{
            background: #e8f4f8;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
        }}
        .file-link {{
            color: #3498db;
            text-decoration: none;
            font-weight: 500;
        }}
        .file-link:hover {{
            text-decoration: underline;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¯ SHAPå¯è§£é‡Šæ€§åˆ†ææŠ¥å‘Š</h1>

        <div class="summary-box">
            <p><strong>ğŸ“… åˆ†ææ—¶é—´:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p><strong>ğŸ“‚ é¡¹ç›®ç›®å½•:</strong> {self.paper_dir.name}</p>
            <p><strong>ğŸ”¬ åˆ†ææ¨¡å‹æ•°:</strong> {len(results)}</p>
            <p><strong>ğŸ’¡ è¯´æ˜:</strong> SHAPå€¼è¡¨ç¤ºæ¯ä¸ªç‰¹å¾å¯¹æ¨¡å‹é¢„æµ‹çš„è´¡çŒ®åº¦ã€‚å€¼è¶Šå¤§è¡¨ç¤ºè¯¥ç‰¹å¾å¯¹é¢„æµ‹ç»“æœå½±å“è¶Šå¤§ã€‚</p>
        </div>

        <h2>ğŸ“Š åˆ†æç»“æœ</h2>
"""

        for result in results:
            if result is None:
                continue

            model = result['model']
            target = result['target']
            top_features = result['top_features']

            html += f"""
        <div class="model-section">
            <div class="model-title">ğŸ”¹ {model} - {target}</div>

            <h3>Top 10 é‡è¦ç‰¹å¾</h3>
            <table class="feature-table">
                <thead>
                    <tr>
                        <th>æ’å</th>
                        <th>ç‰¹å¾åç§°</th>
                        <th>é‡è¦æ€§ (Mean |SHAP|)</th>
                    </tr>
                </thead>
                <tbody>
"""

            for idx, row in enumerate(top_features.iterrows(), 1):
                feature = row[1]['feature']
                importance = row[1]['importance']
                html += f"""
                    <tr>
                        <td>{idx}</td>
                        <td>{feature}</td>
                        <td>{importance:.6f}</td>
                    </tr>
"""

            html += """
                </tbody>
            </table>

            <h3>å¯è§†åŒ–ç»“æœ</h3>
            <div class="images">
"""

            # æ·»åŠ å›¾ç‰‡é“¾æ¥
            img_dir = f"{model}/{target}"
            html += f"""
                <div>
                    <p><strong>ç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾</strong></p>
                    <a href="{img_dir}/feature_importance_bar.png" target="_blank">
                        <img src="{img_dir}/feature_importance_bar.png" alt="Feature Importance">
                    </a>
                </div>
                <div>
                    <p><strong>SHAP Summary Plot</strong></p>
                    <a href="{img_dir}/shap_summary_plot.png" target="_blank">
                        <img src="{img_dir}/shap_summary_plot.png" alt="SHAP Summary">
                    </a>
                </div>
"""

            html += """
            </div>

            <p style="margin-top: 15px;">
                ğŸ“„ <a class="file-link" href="{}/{}/shap_feature_importance.csv">ä¸‹è½½å®Œæ•´ç‰¹å¾é‡è¦æ€§æ•°æ® (CSV)</a> |
                ğŸ“„ <a class="file-link" href="{}/{}/shap_metadata.json">å…ƒæ•°æ® (JSON)</a>
            </p>
        </div>
""".format(model, target, model, target)

        html += """
        <div class="summary-box" style="margin-top: 40px;">
            <h3>ğŸ“– å¦‚ä½•ä½¿ç”¨è¿™äº›ç»“æœ</h3>
            <ol>
                <li><strong>è¯†åˆ«å…³é”®ç‰¹å¾:</strong> Topç‰¹å¾è¡¨æ˜å“ªäº›åˆ†å­æ€§è´¨å¯¹é¢„æµ‹æœ€é‡è¦</li>
                <li><strong>æŒ‡å¯¼åˆ†å­è®¾è®¡:</strong> å…³æ³¨é‡è¦ç‰¹å¾æ¥ä¼˜åŒ–åˆ†å­ç»“æ„</li>
                <li><strong>æ¨¡å‹è¯Šæ–­:</strong> æ£€æŸ¥æ¨¡å‹æ˜¯å¦å…³æ³¨åˆç†çš„åŒ–å­¦ç‰¹å¾</li>
                <li><strong>è®ºæ–‡å†™ä½œ:</strong> åœ¨è®¨è®ºéƒ¨åˆ†è§£é‡Šæ¨¡å‹çš„é¢„æµ‹ä¾æ®</li>
            </ol>
        </div>
    </div>
</body>
</html>
"""

        report_path = self.output_dir / 'shap_report.html'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html)

        print(f"  âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        print(f"  ğŸŒ ç”¨æµè§ˆå™¨æ‰“å¼€æŸ¥çœ‹: file://{report_path.absolute()}")

        return report_path


def main():
    parser = argparse.ArgumentParser(
        description='SHAPå¯è§£é‡Šæ€§åˆ†æå·¥å…· - åˆ†æå·²è®­ç»ƒçš„æ¨¡å‹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
    # åˆ†ææ‰€æœ‰æ¨¡å‹
    python analyze_shap.py Paper_0930_222051

    # åªåˆ†æXGBoostå’ŒLightGBM
    python analyze_shap.py Paper_0930_222051 --models xgboost lightgbm

    # ä½¿ç”¨æ›´å¤§çš„æ ·æœ¬é‡
    python analyze_shap.py Paper_0930_222051 --sample-size 200
        """
    )

    parser.add_argument('paper_dir', help='è®ºæ–‡è¾“å‡ºç›®å½• (å¦‚: Paper_0930_222051)')
    parser.add_argument('--models', nargs='+', help='æŒ‡å®šè¦åˆ†æçš„æ¨¡å‹ (å¦‚: xgboost lightgbm)')
    parser.add_argument('--sample-size', type=int, default=100, help='SHAPåˆ†æçš„æ ·æœ¬æ•°é‡ (é»˜è®¤: 100)')

    args = parser.parse_args()

    print("="*70)
    print("ğŸ¯ SHAPå¯è§£é‡Šæ€§åˆ†æå·¥å…·")
    print("="*70)

    # åˆ›å»ºåˆ†æå™¨
    analyzer = ModelShapAnalyzer(args.paper_dir)

    # æŸ¥æ‰¾æ¨¡å‹
    models = analyzer.find_models(model_filter=args.models)

    if not models:
        print("\nâŒ æœªæ‰¾åˆ°ä»»ä½•æ¨¡å‹æ–‡ä»¶")
        return 1

    # åˆ†ææ¯ä¸ªæ¨¡å‹
    results = []
    for model_info in models:
        result = analyzer.analyze_model(model_info, sample_size=args.sample_size)
        results.append(result)

    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    analyzer.generate_summary_report(results)

    print("\n" + "="*70)
    print("âœ… æ‰€æœ‰åˆ†æå®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {analyzer.output_dir}")
    print("="*70)

    return 0


if __name__ == '__main__':
    sys.exit(main())