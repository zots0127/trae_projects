#!/usr/bin/env python3
"""
æ•°æ®åˆ†æå’Œå¯è§†åŒ–è„šæœ¬ - ç”Ÿæˆè®ºæ–‡å›¾è¡¨
"""

import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime
import argparse
import json
from scipy import stats
from sklearn.metrics import r2_score, mean_absolute_error

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

# è®¾ç½®ç»˜å›¾é£æ ¼
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")

def load_data(data_file):
    """åŠ è½½æ•°æ®"""
    df = pd.read_csv(data_file)
    print(f"âœ… åŠ è½½æ•°æ®: {data_file}")
    print(f"   æ ·æœ¬æ•°: {len(df)}")
    print(f"   ç‰¹å¾æ•°: {len(df.columns)}")
    return df

def plot_wavelength_plqy_scatter(df, output_dir):
    """
    ç»˜åˆ¶æ³¢é•¿-PLQYæ•£ç‚¹å›¾ï¼ˆç±»ä¼¼å›¾cï¼‰
    æŒ‰æº¶å‰‚ç±»å‹ç€è‰²
    """
    fig, ax = plt.subplots(1, 1, figsize=(8, 6))
    
    # å®šä¹‰æº¶å‰‚ç±»å‹å’Œé¢œè‰²
    solvent_colors = {
        'CH2Cl2': '#1f77b4',  # è“è‰²
        'CH3CN': '#2ca02c',   # ç»¿è‰²
        'Toluene': '#ff7f0e',  # æ©™è‰²
        'Others': '#9467bd'    # ç´«è‰²
    }
    
    # æå–æ³¢é•¿å’ŒPLQYæ•°æ®
    wavelength_col = None
    plqy_col = None
    
    for col in df.columns:
        if 'wavelength' in col.lower() or 'max_wavelength' in col.lower():
            wavelength_col = col
        if 'plqy' in col.lower():
            plqy_col = col
    
    if wavelength_col and plqy_col:
        # å¦‚æœæœ‰æº¶å‰‚åˆ—ï¼ŒæŒ‰æº¶å‰‚åˆ†ç»„
        if 'Solvent' in df.columns:
            for solvent, color in solvent_colors.items():
                mask = df['Solvent'] == solvent
                ax.scatter(df.loc[mask, wavelength_col], 
                          df.loc[mask, plqy_col],
                          c=color, label=solvent, alpha=0.6, s=20)
        else:
            # æ²¡æœ‰æº¶å‰‚ä¿¡æ¯ï¼Œä½¿ç”¨å•ä¸€é¢œè‰²
            ax.scatter(df[wavelength_col], df[plqy_col], 
                      alpha=0.6, s=20, c='#1f77b4')
        
        ax.set_xlabel('Wavelength (nm)', fontsize=12)
        ax.set_ylabel('PLQY', fontsize=12)
        ax.set_xlim(440, 880)
        ax.set_ylim(0, 1.0)
        ax.legend(loc='upper right')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        save_path = output_dir / 'wavelength_plqy_scatter.png'
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… ä¿å­˜æ•£ç‚¹å›¾: {save_path}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°æ³¢é•¿æˆ–PLQYåˆ—")

def plot_plqy_distribution(df, output_dir):
    """
    ç»˜åˆ¶PLQYåˆ†å¸ƒç›´æ–¹å›¾ï¼ˆç±»ä¼¼å›¾dï¼‰
    æŒ‰æº¶å‰‚å’ŒPLQYèŒƒå›´åˆ†ç»„
    """
    fig, ax = plt.subplots(1, 1, figsize=(8, 6))
    
    plqy_col = None
    for col in df.columns:
        if 'plqy' in col.lower():
            plqy_col = col
            break
    
    if plqy_col:
        # å®šä¹‰PLQYèŒƒå›´
        bins = [0, 0.1, 0.5, 1.0]
        labels = ['â‰¤0.1', '0.1-0.5', '>0.5']
        
        # å¦‚æœæœ‰æº¶å‰‚ä¿¡æ¯
        if 'Solvent' in df.columns:
            solvent_types = ['CH2Cl2', 'CH3CN', 'Toluene', 'Others']
            colors = ['#1f77b4', '#2ca02c', '#ff7f0e', '#9467bd']
            
            # åˆ›å»ºåˆ†ç»„æ•°æ®
            data_by_range = []
            for i in range(len(bins)-1):
                range_data = []
                for solvent in solvent_types:
                    mask = (df['Solvent'] == solvent) & \
                           (df[plqy_col] > bins[i]) & \
                           (df[plqy_col] <= bins[i+1])
                    range_data.append(mask.sum())
                data_by_range.append(range_data)
            
            # ç»˜åˆ¶å †å æŸ±çŠ¶å›¾
            x = np.arange(len(labels))
            width = 0.6
            bottom = np.zeros(len(labels))
            
            for j, (solvent, color) in enumerate(zip(solvent_types, colors)):
                values = [data_by_range[i][j] for i in range(len(labels))]
                ax.bar(x, values, width, bottom=bottom, label=solvent, color=color)
                bottom += values
        else:
            # ç®€å•ç›´æ–¹å›¾
            df[plqy_col].hist(bins=bins, ax=ax, edgecolor='black')
        
        ax.set_xlabel('PLQY Range', fontsize=12)
        ax.set_ylabel('Number of entries', fontsize=12)
        ax.set_xticks(range(len(labels)))
        ax.set_xticklabels(labels)
        ax.legend(loc='upper right')
        
        plt.tight_layout()
        save_path = output_dir / 'plqy_distribution.png'
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… ä¿å­˜åˆ†å¸ƒå›¾: {save_path}")

def plot_prediction_scatter(df, predictions_file, output_dir):
    """
    ç»˜åˆ¶é¢„æµ‹vså®éªŒæ•£ç‚¹å›¾ï¼ˆç±»ä¼¼å›¾eå’Œfï¼‰
    """
    if not predictions_file or not Path(predictions_file).exists():
        print("âš ï¸ æœªæä¾›é¢„æµ‹æ–‡ä»¶æˆ–æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    # åŠ è½½é¢„æµ‹ç»“æœ
    pred_df = pd.read_csv(predictions_file)
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    
    # æŸ¥æ‰¾æ³¢é•¿å’ŒPLQYçš„é¢„æµ‹åˆ—
    targets = ['wavelength', 'plqy']
    
    for idx, target in enumerate(targets):
        ax = axes[idx]
        
        # æŸ¥æ‰¾ç›¸å…³åˆ—
        exp_col = None
        pred_col = None
        
        for col in pred_df.columns:
            if target in col.lower() and 'experimental' in col.lower():
                exp_col = col
            elif target in col.lower() and 'predicted' in col.lower():
                pred_col = col
        
        if exp_col and pred_col:
            x = pred_df[exp_col].values
            y = pred_df[pred_col].values
            
            # ç§»é™¤NaNå€¼
            mask = ~(np.isnan(x) | np.isnan(y))
            x = x[mask]
            y = y[mask]
            
            # è®¡ç®—æŒ‡æ ‡
            r2 = r2_score(x, y)
            mae = mean_absolute_error(x, y)
            
            # ç»˜åˆ¶æ•£ç‚¹å›¾
            ax.scatter(x, y, alpha=0.5, s=10, c='#1f77b4')
            
            # æ·»åŠ å¯¹è§’çº¿
            min_val = min(x.min(), y.min())
            max_val = max(x.max(), y.max())
            ax.plot([min_val, max_val], [min_val, max_val], 
                   'r--', lw=1, alpha=0.7)
            
            # è®¾ç½®æ ‡ç­¾
            if 'wavelength' in target:
                ax.set_xlabel('Experimental Î»em (nm)', fontsize=12)
                ax.set_ylabel('Predicted Î»em (nm)', fontsize=12)
                title = f'Wavelength Prediction'
            else:
                ax.set_xlabel('Experimental PLQY', fontsize=12)
                ax.set_ylabel('Predicted PLQY', fontsize=12)
                title = f'PLQY Prediction'
            
            # æ·»åŠ æŒ‡æ ‡æ–‡æœ¬
            ax.text(0.05, 0.95, f'MAE = {mae:.2f}\nRÂ² = {r2:.2f}',
                   transform=ax.transAxes, fontsize=11,
                   verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
            
            ax.set_title(title, fontsize=13)
            ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    save_path = output_dir / 'prediction_scatter.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ä¿å­˜é¢„æµ‹æ•£ç‚¹å›¾: {save_path}")

def plot_correlation_matrix(df, output_dir):
    """
    ç»˜åˆ¶ç›¸å…³æ€§çŸ©é˜µï¼ˆç±»ä¼¼å›¾gï¼‰
    """
    # é€‰æ‹©PLQYç›¸å…³çš„æ•°å€¼åˆ—
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    
    # é€‰æ‹©å…³é”®åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    key_cols = []
    for col in numeric_cols:
        if any(keyword in col.lower() for keyword in ['plqy', 'wavelength', 'tau', 'lifetime']):
            key_cols.append(col)
    
    if len(key_cols) < 2:
        key_cols = numeric_cols[:min(10, len(numeric_cols))]  # é€‰æ‹©å‰10ä¸ªæ•°å€¼åˆ—
    
    if len(key_cols) >= 2:
        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = df[key_cols].corr()
        
        # åˆ›å»ºçƒ­å›¾
        fig, ax = plt.subplots(1, 1, figsize=(10, 8))
        
        # ä½¿ç”¨è‡ªå®šä¹‰é¢œè‰²å›¾
        cmap = sns.diverging_palette(240, 10, as_cmap=True)
        
        # ç»˜åˆ¶çƒ­å›¾
        sns.heatmap(corr_matrix, annot=True, fmt='.2f', 
                   cmap=cmap, center=0,
                   square=True, linewidths=1,
                   cbar_kws={"shrink": .8},
                   ax=ax)
        
        ax.set_title('Correlation Matrix', fontsize=14)
        
        plt.tight_layout()
        save_path = output_dir / 'correlation_matrix.png'
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… ä¿å­˜ç›¸å…³æ€§çŸ©é˜µ: {save_path}")

def generate_summary_stats(df, output_dir):
    """ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡"""
    stats = {}
    
    # åŸºæœ¬ç»Ÿè®¡
    stats['total_samples'] = len(df)
    stats['total_features'] = len(df.columns)
    
    # PLQYç»Ÿè®¡
    plqy_col = None
    for col in df.columns:
        if 'plqy' in col.lower():
            plqy_col = col
            break
    
    if plqy_col:
        stats['plqy'] = {
            'mean': df[plqy_col].mean(),
            'std': df[plqy_col].std(),
            'min': df[plqy_col].min(),
            'max': df[plqy_col].max(),
            'median': df[plqy_col].median()
        }
    
    # æ³¢é•¿ç»Ÿè®¡
    wavelength_col = None
    for col in df.columns:
        if 'wavelength' in col.lower():
            wavelength_col = col
            break
    
    if wavelength_col:
        stats['wavelength'] = {
            'mean': df[wavelength_col].mean(),
            'std': df[wavelength_col].std(),
            'min': df[wavelength_col].min(),
            'max': df[wavelength_col].max(),
            'median': df[wavelength_col].median()
        }
    
    # ä¿å­˜ç»Ÿè®¡
    stats_file = output_dir / 'summary_stats.json'
    with open(stats_file, 'w') as f:
        json.dump(stats, f, indent=2)
    
    print(f"âœ… ä¿å­˜ç»Ÿè®¡ä¿¡æ¯: {stats_file}")
    
    # æ‰“å°ç»Ÿè®¡æ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ“Š æ•°æ®ç»Ÿè®¡æ‘˜è¦")
    print("=" * 60)
    print(f"æ ·æœ¬æ€»æ•°: {stats['total_samples']}")
    
    if 'plqy' in stats:
        print(f"\nPLQYç»Ÿè®¡:")
        print(f"  å‡å€¼: {stats['plqy']['mean']:.3f}")
        print(f"  æ ‡å‡†å·®: {stats['plqy']['std']:.3f}")
        print(f"  èŒƒå›´: [{stats['plqy']['min']:.3f}, {stats['plqy']['max']:.3f}]")
    
    if 'wavelength' in stats:
        print(f"\næ³¢é•¿ç»Ÿè®¡:")
        print(f"  å‡å€¼: {stats['wavelength']['mean']:.1f} nm")
        print(f"  æ ‡å‡†å·®: {stats['wavelength']['std']:.1f} nm")
        print(f"  èŒƒå›´: [{stats['wavelength']['min']:.1f}, {stats['wavelength']['max']:.1f}] nm")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ•°æ®åˆ†æå’Œå¯è§†åŒ–')
    
    parser.add_argument('--data', '-d', required=True,
                       help='æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--predictions', '-p',
                       help='é¢„æµ‹ç»“æœæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--output', '-o',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--plots', nargs='+',
                       choices=['scatter', 'distribution', 'prediction', 'correlation', 'all'],
                       default=['all'],
                       help='è¦ç”Ÿæˆçš„å›¾è¡¨ç±»å‹')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    if args.output:
        output_dir = Path(args.output)
    else:
        output_dir = Path(f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
    
    output_dir.mkdir(exist_ok=True, parents=True)
    
    print("=" * 60)
    print("æ•°æ®åˆ†æå’Œå¯è§†åŒ–")
    print("=" * 60)
    print(f"æ•°æ®æ–‡ä»¶: {args.data}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    # åŠ è½½æ•°æ®
    df = load_data(args.data)
    
    # ç”Ÿæˆå›¾è¡¨
    if 'all' in args.plots or 'scatter' in args.plots:
        plot_wavelength_plqy_scatter(df, output_dir)
    
    if 'all' in args.plots or 'distribution' in args.plots:
        plot_plqy_distribution(df, output_dir)
    
    if 'all' in args.plots or 'prediction' in args.plots:
        if args.predictions:
            plot_prediction_scatter(df, args.predictions, output_dir)
    
    if 'all' in args.plots or 'correlation' in args.plots:
        plot_correlation_matrix(df, output_dir)
    
    # ç”Ÿæˆç»Ÿè®¡æ‘˜è¦
    generate_summary_stats(df, output_dir)
    
    print("\n" + "=" * 60)
    print("âœ… åˆ†æå®Œæˆï¼")
    print(f"ç»“æœä¿å­˜åœ¨: {output_dir}")
    print("=" * 60)

if __name__ == "__main__":
    main()