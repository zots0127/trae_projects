#!/usr/bin/env python3
"""
ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æ‰€æœ‰ç»„åˆè¿›è¡Œå®Œæ•´é¢„æµ‹
æ˜¾ç¤ºè¯¦ç»†è¿›åº¦ï¼Œä¸é™åˆ¶è¾“å‡ºæ•°é‡
"""

import pandas as pd
import numpy as np
import joblib
from pathlib import Path
import argparse
from datetime import datetime
import time
import sys
import json
import platform
import subprocess
import psutil
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.feature_extractor import FeatureExtractor

# å…¨å±€æ€§èƒ½è®°å½•
performance_stats = {
    'start_time': None,
    'end_time': None,
    'steps': [],
    'hardware_info': {}
}

def get_hardware_info():
    """è·å–ç¡¬ä»¶ä¿¡æ¯"""
    info = {}
    
    # åŸºæœ¬ç³»ç»Ÿä¿¡æ¯
    info['æ“ä½œç³»ç»Ÿ'] = platform.system()
    info['ç³»ç»Ÿç‰ˆæœ¬'] = platform.version()
    info['æœºå™¨æ¶æ„'] = platform.machine()
    info['å¤„ç†å™¨'] = platform.processor()
    info['Pythonç‰ˆæœ¬'] = platform.python_version()
    
    # CPUä¿¡æ¯
    try:
        info['CPUç‰©ç†æ ¸å¿ƒæ•°'] = psutil.cpu_count(logical=False)
        info['CPUé€»è¾‘æ ¸å¿ƒæ•°'] = psutil.cpu_count(logical=True)
        info['CPUä½¿ç”¨ç‡'] = f"{psutil.cpu_percent(interval=1)}%"
    except:
        pass
    
    # å†…å­˜ä¿¡æ¯
    try:
        mem = psutil.virtual_memory()
        info['æ€»å†…å­˜'] = f"{mem.total / (1024**3):.1f} GB"
        info['å¯ç”¨å†…å­˜'] = f"{mem.available / (1024**3):.1f} GB"
        info['å†…å­˜ä½¿ç”¨ç‡'] = f"{mem.percent}%"
    except:
        pass
    
    # macOSç‰¹å®šä¿¡æ¯
    if platform.system() == 'Darwin':
        try:
            # è·å–Macå‹å·
            result = subprocess.run(['sysctl', '-n', 'hw.model'], 
                                 capture_output=True, text=True)
            if result.returncode == 0:
                info['Macå‹å·'] = result.stdout.strip()
            
            # è·å–èŠ¯ç‰‡ä¿¡æ¯
            result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                 capture_output=True, text=True)
            if result.returncode == 0:
                info['CPUå‹å·'] = result.stdout.strip()
        except:
            pass
    
    return info

def load_models(project_dir, model_name='xgboost', use_intersection=False):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    
    Args:
        project_dir: é¡¹ç›®ç›®å½•
        model_name: æ¨¡å‹åç§°
        use_intersection: æ˜¯å¦ä½¿ç”¨äº¤é›†è®­ç»ƒçš„æ¨¡å‹
    """
    step_start = time.time()
    print("\n" + "="*80)
    print("æ­¥éª¤1: åŠ è½½æ¨¡å‹")
    print("-"*80)
    
    models = {}
    
    # å°è¯•å¤šç§å¯èƒ½çš„æ¨¡å‹è·¯å¾„
    possible_paths = [
        # AutoML è®­ç»ƒè·¯å¾„
        Path(project_dir) / 'all_models' / 'automl_train' / model_name / 'models',
        Path(project_dir) / '*' / 'automl_train' / model_name / 'models',
        # æ ‡å‡†è·¯å¾„
        Path(project_dir) / model_name / 'models',
        Path(project_dir) / 'models' / model_name,
    ]
    
    # æ ¹æ®æ˜¯å¦ä½¿ç”¨äº¤é›†é€‰æ‹©æ¨¡å‹ç›®å½•
    if use_intersection:
        # äº¤é›†è®­ç»ƒçš„æ¨¡å‹é€šå¸¸åœ¨ intersection å­ç›®å½•
        possible_paths.extend([
            Path(project_dir) / model_name / 'intersection' / f'{model_name}_intersection' / 'models',
            Path(project_dir) / model_name / 'intersection' / 'models',
        ])
    
    # æŸ¥æ‰¾å­˜åœ¨çš„æ¨¡å‹ç›®å½•
    model_dir = None
    for path in possible_paths:
        if '*' in str(path):
            # å¤„ç†é€šé…ç¬¦è·¯å¾„
            matches = list(Path(project_dir).glob(str(path.relative_to(Path(project_dir)))))
            if matches:
                model_dir = matches[0]
                break
        elif path.exists():
            model_dir = path
            break
    
    if model_dir is None:
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {project_dir}/{model_name}/models")
        print(f"  å°è¯•è¿‡çš„è·¯å¾„:")
        for path in possible_paths[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªä¸»è¦è·¯å¾„
            print(f"    â€¢ {path}")
        return models
    
    print(f"  ğŸ“ æ‰¾åˆ°æ¨¡å‹ç›®å½•: {model_dir}")
    if 'automl_train' in str(model_dir):
        print(f"  ğŸ“Œ ä½¿ç”¨AutoMLè®­ç»ƒçš„æ¨¡å‹")
    elif 'intersection' in str(model_dir):
        print(f"  ğŸ“Œ ä½¿ç”¨äº¤é›†è®­ç»ƒæ¨¡å‹")
    else:
        print(f"  ğŸ“Œ ä½¿ç”¨æ ‡å‡†è®­ç»ƒæ¨¡å‹")
    
    print(f"  ğŸ“ æ¨¡å‹ç›®å½•: {model_dir}")
    
    # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶ï¼ˆåªåŠ è½½wavelengthå’ŒPLQYï¼‰
    for model_file in model_dir.glob("*.joblib"):
        filename = model_file.stem
        if 'wavelength' in filename.lower():
            models['wavelength'] = joblib.load(model_file)
            print(f"  âœ… æ³¢é•¿æ¨¡å‹: {model_file.name}")
        elif 'plqy' in filename.lower():
            models['PLQY'] = joblib.load(model_file)
            print(f"  âœ… PLQYæ¨¡å‹: {model_file.name}")
        # è·³è¿‡tauæ¨¡å‹
    
    print(f"\næˆåŠŸåŠ è½½ {len(models)} ä¸ªæ¨¡å‹")
    
    step_time = time.time() - step_start
    performance_stats['steps'].append({
        'name': 'æ¨¡å‹åŠ è½½',
        'time_seconds': step_time,
        'details': f'åŠ è½½{len(models)}ä¸ªæ¨¡å‹'
    })
    return models

def extract_features_batch(df, feature_type='combined', batch_size=1000):
    """æ‰¹é‡æå–ç‰¹å¾ï¼Œæ˜¾ç¤ºè¯¦ç»†è¿›åº¦"""
    step_start = time.time()
    print("\n" + "="*80)
    print("æ­¥éª¤2: ç‰¹å¾æå–")
    print("-"*80)
    print(f"é…ç½®:")
    print(f"  â€¢ ç‰¹å¾ç±»å‹: {feature_type}")
    print(f"  â€¢ æ‰¹å¤„ç†å¤§å°: {batch_size:,}")
    print(f"  â€¢ æ€»æ ·æœ¬æ•°: {len(df):,}")
    print("\nå¼€å§‹æå–...")
    
    extractor = FeatureExtractor(
        feature_type=feature_type,
        morgan_radius=2,
        morgan_bits=1024,
        use_cache=True
    )
    
    n_samples = len(df)
    features_list = []
    valid_indices = []
    failed_count = 0
    
    start_time = time.time()
    
    for i in range(0, n_samples, batch_size):
        batch_start_time = time.time()
        batch_end = min(i + batch_size, n_samples)
        batch_df = df.iloc[i:batch_end]
        
        batch_valid = 0
        for idx, row in batch_df.iterrows():
            try:
                # æå–ç»„åˆç‰¹å¾
                smiles_list = [row['L1'], row['L2'], row['L3']]
                features = extractor.extract_combination(smiles_list)
                
                if features is not None:
                    features_list.append(features)
                    valid_indices.append(idx)
                    batch_valid += 1
                else:
                    failed_count += 1
            except Exception as e:
                failed_count += 1
                continue
        
        # è®¡ç®—é€Ÿåº¦å’Œå‰©ä½™æ—¶é—´
        batch_time = time.time() - batch_start_time
        elapsed_time = time.time() - start_time
        processed = batch_end
        rate = processed / elapsed_time if elapsed_time > 0 else 0
        remaining = (n_samples - processed) / rate if rate > 0 else 0
        
        # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯1000ä¸ªæ ·æœ¬æˆ–æ¯10ä¸ªæ‰¹æ¬¡æ˜¾ç¤ºä¸€æ¬¡ï¼‰
        if i % (batch_size * 10) == 0 or batch_end == n_samples:
            print(f"\r  è¿›åº¦: {processed:,}/{n_samples:,} ({100*processed/n_samples:.1f}%) | "
                  f"æˆåŠŸ: {len(valid_indices):,} | å¤±è´¥: {failed_count:,} | "
                  f"é€Ÿåº¦: {rate:.0f} samples/s | "
                  f"å‰©ä½™æ—¶é—´: {remaining/60:.1f} min", end='', flush=True)
    
    print()  # æ¢è¡Œ
    
    total_time = time.time() - start_time
    if features_list:
        X = np.vstack(features_list)
        df_valid = df.iloc[valid_indices].reset_index(drop=True)
        print(f"\nâœ… ç‰¹å¾æå–å®Œæˆ:")
        print(f"  â€¢ æˆåŠŸ: {len(X):,} ä¸ªæ ·æœ¬")
        print(f"  â€¢ å¤±è´¥: {failed_count:,} ä¸ªæ ·æœ¬")
        print(f"  â€¢ æˆåŠŸç‡: {100*len(X)/n_samples:.1f}%")
        print(f"  â€¢ æ€»ç”¨æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
        print(f"  â€¢ å¹³å‡é€Ÿåº¦: {n_samples/total_time:.0f} samples/s")
        
        step_time = time.time() - step_start
        performance_stats['steps'].append({
            'name': 'ç‰¹å¾æå–',
            'time_seconds': step_time,
            'samples_processed': n_samples,
            'samples_success': len(X),
            'samples_failed': failed_count,
            'speed_samples_per_sec': n_samples/total_time,
            'details': f'{len(X):,}/{n_samples:,}æ ·æœ¬æˆåŠŸ'
        })
        return X, df_valid
    else:
        print(f"\nâŒ ç‰¹å¾æå–å¤±è´¥ï¼Œæ²¡æœ‰æœ‰æ•ˆçš„ç‰¹å¾")
        return None, None

def predict_batch(models, X, df_valid, batch_size=10000):
    """æ‰¹é‡é¢„æµ‹ï¼Œæ˜¾ç¤ºè¯¦ç»†è¿›åº¦"""
    step_start = time.time()
    print("\n" + "="*80)
    print("æ­¥éª¤3: æ‰¹é‡é¢„æµ‹")
    print("-"*80)
    print(f"é…ç½®:")
    print(f"  â€¢ æ ·æœ¬æ•°: {len(X):,}")
    print(f"  â€¢ æ‰¹å¤§å°: {batch_size:,}")
    print(f"  â€¢ æ¨¡å‹æ•°: {len(models)}")
    
    predictions = {}
    target_times = {}
    
    # é¢„æµ‹æ¯ä¸ªç›®æ ‡
    for target_idx, (target, model) in enumerate(models.items(), 1):
        print(f"\né¢„æµ‹ç›®æ ‡ {target_idx}/{len(models)}: {target}")
        
        n_samples = len(X)
        preds = []
        
        start_time = time.time()
        
        for i in range(0, n_samples, batch_size):
            batch_end = min(i + batch_size, n_samples)
            batch_X = X[i:batch_end]
            batch_pred = model.predict(batch_X)
            preds.append(batch_pred)
            
            # è®¡ç®—è¿›åº¦
            elapsed = time.time() - start_time
            rate = batch_end / elapsed if elapsed > 0 else 0
            remaining = (n_samples - batch_end) / rate if rate > 0 else 0
            
            # æ˜¾ç¤ºè¿›åº¦
            print(f"\r  è¿›åº¦: {batch_end:,}/{n_samples:,} ({100*batch_end/n_samples:.1f}%) | "
                  f"é€Ÿåº¦: {rate:.0f} samples/s | "
                  f"å‰©ä½™: {remaining:.0f}s", end='', flush=True)
        
        predictions[target] = np.concatenate(preds)
        
        # è®°å½•æ—¶é—´ï¼ˆæé«˜ç²¾åº¦ï¼‰
        target_time = time.time() - start_time
        target_times[target] = target_time
        
        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\n  âœ… å®Œæˆ: {target}")
        print(f"    â€¢ æœ€å°å€¼: {predictions[target].min():.6f}")
        print(f"    â€¢ æœ€å¤§å€¼: {predictions[target].max():.6f}")
        print(f"    â€¢ å¹³å‡å€¼: {predictions[target].mean():.6f}")
        print(f"    â€¢ æ ‡å‡†å·®: {predictions[target].std():.6f}")
        print(f"    â€¢ ç”¨æ—¶: {target_time:.3f}ç§’")
        print(f"    â€¢ é€Ÿåº¦: {n_samples/target_time:.0f} samples/s")
    
    # æ·»åŠ é¢„æµ‹åˆ°DataFrame
    print("\næ·»åŠ é¢„æµ‹ç»“æœåˆ°æ•°æ®æ¡†...")
    if 'wavelength' in predictions:
        df_valid['Predicted_wavelength'] = predictions['wavelength']
    if 'PLQY' in predictions:
        df_valid['Predicted_PLQY'] = predictions['PLQY']
    
    step_time = time.time() - step_start
    prediction_speed = len(X) / step_time if step_time > 0 else 0
    
    performance_stats['steps'].append({
        'name': 'æ‰¹é‡é¢„æµ‹',
        'time_seconds': step_time,
        'samples': len(X),
        'models': len(models),
        'prediction_speed_samples_per_sec': prediction_speed,
        'target_times': target_times,
        'details': f'é¢„æµ‹{len(models)}ä¸ªç›®æ ‡ï¼Œé€Ÿåº¦: {prediction_speed:.0f} samples/s'
    })
    
    return df_valid

def analyze_results(df):
    """åˆ†æé¢„æµ‹ç»“æœ"""
    print("\n" + "="*80)
    print("æ­¥éª¤4: ç»“æœåˆ†æ")
    print("-"*80)
    
    if 'Predicted_PLQY' in df.columns:
        print("\nğŸ“Š PLQYåˆ†å¸ƒ:")
        plqy = df['Predicted_PLQY']
        print(f"  â€¢ æœ€å°å€¼: {plqy.min():.4f}")
        print(f"  â€¢ 25åˆ†ä½: {plqy.quantile(0.25):.4f}")
        print(f"  â€¢ ä¸­ä½æ•°: {plqy.median():.4f}")
        print(f"  â€¢ 75åˆ†ä½: {plqy.quantile(0.75):.4f}")
        print(f"  â€¢ æœ€å¤§å€¼: {plqy.max():.4f}")
        print(f"  â€¢ å¹³å‡å€¼: {plqy.mean():.4f}")
        print(f"  â€¢ æ ‡å‡†å·®: {plqy.std():.4f}")
        
        # PLQYèŒƒå›´åˆ†å¸ƒ
        print("\n  PLQYèŒƒå›´åˆ†å¸ƒ:")
        ranges = [
            (0.9, 1.0, "0.9-1.0"),
            (0.8, 0.9, "0.8-0.9"),
            (0.7, 0.8, "0.7-0.8"),
            (0.6, 0.7, "0.6-0.7"),
            (0.5, 0.6, "0.5-0.6"),
            (0.0, 0.5, "0.0-0.5")
        ]
        for min_val, max_val, label in ranges:
            count = ((plqy >= min_val) & (plqy < max_val)).sum()
            pct = 100 * count / len(plqy)
            print(f"    {label}: {count:,} ({pct:.1f}%)")
        
        # Top 10 PLQY
        print("\nğŸ† Top 10 PLQYç»„åˆ:")
        top10 = df.nlargest(10, 'Predicted_PLQY')
        for i, (idx, row) in enumerate(top10.iterrows(), 1):
            print(f"\n  #{i}:")
            print(f"    PLQY: {row['Predicted_PLQY']:.4f}")
            if 'Predicted_wavelength' in df.columns:
                print(f"    æ³¢é•¿: {row['Predicted_wavelength']:.1f} nm")
            if i <= 3:  # æ˜¾ç¤ºå‰3ä¸ªçš„SMILES
                print(f"    L1/L2: {row['L1'][:60]}...")
                print(f"    L3: {row['L3'][:60]}...")
    
    if 'Predicted_wavelength' in df.columns:
        print("\nğŸ“Š æ³¢é•¿åˆ†å¸ƒ:")
        wl = df['Predicted_wavelength']
        print(f"  â€¢ æœ€å°å€¼: {wl.min():.1f} nm")
        print(f"  â€¢ 25åˆ†ä½: {wl.quantile(0.25):.1f} nm")
        print(f"  â€¢ ä¸­ä½æ•°: {wl.median():.1f} nm")
        print(f"  â€¢ 75åˆ†ä½: {wl.quantile(0.75):.1f} nm")
        print(f"  â€¢ æœ€å¤§å€¼: {wl.max():.1f} nm")
        print(f"  â€¢ å¹³å‡å€¼: {wl.mean():.1f} nm")

def save_performance_stats(output_dir):
    """ä¿å­˜æ€§èƒ½ç»Ÿè®¡è¡¨æ ¼"""
    print("\nä¿å­˜æ€§èƒ½ç»Ÿè®¡...")
    
    # åˆ›å»ºæ€§èƒ½ç»Ÿè®¡è¡¨æ ¼
    perf_data = []
    for step in performance_stats['steps']:
        row = {
            'æ­¥éª¤': step['name'],
            'è€—æ—¶(ç§’)': f"{step['time_seconds']:.3f}",
            'è€—æ—¶(åˆ†é’Ÿ)': f"{step['time_seconds']/60:.3f}",
            'è¯¦ç»†ä¿¡æ¯': step['details']
        }
        
        # æ·»åŠ é¢å¤–ä¿¡æ¯ - ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æœ‰å€¼
        if 'samples_processed' in step:
            row['å¤„ç†æ ·æœ¬æ•°'] = f"{step['samples_processed']:,}"
            row['æˆåŠŸæ ·æœ¬æ•°'] = f"{step['samples_success']:,}"
            row['å¤±è´¥æ ·æœ¬æ•°'] = f"{step['samples_failed']:,}"
            row['é€Ÿåº¦(æ ·æœ¬/ç§’)'] = f"{step['speed_samples_per_sec']:.0f}"
        elif 'samples' in step:  # æ‰¹é‡é¢„æµ‹æ­¥éª¤
            row['å¤„ç†æ ·æœ¬æ•°'] = f"{step['samples']:,}"
            row['æˆåŠŸæ ·æœ¬æ•°'] = f"{step['samples']:,}"
            row['å¤±è´¥æ ·æœ¬æ•°'] = '0'
            if 'prediction_speed_samples_per_sec' in step:
                row['é€Ÿåº¦(æ ·æœ¬/ç§’)'] = f"{step['prediction_speed_samples_per_sec']:.0f}"
            else:
                row['é€Ÿåº¦(æ ·æœ¬/ç§’)'] = '-'
        else:
            row['å¤„ç†æ ·æœ¬æ•°'] = '-'
            row['æˆåŠŸæ ·æœ¬æ•°'] = '-'
            row['å¤±è´¥æ ·æœ¬æ•°'] = '-'
            row['é€Ÿåº¦(æ ·æœ¬/ç§’)'] = '-'
        
        if 'target_times' in step:
            for target, t in step['target_times'].items():
                row[f'{target}é¢„æµ‹æ—¶é—´(ç§’)'] = f"{t:.3f}"
        
        perf_data.append(row)
    
    # æ·»åŠ æ€»è®¡è¡Œ
    total_time = performance_stats['end_time'] - performance_stats['start_time']
    perf_data.append({
        'æ­¥éª¤': 'æ€»è®¡',
        'è€—æ—¶(ç§’)': f"{total_time:.3f}",
        'è€—æ—¶(åˆ†é’Ÿ)': f"{total_time/60:.3f}",
        'è¯¦ç»†ä¿¡æ¯': f"å®Œæˆ{len(performance_stats['steps'])}ä¸ªæ­¥éª¤",
        'å¤„ç†æ ·æœ¬æ•°': '-',
        'æˆåŠŸæ ·æœ¬æ•°': '-',
        'å¤±è´¥æ ·æœ¬æ•°': '-',
        'é€Ÿåº¦(æ ·æœ¬/ç§’)': '-'
    })
    
    # ä¿å­˜ä¸ºCSV
    perf_df = pd.DataFrame(perf_data)
    perf_file = Path(output_dir) / 'performance_statistics.csv'
    perf_df.to_csv(perf_file, index=False, encoding='utf-8-sig')
    print(f"  âœ… æ€§èƒ½ç»Ÿè®¡: {perf_file}")
    
    # ä¿å­˜ç¡¬ä»¶ä¿¡æ¯
    hardware_df = pd.DataFrame([performance_stats['hardware_info']])
    hardware_file = Path(output_dir) / 'hardware_info.csv'
    hardware_df.to_csv(hardware_file, index=False, encoding='utf-8-sig')
    print(f"  âœ… ç¡¬ä»¶ä¿¡æ¯: {hardware_file}")
    
    # ä¿å­˜ä¸ºJSON
    json_file = Path(output_dir) / 'performance_statistics.json'
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(performance_stats, f, ensure_ascii=False, indent=2)
    print(f"  âœ… è¯¦ç»†ç»Ÿè®¡: {json_file}")
    
    # æ‰“å°æ€§èƒ½è¡¨æ ¼
    print("\næ€§èƒ½ç»Ÿè®¡æ±‡æ€»:")
    print("-" * 80)
    print(perf_df.to_string(index=False))
    print("-" * 80)
    
    # æ‰“å°ç¡¬ä»¶ä¿¡æ¯
    print("\nç¡¬ä»¶é…ç½®:")
    print("-" * 80)
    for key, value in performance_stats['hardware_info'].items():
        print(f"{key:20s}: {value}")
    print("-" * 80)
    
    # æ‰“å°æ€§èƒ½æ‘˜è¦
    print("\n" + "="*80)
    print("ğŸš€ æ€§èƒ½æŒ‡æ ‡æ‘˜è¦")
    print("="*80)
    
    # æå–å…³é”®æ€§èƒ½æ•°æ®
    feature_speed = 0
    prediction_speed = 0
    total_samples = 0
    
    for step in performance_stats['steps']:
        if step['name'] == 'ç‰¹å¾æå–' and 'speed_samples_per_sec' in step:
            feature_speed = step['speed_samples_per_sec']
            total_samples = step.get('samples_processed', 0)
        elif step['name'] == 'æ‰¹é‡é¢„æµ‹' and 'prediction_speed_samples_per_sec' in step:
            prediction_speed = step['prediction_speed_samples_per_sec']
            if total_samples == 0:
                total_samples = step.get('samples', 0)
    
    total_time = performance_stats['end_time'] - performance_stats['start_time']
    end_to_end_speed = total_samples / total_time if total_time > 0 else 0
    
    print(f"  ğŸ“Š å¤„ç†æ ·æœ¬æ•°: {total_samples:,}")
    print(f"  â±ï¸  æ€»è€—æ—¶: {total_time:.1f}ç§’ ({total_time/60:.2f}åˆ†é’Ÿ)")
    print(f"  ğŸ”¬ ç‰¹å¾æå–é€Ÿåº¦: {feature_speed:,.0f} samples/s")
    print(f"  ğŸ¯ æ¨¡å‹é¢„æµ‹é€Ÿåº¦: {prediction_speed:,.0f} samples/s")
    print(f"  ğŸ ç«¯åˆ°ç«¯é€Ÿåº¦: {end_to_end_speed:,.0f} samples/s")
    
    if prediction_speed > 100000:
        print(f"  âš¡ è¶…é«˜é€Ÿé¢„æµ‹: {prediction_speed/1000:.0f}K samples/s!")
    
    print("="*80)
    
    # ä¿å­˜è¯¦ç»†æ€§èƒ½æŠ¥å‘Š
    performance_report = {
        'summary': {
            'total_samples': total_samples,
            'total_time_seconds': total_time,
            'feature_extraction_speed': feature_speed,
            'prediction_speed': prediction_speed,
            'end_to_end_speed': end_to_end_speed
        },
        'steps': performance_stats['steps'],
        'hardware': performance_stats['hardware_info']
    }
    
    report_file = Path(output_dir) / 'performance_detailed.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(performance_report, f, ensure_ascii=False, indent=2)
    print(f"\n  âœ… è¯¦ç»†æ€§èƒ½æŠ¥å‘Š: {report_file}")
    
    return perf_df

def save_results(df, output_file):
    """ä¿å­˜ç»“æœï¼ŒåŒ…æ‹¬æ’åºç‰ˆæœ¬"""
    step_start = time.time()
    print("\n" + "="*80)
    print("æ­¥éª¤5: ä¿å­˜ç»“æœ")
    print("-"*80)
    
    # ä¿å­˜å®Œæ•´ç»“æœ
    print(f"\nä¿å­˜å®Œæ•´é¢„æµ‹ç»“æœ...")
    df.to_csv(output_file, index=False)
    print(f"  âœ… æ–‡ä»¶: {output_file}")
    print(f"  âœ… è¡Œæ•°: {len(df):,}")
    
    # æŒ‰PLQYæ’åºä¿å­˜
    if 'Predicted_PLQY' in df.columns:
        sorted_file = output_file.replace('.csv', '_sorted_by_plqy.csv')
        df_sorted = df.sort_values('Predicted_PLQY', ascending=False)
        df_sorted.to_csv(sorted_file, index=False)
        print(f"  âœ… PLQYæ’åºç‰ˆ: {sorted_file}")
        
        # ä¿å­˜ä¸åŒé˜ˆå€¼çš„ç­›é€‰ç»“æœ
        thresholds = [0.9, 0.8, 0.7]
        for threshold in thresholds:
            filtered = df[df['Predicted_PLQY'] >= threshold]
            if len(filtered) > 0:
                threshold_file = output_file.replace('.csv', f'_plqy_{threshold:.1f}+.csv')
                filtered.to_csv(threshold_file, index=False)
                print(f"  âœ… PLQYâ‰¥{threshold}: {threshold_file} ({len(filtered):,} ä¸ª)")
    
    step_time = time.time() - step_start
    performance_stats['steps'].append({
        'name': 'ç»“æœä¿å­˜',
        'time_seconds': step_time,
        'details': f'ä¿å­˜{len(df):,}æ¡é¢„æµ‹ç»“æœ'
    })

def main():
    parser = argparse.ArgumentParser(description='é¢„æµ‹æ‰€æœ‰ç»„åˆæ€§è´¨')
    parser.add_argument('--project', '-p',
                       help='æ¨¡å‹é¡¹ç›®ç›®å½• (å¦‚: paper_table_20250912_123547)')
    parser.add_argument('--input', '-i', 
                       help='ç»„åˆæ–‡ä»¶ (é»˜è®¤: PROJECT/ir_assemble.csv)')
    parser.add_argument('--output', '-o',
                       help='è¾“å‡ºæ–‡ä»¶ (é»˜è®¤: PROJECT/ir_assemble_predicted_all.csv)')
    parser.add_argument('--intersection', action='store_true',
                       help='ä½¿ç”¨äº¤é›†è®­ç»ƒçš„æ¨¡å‹ï¼ˆåªç”¨ä¸‰ä¸ªç›®æ ‡éƒ½æœ‰å€¼çš„æ•°æ®è®­ç»ƒï¼‰')
    parser.add_argument('--batch-size', type=int, default=1000,
                       help='ç‰¹å¾æå–æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--predict-batch', type=int, default=10000,
                       help='é¢„æµ‹æ‰¹å¤„ç†å¤§å°')
    
    args = parser.parse_args()
    
    # è‡ªåŠ¨æ£€æµ‹æœ€æ–°çš„é¡¹ç›®ç›®å½•
    if not args.project:
        # æŸ¥æ‰¾æœ€æ–°çš„paper_tableç›®å½•
        import glob
        project_dirs = sorted(glob.glob('paper_table_*'))
        if project_dirs:
            args.project = project_dirs[-1]  # ä½¿ç”¨æœ€æ–°çš„
            print(f"è‡ªåŠ¨é€‰æ‹©æœ€æ–°é¡¹ç›®ç›®å½•: {args.project}")
        else:
            print("âŒ æœªæ‰¾åˆ°é¡¹ç›®ç›®å½•ï¼Œè¯·ä½¿ç”¨ --project æŒ‡å®š")
            return
    
    # è®¾ç½®é»˜è®¤è¾“å…¥è¾“å‡ºè·¯å¾„
    if not args.input:
        args.input = f"{args.project}/ir_assemble.csv"
    if not args.output:
        if args.intersection:
            args.output = f"{args.project}/ir_assemble_predicted_intersection.csv"
        else:
            args.output = f"{args.project}/ir_assemble_predicted_all.csv"
    
    print("="*80)
    print("å®Œæ•´é¢„æµ‹æµç¨‹ - 272,104ä¸ªç»„åˆ")
    print("="*80)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"\né…ç½®:")
    print(f"  â€¢ é¡¹ç›®ç›®å½•: {args.project}")
    print(f"  â€¢ æ¨¡å‹ç±»å‹: {'äº¤é›†è®­ç»ƒæ¨¡å‹' if args.intersection else 'å®Œæ•´æ•°æ®è®­ç»ƒæ¨¡å‹'}")
    print(f"  â€¢ è¾“å…¥æ–‡ä»¶: {args.input}")
    print(f"  â€¢ è¾“å‡ºæ–‡ä»¶: {args.output}")
    
    # è®°å½•å¼€å§‹æ—¶é—´å’Œç¡¬ä»¶ä¿¡æ¯
    performance_stats['start_time'] = time.time()
    performance_stats['hardware_info'] = get_hardware_info()
    total_start = time.time()
    
    # æ˜¾ç¤ºç¡¬ä»¶ä¿¡æ¯
    print("\nç¡¬ä»¶é…ç½®:")
    for key, value in performance_stats['hardware_info'].items():
        print(f"  â€¢ {key}: {value}")
    
    # 1. åŠ è½½ç»„åˆ
    print(f"\nåŠ è½½ç»„åˆæ–‡ä»¶...")
    df = pd.read_csv(args.input)
    print(f"  âœ… åŠ è½½ {len(df):,} ä¸ªç»„åˆ")
    
    # éªŒè¯L1=L2
    same_count = (df['L1'] == df['L2']).sum()
    print(f"  âœ… L1=L2éªŒè¯: {same_count:,}/{len(df):,}")
    
    # 2. åŠ è½½æ¨¡å‹
    models = load_models(args.project, use_intersection=args.intersection)
    if not models:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹")
        return
    
    # 3. æå–ç‰¹å¾
    X, df_valid = extract_features_batch(df, batch_size=args.batch_size)
    if X is None:
        print("âŒ ç‰¹å¾æå–å¤±è´¥")
        return
    
    # 4. é¢„æµ‹
    df_predicted = predict_batch(models, X, df_valid, batch_size=args.predict_batch)
    
    # 5. åˆ†æç»“æœ
    analyze_results(df_predicted)
    
    # 6. ä¿å­˜ç»“æœ
    save_results(df_predicted, args.output)
    
    # è®°å½•ç»“æŸæ—¶é—´
    performance_stats['end_time'] = time.time()
    
    # 7. ä¿å­˜æ€§èƒ½ç»Ÿè®¡
    output_dir = Path(args.output).parent
    save_performance_stats(output_dir)
    
    # æ€»ç»“
    total_time = time.time() - total_start
    print("\n" + "="*80)
    print("âœ… é¢„æµ‹å®Œæˆ!")
    print(f"  â€¢ æ€»ç”¨æ—¶: {total_time:.3f} ç§’ ({total_time/60:.3f} åˆ†é’Ÿ)")
    print(f"  â€¢ å¤„ç†é€Ÿåº¦: {len(df)/total_time:.0f} samples/s")
    print(f"  â€¢ å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)

if __name__ == "__main__":
    main()