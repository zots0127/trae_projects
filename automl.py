#!/usr/bin/env python3
"""
AutoML - è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ å‘½ä»¤è¡Œæ¥å£
ç±»ä¼¼YOLOçš„ç®€æ´å‘½ä»¤è¡Œå·¥å…·

ä½¿ç”¨æ–¹å¼:
    automl train model=xgboost data=mydata.csv config=config.yaml
    automl predict model=saved_model.joblib data=test.csv
    automl validate config=config.yaml
    automl export model=xgboost target=wavelength format=onnx
"""

import sys
import os
from pathlib import Path
import argparse
import json
import yaml
from typing import Dict, Any, List, Optional
import pandas as pd
import numpy as np
import psutil
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing as mp

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from config.system import ExperimentConfig, ConfigValidator
from config.manager import DynamicConfigManager, get_config, list_configs, save_config
from training.pipeline import TrainingPipeline
from models.base import load_model
from utils.run_manager import RunManager
from utils.analysis import ResultsAnalyzer
import joblib


# ========================================
#           å‘½ä»¤è§£æå™¨
# ========================================

class MLArgumentParser:
    """MLå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    
    @staticmethod
    def parse_args_string(args_string: str) -> Dict[str, Any]:
        """
        è§£æ key=value æ ¼å¼çš„å‚æ•°å­—ç¬¦ä¸²
        
        Args:
            args_string: å‚æ•°å­—ç¬¦ä¸²ï¼Œå¦‚ "model=xgboost data=file.csv"
        
        Returns:
            å‚æ•°å­—å…¸
        """
        params = {}
        
        # åˆ†å‰²å‚æ•°
        parts = args_string.split()
        
        for part in parts:
            if '=' in part:
                key, value = part.split('=', 1)
                
                # ç§»é™¤å¤–å±‚å¼•å·ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if (value.startswith("'") and value.endswith("'")) or \
                   (value.startswith('"') and value.endswith('"')):
                    value = value[1:-1]
                
                # å°è¯•è§£æå€¼çš„ç±»å‹
                # ç‰¹æ®Šå‚æ•°ï¼šnameå’Œprojectåº”è¯¥å§‹ç»ˆæ˜¯å­—ç¬¦ä¸²
                if key in ['name', 'project']:
                    # ä¿æŒä¸ºå­—ç¬¦ä¸²ï¼Œä¸è¿›è¡Œç±»å‹è½¬æ¢
                    pass
                # å¸ƒå°”å€¼
                elif value.lower() in ['true', 'false']:
                    value = value.lower() == 'true'
                # æ•°å­—
                elif value.replace('.', '').replace('-', '').isdigit():
                    if '.' in value:
                        value = float(value)
                    else:
                        value = int(value)
                # åˆ—è¡¨
                elif value.startswith('[') and value.endswith(']'):
                    try:
                        value = json.loads(value)
                    except json.JSONDecodeError:
                        # å°è¯•ä¿®å¤å•å¼•å·çš„JSON
                        try:
                            fixed_value = value.replace("'", '"')
                            value = json.loads(fixed_value)
                        except:
                            # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•ä½œä¸ºé€—å·åˆ†éš”çš„åˆ—è¡¨
                            inner = value[1:-1].strip()
                            if inner:
                                value = [v.strip().strip("'\"") for v in inner.split(',')]
                            else:
                                value = []
                # å­—å…¸
                elif value.startswith('{') and value.endswith('}'):
                    try:
                        value = json.loads(value)
                    except json.JSONDecodeError:
                        # å°è¯•ä¿®å¤å•å¼•å·çš„JSON
                        try:
                            fixed_value = value.replace("'", '"')
                            value = json.loads(fixed_value)
                        except:
                            pass  # ä¿æŒåŸå€¼
                # ç‰¹æ®Šå¤„ç†modelså‚æ•°ï¼šæ”¯æŒé€—å·åˆ†éš”æ ¼å¼
                elif key == 'models' and ',' in value:
                    value = [m.strip() for m in value.split(',')]
                
                params[key] = value
        
        return params
    
    @staticmethod
    def _parse_bool(value) -> bool:
        """è§£æå¸ƒå°”å€¼"""
        if isinstance(value, bool):
            return value
        if isinstance(value, str):
            return value.lower() in ['true', 'yes', '1', 'on']
        return bool(value)
    
    @staticmethod
    def merge_params_to_config(config: ExperimentConfig, params: Dict[str, Any]) -> ExperimentConfig:
        """
        å°†å‚æ•°åˆå¹¶åˆ°é…ç½®ä¸­
        
        Args:
            config: åŸºç¡€é…ç½®
            params: è¦åˆå¹¶çš„å‚æ•°
        
        Returns:
            æ›´æ–°åçš„é…ç½®
        """
        for key, value in params.items():
            # å¤„ç†åµŒå¥—é”®
            if '.' in key:
                parts = key.split('.')
                obj = config
                
                # å¯¼èˆªåˆ°åµŒå¥—å¯¹è±¡
                for part in parts[:-1]:
                    if hasattr(obj, part):
                        obj = getattr(obj, part)
                    else:
                        print(f"âš ï¸ æœªçŸ¥é…ç½®é¡¹: {key}")
                        continue
                
                # è®¾ç½®å€¼
                if hasattr(obj, parts[-1]):
                    setattr(obj, parts[-1], value)
            else:
                # ç‰¹æ®Šå¤„ç†ä¸€äº›å¸¸ç”¨å‚æ•°
                if key == 'model':
                    config.model.model_type = value
                elif key == 'data':
                    config.data.data_path = value
                elif key == 'feature':
                    config.feature.feature_type = value
                elif key == 'folds':
                    config.training.n_folds = int(value) if isinstance(value, str) else value
                elif key == 'project':
                    config.logging.project_name = value
                elif key == 'target':
                    if isinstance(value, str):
                        config.data.target_columns = [value]
                    else:
                        config.data.target_columns = value
                elif key == 'save_curves':
                    # å¤„ç†ä¿å­˜è®­ç»ƒæ›²çº¿å‚æ•°
                    config.training.save_training_curves = MLArgumentParser._parse_bool(value)
                elif key == 'save_importance':
                    # å¤„ç†ä¿å­˜ç‰¹å¾é‡è¦æ€§å‚æ•°
                    config.training.save_feature_importance = MLArgumentParser._parse_bool(value)
                elif key in ['test_data', 'test_data_path']:
                    # è®­ç»ƒå®Œæˆåå¯¹å¤–éƒ¨æµ‹è¯•é›†è¿›è¡Œè¯„ä¼°
                    config.data.test_data_path = value
                    print(f"   âœ… è®¾ç½®æµ‹è¯•æ•°æ®é›†: {value}")
                elif key in ['nan_handling', 'nan', 'missing']:
                    # ç¼ºå¤±å€¼å¤„ç†ç­–ç•¥
                    config.data.nan_handling = value
                    print(f"   âœ… è®¾ç½®ç¼ºå¤±å€¼å¤„ç†: {value}")
                elif key in ['multi_target', 'multi_target_strategy', 'target_strategy']:
                    # å¤šç›®æ ‡æ•°æ®é€‰æ‹©ç­–ç•¥
                    config.data.multi_target_strategy = value
                    print(f"   âœ… è®¾ç½®å¤šç›®æ ‡ç­–ç•¥: {value}")
                elif hasattr(config, key):
                    setattr(config, key, value)
        
        return config


# ========================================
#           è®­ç»ƒå‘½ä»¤
# ========================================

def train_command(args: List[str]):
    """è®­ç»ƒå‘½ä»¤"""
    print("\n" + "="*60)
    print("AutoML Training System")
    print("="*60)
    from time import perf_counter as _pc
    _t0 = _pc()
    
    # è§£æå‚æ•°ï¼ˆå¸¦ç±»å‹æ¨æ–­ï¼‰
    parser = MLArgumentParser()
    params = parser.parse_args_string(' '.join(args))
    config_path = params.pop('config', None)
    name = params.get('name')
    project = params.get('project')
    # æ£€æµ‹å…¨æ¨¡å‹å¼€å…³
    all_flag = any(flag in args for flag in ['-all', '--all'])
    
    # è§£æNUMAå’Œå¹¶è¡Œå‚æ•°
    numa_enabled = parser._parse_bool(params.get('numa', False))
    cores_per_task = int(params.get('cores', 4)) if 'cores' in params else None
    parallel_tasks = int(params.get('parallel', 1)) if 'parallel' in params else 1
    bind_cpu = parser._parse_bool(params.get('bind_cpu', False))
    
    # åŠ è½½æˆ–åˆ›å»ºé…ç½®
    _t_conf_start = _pc()
    manager = DynamicConfigManager()
    
    if config_path:
        # å°è¯•è·å–é…ç½®ï¼ˆæ”¯æŒæ¨¡æ¿åç§°æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
        config = manager.get_config(config_path)
        if config:
            print(f"âœ… ä½¿ç”¨é…ç½®: {config_path}")
        else:
            print(f"âŒ é…ç½®æ–‡ä»¶æˆ–æ¨¡æ¿ä¸å­˜åœ¨: {config_path}")
            return 1
    else:
        # ä½¿ç”¨é»˜è®¤é…ç½®
        config = manager.get_config('xgboost_quick')
        if not config:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨å†…ç½®é»˜è®¤é…ç½®
            config = ExperimentConfig()
            print("âœ… ä½¿ç”¨é»˜è®¤é…ç½®")
        else:
            print("âœ… ä½¿ç”¨é»˜è®¤é…ç½®: xgboost_quick")
    
    # åˆå¹¶å‘½ä»¤è¡Œå‚æ•°
    config = parser.merge_params_to_config(config, params)
    _t_conf_end = _pc(); conf_secs = _t_conf_end - _t_conf_start
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦è®­ç»ƒå¤šä¸ªæ¨¡å‹
    models_to_train = []
    if all_flag:
        # ä½¿ç”¨ --all æ ‡å¿—è®­ç»ƒæ‰€æœ‰æ¨¡å‹
        from models import ModelFactory
        models_to_train = ModelFactory.get_supported_models()
        print("âœ… å¯ç”¨å…¨æ¨¡å‹è®­ç»ƒæ¨¡å¼")
        print(f"   å°†è®­ç»ƒ {len(models_to_train)} ä¸ªæ¨¡å‹: {models_to_train}")
    elif 'models' in params and params['models']:
        # ä»å‘½ä»¤è¡Œå‚æ•°è·å–æ¨¡å‹åˆ—è¡¨
        if isinstance(params['models'], list):
            models_to_train = params['models']
        elif isinstance(params['models'], str):
            # æ”¯æŒé€—å·åˆ†éš”çš„æ¨¡å‹åˆ—è¡¨
            models_to_train = [m.strip() for m in params['models'].split(',')]
        print("âœ… å¤šæ¨¡å‹è®­ç»ƒæ¨¡å¼")
        print(f"   å°†è®­ç»ƒ {len(models_to_train)} ä¸ªæ¨¡å‹: {models_to_train}")
    
    # ä¿å­˜æ¨¡å‹åˆ—è¡¨åˆ°é…ç½®ï¼ˆç”¨äºåç»­è®­ç»ƒï¼‰
    if models_to_train:
        config.models_to_train = models_to_train
    
    # åˆ›å»ºè¿è¡Œç›®å½•ï¼ˆç±»ä¼¼YOLOï¼‰
    _t_run_dir_start = _pc()
    # å¦‚æœæŒ‡å®šäº†projectï¼Œä½¿ç”¨projectä½œä¸ºåŸºç¡€ç›®å½•ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤çš„runs
    if project:
        run_manager = RunManager(base_dir=project, task="train")
        run_dir = run_manager.get_next_run_dir(name=name, project=None)  # projectå·²ç»ä½œä¸ºbase_diräº†
        # å¯¹äºæŒ‡å®šprojectçš„æƒ…å†µï¼Œä¿æŒå®Œæ•´çš„ç›®å½•ç»“æ„
        config.logging.base_dir = str(run_dir.parent)
        config.logging.project_name = run_dir.name
    else:
        run_manager = RunManager(task="train")
        run_dir = run_manager.get_next_run_dir(name=name, project=None)
        config.logging.base_dir = str(run_dir.parent)
        config.logging.project_name = run_dir.name
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯ï¼ˆYOLOé£æ ¼çš„è¯¦ç»†é…ç½®ï¼‰
    print(f"\n" + "="*60)
    print("ğŸ“‹ é…ç½®ä¿¡æ¯ (Configuration)")
    print("="*60)
    
    # æ•°æ®é…ç½®
    print("\nğŸ—‚ï¸  æ•°æ®é…ç½® (Data):")
    print(f"   è®­ç»ƒæ•°æ®: {config.data.data_path}")
    data_path = Path(config.data.data_path)
    if data_path.exists():
        print(f"   âœ… è®­ç»ƒæ•°æ®å­˜åœ¨ ({data_path.stat().st_size / 1024:.1f} KB)")
    else:
        print(f"   âŒ è®­ç»ƒæ•°æ®ä¸å­˜åœ¨!")
    
    # æµ‹è¯•æ•°æ®é…ç½®
    if hasattr(config.data, 'test_data_path') and config.data.test_data_path:
        print(f"   æµ‹è¯•æ•°æ®: {config.data.test_data_path}")
        test_path = Path(config.data.test_data_path)
        if test_path.exists():
            print(f"   âœ… æµ‹è¯•æ•°æ®å­˜åœ¨ ({test_path.stat().st_size / 1024:.1f} KB)")
        else:
            print(f"   âš ï¸ æµ‹è¯•æ•°æ®è·¯å¾„æ— æ•ˆ: {test_path}")
            # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
            alt_paths = [
                Path(test_path.name),
                Path("../data") / test_path.name,
                Path("data") / test_path.name
            ]
            for alt in alt_paths:
                if alt.exists():
                    print(f"   ğŸ’¡ æ‰¾åˆ°æ–‡ä»¶åœ¨: {alt}")
                    config.data.test_data_path = str(alt)
                    break
    else:
        print("   æµ‹è¯•æ•°æ®: æœªæŒ‡å®š")
    
    print(f"   ç›®æ ‡åˆ—: {config.data.target_columns}")
    print(f"   å¤šç›®æ ‡ç­–ç•¥: {config.data.multi_target_strategy}")
    if config.data.multi_target_strategy == "intersection":
        print(f"     â†’ ä½¿ç”¨æ‰€æœ‰ç›®æ ‡éƒ½æœ‰å€¼çš„æ•°æ®ï¼ˆæœ€ä¸¥æ ¼ï¼‰")
    elif config.data.multi_target_strategy == "independent":
        print(f"     â†’ æ¯ä¸ªç›®æ ‡ç‹¬ç«‹ä½¿ç”¨æœ‰æ•ˆæ•°æ®ï¼ˆé»˜è®¤ï¼‰")
    elif config.data.multi_target_strategy == "union":
        print(f"     â†’ ä½¿ç”¨æ‰€æœ‰æ•°æ®ï¼Œç¼ºå¤±å€¼å¡«å……")
    print(f"   ç¼ºå¤±å€¼å¤„ç†: {config.data.nan_handling}")
    if config.data.nan_handling != "skip":
        print(f"     - ç‰¹å¾NaNç­–ç•¥: {config.data.feature_nan_strategy}")
        print(f"     - ç›®æ ‡NaNç­–ç•¥: {config.data.target_nan_strategy}")
    
    # æ¨¡å‹é…ç½®
    print("\nğŸ¤– æ¨¡å‹é…ç½® (Model):")
    print(f"   æ¨¡å‹ç±»å‹: {config.model.model_type}")
    print(f"   äº¤å‰éªŒè¯: {config.training.n_folds}æŠ˜")
    if config.model.hyperparameters:
        print("   è¶…å‚æ•°:")
        for key, value in config.model.hyperparameters.items():
            print(f"     - {key}: {value}")
    
    # ç‰¹å¾é…ç½®
    print("\nğŸ”§ ç‰¹å¾é…ç½® (Features):")
    print(f"   ç‰¹å¾ç±»å‹: {config.feature.feature_type}")
    if hasattr(config.feature, 'morgan_bits'):
        print(f"   MorganæŒ‡çº¹ä½æ•°: {config.feature.morgan_bits}")
    if hasattr(config.feature, 'morgan_radius'):
        print(f"   MorganæŒ‡çº¹åŠå¾„: {config.feature.morgan_radius}")
    print(f"   ç¼“å­˜: {'å¯ç”¨' if config.feature.use_cache else 'ç¦ç”¨'}")
    
    # è¾“å‡ºé…ç½®
    print("\nğŸ“ è¾“å‡ºé…ç½® (Output):")
    print(f"   é¡¹ç›®ç›®å½•: {run_dir}")
    print(f"   æ¨¡å‹ä¿å­˜: {run_dir}/models/")
    print(f"   ç»“æœå¯¼å‡º: {run_dir}/exports/")
    print(f"   ç‰¹å¾é‡è¦æ€§: {run_dir}/feature_importance/")
    
    print("\n" + "="*60)
    if hasattr(config, 'models_to_train') and config.models_to_train:
        print(f"   å¤šæ¨¡å‹è®­ç»ƒ: å·²å¯ç”¨")
        print(f"   è®­ç»ƒæ¨¡å‹: {len(config.models_to_train)} ä¸ª")
        print(f"   æ¨¡å‹åˆ—è¡¨: {', '.join(config.models_to_train[:5])}{'...' if len(config.models_to_train) > 5 else ''}")
    if numa_enabled:
        print(f"   NUMAä¼˜åŒ–: å·²å¯ç”¨")
        print(f"   å¹¶è¡Œä»»åŠ¡æ•°: {parallel_tasks}")
        if cores_per_task:
            print(f"   æ¯ä»»åŠ¡æ ¸å¿ƒæ•°: {cores_per_task}")
    print(f"   è¿è¡Œç›®å½•: {run_dir}")
    
    # éªŒè¯é…ç½®
    _t_validate_start = _pc()
    if not ConfigValidator.validate_all(config):
        return 1
    _t_validate_end = _pc(); validate_secs = _t_validate_end - _t_validate_start
    
    # æ‰§è¡Œè®­ç»ƒ
    _t_train_start = _pc()
    try:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è®­ç»ƒå¤šä¸ªæ¨¡å‹
        if hasattr(config, 'models_to_train') and config.models_to_train:
            # å¤šæ¨¡å‹è®­ç»ƒæ¨¡å¼
            if parallel_tasks > 1:
                print(f"\nğŸš€ å¯åŠ¨å¹¶è¡Œè®­ç»ƒ: {parallel_tasks} ä¸ªå¹¶å‘ä»»åŠ¡")
                results = parallel_train_models(
                    config, run_dir, 
                    numa_enabled, cores_per_task, parallel_tasks, bind_cpu
                )
            else:
                print(f"\nğŸš€ ä¸²è¡Œè®­ç»ƒ {len(config.models_to_train)} ä¸ªæ¨¡å‹...")
                all_results = []
                
                for i, model_type in enumerate(config.models_to_train, 1):
                    print(f"\n[{i}/{len(config.models_to_train)}] è®­ç»ƒæ¨¡å‹: {model_type}")
                    print("-" * 40)
                    
                    # åˆ›å»ºæ¨¡å‹ä¸“ç”¨é…ç½®ï¼ˆæ·±æ‹·è´ï¼‰
                    import copy
                    model_config = copy.deepcopy(config)
                    model_config.model.model_type = model_type
                    
                    # é‡è¦ï¼šé‡ç½®è¶…å‚æ•°ä¸ºæ¨¡å‹ç‰¹å®šçš„é»˜è®¤å€¼ï¼Œé¿å…ä½¿ç”¨å…¶ä»–æ¨¡å‹çš„å‚æ•°
                    from models.base import MODEL_PARAMS
                    if model_type in MODEL_PARAMS:
                        model_config.model.hyperparameters = MODEL_PARAMS[model_type].copy()
                    else:
                        model_config.model.hyperparameters = {}
                    
                    # ä¿®å¤æ·±æ‹·è´åçš„é…ç½®å¯¹è±¡
                    from config.system import ComparisonConfig, ExportConfig
                    if isinstance(model_config.comparison, dict):
                        model_config.comparison = ComparisonConfig(**model_config.comparison)
                    if isinstance(model_config.export, dict):
                        model_config.export = ExportConfig(**model_config.export)
                    
                    # åˆ›å»ºç»Ÿä¸€çš„AutoMLç›®å½•ç»“æ„
                    automl_dir = run_dir / "automl_train"
                    automl_dir.mkdir(parents=True, exist_ok=True)
                    model_run_dir = automl_dir / model_type
                    model_run_dir.mkdir(parents=True, exist_ok=True)
                    
                    # æ›´æ–°æ—¥å¿—é…ç½®ï¼Œä½¿ç”¨çˆ¶ç›®å½•
                    model_config.logging.base_dir = str(run_dir.parent)
                    model_config.logging.project_name = f"{run_dir.name}/automl_train/{model_type}"
                    
                    try:
                        # è®¾ç½®CPUäº²å’Œæ€§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        if numa_enabled and cores_per_task:
                            setup_cpu_affinity(0, cores_per_task, bind_cpu)
                            if 'n_jobs' in model_config.model.hyperparameters:
                                model_config.model.hyperparameters['n_jobs'] = cores_per_task
                        
                        # è®­ç»ƒæ¨¡å‹
                        pipeline = TrainingPipeline(model_config)
                        results = pipeline.run()
                        all_results.append({'model': model_type, 'success': True, 'results': results})
                        print(f"âœ… {model_type} è®­ç»ƒå®Œæˆ")
                        
                    except Exception as e:
                        print(f"âŒ {model_type} è®­ç»ƒå¤±è´¥: {e}")
                        all_results.append({'model': model_type, 'success': False, 'error': str(e)})
                
                # æ±‡æ€»ç»“æœ
                results = all_results
        
        else:
            # å•æ¨¡å‹è®­ç»ƒ
            if numa_enabled and cores_per_task:
                # è®¾ç½®CPUäº²å’Œæ€§
                setup_cpu_affinity(0, cores_per_task, bind_cpu)
                # æ›´æ–°æ¨¡å‹çš„n_jobså‚æ•°
                if 'n_jobs' in config.model.hyperparameters:
                    config.model.hyperparameters['n_jobs'] = cores_per_task
            
            pipeline = TrainingPipeline(config)
            results = pipeline.run()
        
        _t_train_end = _pc(); train_secs = _t_train_end - _t_train_start
        total_secs = _pc() - _t0
        print("\n" + "="*60)
        print("âœ¨ è®­ç»ƒå®Œæˆ!")
        print("="*60)
        
        # å¦‚æœå¯ç”¨äº†å¯¹æ¯”è¡¨æ ¼ç”Ÿæˆ
        _t_table_start = _pc()
        if (hasattr(config, 'comparison') and hasattr(config.comparison, 'enable') and config.comparison.enable and
            hasattr(config, 'models_to_train') and config.models_to_train):
            print("\nğŸ“Š ç”Ÿæˆæ¨¡å‹å¯¹æ¯”è¡¨æ ¼...")
            try:
                from utils.comparison_table import ComparisonTableGenerator
                
                # åˆ›å»ºå¯¹æ¯”è¡¨ç”Ÿæˆå™¨
                generator = ComparisonTableGenerator(str(run_dir))
                
                # æ”¶é›†æ‰€æœ‰ç»“æœ
                df_comparison = generator.collect_all_results()
                
                if not df_comparison.empty:
                    # å¯¼å‡ºæ‰€æœ‰æ ¼å¼
                    formats = config.comparison.formats if hasattr(config.comparison, 'formats') else ['markdown', 'csv']
                    output_files = generator.export_all_formats(
                        output_dir=str(run_dir),
                        formats=formats
                    )
                    
                    print("âœ… å¯¹æ¯”è¡¨æ ¼å·²ç”Ÿæˆ:")
                    for fmt, path in output_files.items():
                        print(f"   - {fmt}: {Path(path).name}")
                else:
                    print("âš ï¸ æœªæ‰¾åˆ°è¶³å¤Ÿçš„ç»“æœç”Ÿæˆå¯¹æ¯”è¡¨")
                    
            except Exception as e:
                print(f"âŒ ç”Ÿæˆå¯¹æ¯”è¡¨å¤±è´¥: {e}")
        _t_table_end = _pc(); table_secs = _t_table_end - _t_table_start
        
        # å¦‚æœæœ‰æµ‹è¯•é›†ï¼Œæ˜¾ç¤ºæµ‹è¯•ç»“æœæ±‡æ€»
        if hasattr(config.data, 'test_data_path') and config.data.test_data_path:
            print("\nğŸ“Š æµ‹è¯•é›†è¯„ä¼°æ±‡æ€»:")
            print("   æµ‹è¯•æ–‡ä»¶: " + Path(config.data.test_data_path).name)
            print("   æ³¨: è¯¦ç»†æµ‹è¯•ç»“æœè§ä¸Šæ–¹å„ç›®æ ‡çš„æµ‹è¯•è¯„ä¼°éƒ¨åˆ†")
        
        # ä¿å­˜è¿è¡Œä¿¡æ¯
        run_manager.save_run_info(
            run_dir, 
            config.to_dict(),
            command=' '.join(['automl', 'train'] + args)
        )
        
        # åˆ›å»ºæŒ‡å‘æœ€æ–°è¿è¡Œçš„é“¾æ¥
        RunManager.create_symlink(run_dir, "last")
        
        # ä¿å­˜é…ç½®
        config_save_path = run_dir / "config.yaml"
        config.to_yaml(str(config_save_path))
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {run_dir}")
        print(f"   æŸ¥çœ‹ç»“æœ: {run_dir}/exports/")
        print(f"   æŸ¥çœ‹æŠ¥å‘Š: {run_dir}/exports/*.html")
        print(f"   æŸ¥çœ‹æ¨¡å‹: {run_dir}/models/")

        # è®­ç»ƒé˜¶æ®µè€—æ—¶è®°å½•ï¼ˆsummary + detailï¼‰
        try:
            # å°è¯•å‘ logger å†™å…¥ timingï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if 'training' in locals() or 'pipeline' in locals():
                # pipeline å†…éƒ¨ logger åœ¨è¿è¡Œæ—¶å·²å­˜åœ¨ï¼ˆæŒ‰è®­ç»ƒç›®æ ‡å†™å…¥ï¼‰ï¼Œè¿™é‡Œæˆ‘ä»¬åªè¿½åŠ å…¨å±€ timing åˆ° summary æ–‡ä»¶
                pass
            timing_summary = {
                'startup_to_end': total_secs,
                'config_prepare': conf_secs,
                'validate': validate_secs,
                'training_all': train_secs,
                'comparison_tables': table_secs,
            }
            import json as __json
            with open(_Path(run_dir) / 'timing_summary.json', 'w') as f:
                __json.dump(timing_summary, f, indent=2)
            print(f"   â±ï¸ æ—¶é—´ç»Ÿè®¡ä¿å­˜: {run_dir}/timing_summary.json")

            # ç»†ç²’åº¦: æ±‡æ€»æ¯ä¸ªå®éªŒå†™å…¥ timing_detail.jsonï¼ˆè‹¥å­˜åœ¨loggerå¯¼å‡ºçš„å®éªŒJSONï¼‰
            try:
                detail = {}
                exp_dir = _Path(run_dir) / 'training_logs' / run_dir.name / 'experiments'
                if exp_dir.exists():
                    for p in exp_dir.glob('*_complete.json'):
                        try:
                            with open(p, 'r') as f:
                                exp = __json.load(f)
                            exp_id = exp.get('experiment_id', p.stem.replace('_complete', ''))
                            detail[exp_id] = exp.get('timing', {})
                        except Exception:
                            continue
                with open(_Path(run_dir) / 'timing_detail.json', 'w') as f:
                    __json.dump(detail, f, indent=2, ensure_ascii=False)
                print(f"   â±ï¸ ç»†ç²’åº¦æ—¶é—´ç»Ÿè®¡ä¿å­˜: {run_dir}/timing_detail.json")
            except Exception:
                pass
        except Exception:
            pass

        # è®ºæ–‡å®Œæ•´èµ„æ–™åŒ…æ•´åˆï¼ˆä»…åœ¨ paper_comparison æˆ–æ˜¾å¼å¼€å¯ comparison.enable æ—¶å¯ç”¨ï¼‰
        try:
            is_paper_mode = (config.name.lower().startswith('paper_comparison') if hasattr(config, 'name') else False)
        except Exception:
            is_paper_mode = False

        should_make_paper_package = False
        try:
            if hasattr(config, 'comparison') and hasattr(config.comparison, 'enable'):
                should_make_paper_package = bool(config.comparison.enable)
        except Exception:
            pass
        should_make_paper_package = should_make_paper_package or is_paper_mode

        if should_make_paper_package:
            try:
                from utils.comparison_table import ComparisonTableGenerator
                from pathlib import Path as _Path
                import shutil as _shutil
                import json as _json
                paper_dir = _Path(run_dir) / 'paper_complete'
                paper_dir.mkdir(parents=True, exist_ok=True)

                # 1) è¡¨æ ¼å¯¼å‡ºï¼ˆå››ç§æ ¼å¼ï¼‰
                generator = ComparisonTableGenerator(str(run_dir))
                exported = generator.export_all_formats(output_dir=str(paper_dir), formats=['markdown','html','latex','csv'])

                # 2) ç”Ÿæˆè®ºæ–‡å›¾ï¼ˆå«æ•°æ®ï¼‰
                try:
                    from scripts.generate_paper_figures import generate_all_figures
                    data_path = config.data.data_path if hasattr(config, 'data') else 'data/Database_normalized.csv'
                    generate_all_figures(str(run_dir), data_path, str(paper_dir))
                except Exception as e:
                    print(f"âš ï¸ ç”Ÿæˆè®ºæ–‡å›¾è¡¨å¤±è´¥: {e}")

                # 3) ä¿ç•™æµ‹è¯•é›†åŸå§‹é¢„æµ‹ä¸çœŸå€¼ï¼ˆè‹¥æœ‰ï¼‰åˆ° paper_complete
                try:
                    from pathlib import Path as __Path
                    exports_dir = __Path(run_dir) / 'exports'
                    if exports_dir.exists():
                        for f in exports_dir.glob('test_predictions_*.csv'):
                            __shutil.copy(f, paper_dir / f.name)
                        for f in exports_dir.glob('test_metrics_*.json'):
                            __shutil.copy(f, paper_dir / f.name)
                except Exception:
                    pass

                # 4) æ±‡æ€»æ–‡ä»¶ä¸é…ç½®
                from datetime import datetime as _datetime
                import numpy as ___np

                # å®šä¹‰ä¸€ä¸ªJSONç¼–ç å™¨æ¥å¤„ç†numpyç±»å‹
                class NumpyEncoder(_json.JSONEncoder):
                    def default(self, obj):
                        if isinstance(obj, (___np.integer, ___np.int64)):
                            return int(obj)
                        elif isinstance(obj, (___np.floating, ___np.float64)):
                            return float(obj)
                        elif isinstance(obj, ___np.ndarray):
                            return obj.tolist()
                        return super().default(obj)

                summary = {
                    'project': str(run_dir.name),
                    'path': str(run_dir),
                    'timestamp': _datetime.now().isoformat(),
                    'comparison_tables': {k: _Path(v).name for k, v in exported.items()},
                    'best_models': generator.get_best_models() if exported else {},
                }
                with open(paper_dir / 'summary.json', 'w', encoding='utf-8') as f:
                    _json.dump(summary, f, indent=2, ensure_ascii=False, cls=NumpyEncoder)

                # ä¿å­˜æœ€ç»ˆé…ç½®å‰¯æœ¬
                try:
                    (_Path(run_dir) / 'config.yaml').replace(paper_dir / 'config.yaml')
                except Exception:
                    try:
                        import shutil as __shutil
                        __shutil.copy(_Path(run_dir) / 'config.yaml', paper_dir / 'config.yaml')
                    except Exception:
                        pass

                # 5) å¯é€‰é¦–é¡µ index.html
                try:
                    index_path = paper_dir / 'index.html'
                    index_html = f"""
                    <!DOCTYPE html>
                    <html>
                    <head><meta charset='utf-8'><title>Paper Complete Package</title></head>
                    <body>
                      <h1>Paper Complete Package</h1>
                      <ul>
                        <li><a href="{_Path(exported.get('html','')).name if exported else ''}">Comparison Table (HTML)</a></li>
                        <li><a href="summary.json">Summary (JSON)</a></li>
                        <li><a href="../timing_summary.json">Timing Summary</a></li>
                        <li><a href="../timing_detail.json">Timing Detail</a></li>
                        <li><a href="figure_c_wavelength_plqy.png">Figure C</a></li>
                        <li><a href="figure_d_plqy_distribution.png">Figure D</a></li>
                        <li><a href="figure_e_f_predictions.png">Figure E-F</a></li>
                        <li><a href="figure_g_plqy_accuracy.png">Figure G</a></li>
                      </ul>
                    </body>
                    </html>
                    """
                    with open(index_path, 'w', encoding='utf-8') as f:
                        f.write(index_html)
                except Exception:
                    pass

                # è¿½åŠ  timing åˆ° summary
                try:
                    import json as ___json
                    import numpy as ___np
                    
                    # å®šä¹‰ä¸€ä¸ªJSONç¼–ç å™¨æ¥å¤„ç†numpyç±»å‹
                    class NumpyEncoder(___json.JSONEncoder):
                        def default(self, obj):
                            if isinstance(obj, (___np.integer, ___np.int64)):
                                return int(obj)
                            elif isinstance(obj, (___np.floating, ___np.float64)):
                                return float(obj)
                            elif isinstance(obj, ___np.ndarray):
                                return obj.tolist()
                            return super().default(obj)
                    
                    s_path = paper_dir / 'summary.json'
                    if s_path.exists():
                        data = ___json.load(open(s_path, 'r'))
                    else:
                        data = {}
                    data['timing'] = timing_summary if 'timing_summary' in locals() else {}
                    with open(s_path, 'w') as f:
                        ___json.dump(data, f, indent=2, ensure_ascii=False, cls=NumpyEncoder)
                except Exception:
                    pass

                # 6) å¯é€‰è‡ªåŠ¨å‘å¸ƒåˆ°åç«¯ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ï¼‰
                try:
                    import os as ___os
                    from utils.publisher import ResultsPublisher
                    api_url = ___os.getenv('RESULTS_API_URL', '').strip()
                    if api_url:
                        print("\nğŸŒ å‘å¸ƒè®ºæ–‡èµ„æ–™åŒ…åˆ°åç«¯...")
                        publisher = ResultsPublisher()
                        resp = publisher.publish_package(
                            str(paper_dir),
                            metadata={'project': run_dir.name, 'path': str(run_dir)}
                        )
                        if resp:
                            print(f"âœ… å‘å¸ƒæˆåŠŸ: {resp}")
                        else:
                            print("âš ï¸ å‘å¸ƒæœªè¿”å›æˆåŠŸå“åº”")
                except Exception as e:
                    print(f"âš ï¸ å‘å¸ƒè¿‡ç¨‹å¼‚å¸¸: {e}")

                print(f"\nğŸ“¦ è®ºæ–‡èµ„æ–™åŒ…å·²ç”Ÿæˆ: {paper_dir}")
            except Exception as e:
                print(f"âš ï¸ æ•´åˆè®ºæ–‡èµ„æ–™åŒ…å¤±è´¥: {e}")

        
        # æ‰“å°ç¤ºä¾‹é¢„æµ‹æŒ‡ä»¤ï¼ˆä¸ºæœ¬æ¬¡è®­ç»ƒäº§ç”Ÿçš„æ‰€æœ‰æ¨¡å‹é€ä¸€æ‰“å°ï¼šå•é…ä½“/å¤šé…ä½“ï¼‰
        try:
            models_dir = run_dir / "models"
            model_paths = []
            if models_dir.exists():
                model_paths = sorted(
                    [p for p in models_dir.glob("*.joblib")],
                    key=lambda p: p.stat().st_mtime
                )
            # å›é€€ï¼šæŸ¥æ‰¾ run_dir ä¸‹æ‰€æœ‰ joblib
            if not model_paths:
                model_paths = sorted(
                    [p for p in run_dir.glob("**/*.joblib")],
                    key=lambda p: p.stat().st_mtime
                )
            if model_paths:
                print("\nğŸ“Œ ç¤ºä¾‹é¢„æµ‹æŒ‡ä»¤ï¼ˆå¤åˆ¶åå¯ç›´æ¥è¿è¡Œï¼ŒæŒ‰æ¨¡å‹åˆ—å‡ºï¼‰ï¼š")
                for mp in model_paths:
                    print(f"  # {mp.name}")
                    # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼Œå¦‚æœæœ‰åˆ™ç”¨å¼•å·åŒ…è£¹
                    model_param = f"model={mp}"
                    if any(char in str(mp) for char in ['(', ')', '[', ']', '{', '}', ' ', '*', '?']):
                        model_param = f'"model={mp}"'
                    
                    # å•æ ·æœ¬ï¼šä½¿ç”¨æ•°æ®é›†ä¸­çœŸå®ç¤ºä¾‹çš„ L1/L2/L3
                    print(f"  python automl.py predict {model_param} input='[[\"[C-]1=C(C2=NC=CC3=CC=CC=C23)C=CC=C1\",\"[C-]1=C(C2=NC=CC3=CC=CC=C23)C=CC=C1\",\"C1=CN=C(C2=CN(CCCCCCN3C4=CC=CC=C4C4=C3C=CC=C4)N=N2)C=C1\"]]' feature=combined")
                    # åŒæ ·æœ¬ï¼šé‡å¤è¯¥ä¸‰è”ä½“ä½œä¸ºç¬¬äºŒä¸ªæ ·æœ¬
                    print(f"  python automl.py predict {model_param} input='[[\"[C-]1=C(C2=NC=CC3=CC=CC=C23)C=CC=C1\",\"[C-]1=C(C2=NC=CC3=CC=CC=C23)C=CC=C1\",\"C1=CN=C(C2=CN(CCCCCCN3C4=CC=CC=C4C4=C3C=CC=C4)N=N2)C=C1\"],[\"[C-]1=C(C2=NC=CC3=CC=CC=C23)C=CC=C1\",\"[C-]1=C(C2=NC=CC3=CC=CC=C23)C=CC=C1\",\"C1=CN=C(C2=CN(CCCCCCN3C4=CC=CC=C4C4=C3C=CC=C4)N=N2)C=C1\"]]' feature=combined")
        except Exception:
            pass
        
        return 0
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æ£€æµ‹åˆ°ä¸­æ–­ï¼Œä¿å­˜å·²å®Œæˆçš„éƒ¨åˆ†å¹¶è¾“å‡ºç¤ºä¾‹é¢„æµ‹å‘½ä»¤...")
        try:
            # å°è¯•ä¿å­˜è¿è¡Œä¿¡æ¯ä¸é…ç½®
            run_manager.save_run_info(
                run_dir,
                config.to_dict(),
                command=' '.join(['automl', 'train'] + args)
            )
            RunManager.create_symlink(run_dir, "last")
            config_save_path = run_dir / "config.yaml"
            config.to_yaml(str(config_save_path))
        except Exception:
            pass
        # å°è¯•æ‰“å°å½“å‰å·²æœ‰æ¨¡å‹çš„é¢„æµ‹å‘½ä»¤
        try:
            models_dir = run_dir / "models"
            model_paths = []
            if models_dir.exists():
                model_paths = sorted(
                    [p for p in models_dir.glob("*.joblib")],
                    key=lambda p: p.stat().st_mtime
                )
            if model_paths:
                print("\nğŸ“Œ å·²å®Œæˆæ¨¡å‹çš„ç¤ºä¾‹é¢„æµ‹æŒ‡ä»¤ï¼š")
                for mp in model_paths:
                    print(f"  # {mp.name}")
                    print(f"  python automl.py predict model={mp} input='[[\"[C-]1=C(C2=NC=CC3=CC=CC=C23)C=CC=C1\",\"[C-]1=C(C2=NC=CC3=CC=CC=C23)C=CC=C1\",\"C1=CN=C(C2=CN(CCCCCCN3C4=CC=CC=C4C4=C3C=CC=C4)N=N2)C=C1\"]]' feature=combined")
            else:
                print("âš ï¸ å°šæœªäº§ç”Ÿæ¨¡å‹æ–‡ä»¶ã€‚")
        except Exception:
            pass
        return 130  # å¸¸è§ä¸­æ–­é€€å‡ºç 

    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


# ========================================
#           é¢„æµ‹å‘½ä»¤
# ========================================

def predict_command(args: List[str]):
    """é¢„æµ‹å‘½ä»¤"""
    print("\n" + "="*60)
    print("AutoML Prediction System")
    print("="*60)
    
    # è§£æå‚æ•°
    params = {}
    for arg in args:
        if '=' in arg:
            key, value = arg.split('=', 1)
            params[key] = value
    
    # æ£€æŸ¥å¿…è¦å‚æ•°
    if 'model' not in params:
        print("âŒ ç¼ºå°‘æ¨¡å‹å‚æ•°: model=path/to/model.joblib")
        return 1
    
    if 'data' not in params and 'input' not in params:
        print("âŒ éœ€è¦æä¾›æ•°æ®: data=path/to/data.csv æˆ– input=[\"CCO\",\"c1ccccc1\"]")
        return 1
    
    # åŠ è½½æ¨¡å‹
    print(f"\nğŸ“¦ åŠ è½½æ¨¡å‹: {params['model']}")
    try:
        model = load_model(params['model'])
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return 1
    
    # æ¨æ–­è®­ç»ƒé…ç½®ï¼ˆç”¨äºè‡ªåŠ¨å¯¹é½ç‰¹å¾ç±»å‹ä¸ SMILES åˆ—ï¼‰
    training_feature_type = None
    training_smiles_columns = None
    training_morgan_bits = None
    training_morgan_radius = None
    try:
        model_path = Path(params['model']).resolve()
        # å¸¸è§ä¿å­˜ä½ç½®: runs/.../models/*.joblib â†’ runs/.../config.yaml
        run_dir = model_path.parent.parent if model_path.parent.name == 'models' else model_path.parent
        config_candidates = [run_dir / 'config.yaml', run_dir / 'experiment_config.yaml']
        for cfg in config_candidates:
            if cfg.exists():
                try:
                    from config.system import ExperimentConfig
                    cfg_obj = ExperimentConfig.from_yaml(str(cfg)) if cfg.suffix in ['.yml', '.yaml'] else ExperimentConfig.from_json(str(cfg))
                    training_feature_type = str(getattr(cfg_obj.feature, 'feature_type', None)).lower()
                    training_smiles_columns = list(getattr(cfg_obj.data, 'smiles_columns', []))
                    training_morgan_bits = getattr(cfg_obj.feature, 'morgan_bits', None)
                    training_morgan_radius = getattr(cfg_obj.feature, 'morgan_radius', None)
                    break
                except Exception:
                    pass
    except Exception:
        pass
    
    # è§£æ/å†³ç­–ç‰¹å¾ç±»å‹
    feature_param = params.get('feature')
    if feature_param is None or str(feature_param).lower() == 'auto':
        feature_type = (training_feature_type or 'combined').lower()
        if training_feature_type:
            print(f"ğŸ” æŒ‰è®­ç»ƒé…ç½®è‡ªåŠ¨è®¾ç½®ç‰¹å¾ç±»å‹: {feature_type}")
    else:
        feature_type = str(feature_param).lower()
    
    # è§£æ/å†³ç­– SMILES åˆ—
    smiles_param = params.get('smiles_columns')
    if smiles_param:
        resolved_smiles_cols = [c.strip() for c in smiles_param.split(',') if c.strip()]
        print(f"ğŸ“Œ ä½¿ç”¨æŒ‡å®šçš„ SMILES åˆ—: {','.join(resolved_smiles_cols)}")
    else:
        resolved_smiles_cols = training_smiles_columns or ['L1', 'L2', 'L3']
        if training_smiles_columns:
            print(f"ğŸ” æŒ‰è®­ç»ƒé…ç½®è‡ªåŠ¨è®¾ç½® SMILES åˆ—: {','.join(resolved_smiles_cols)}")
    expected_ligand_count = len(resolved_smiles_cols)
    
    # è§£æè¾“å‡ºåˆ—å
    output_column = params.get('output_column', 'Prediction')
    
    # è§£ææ‰¹å¤„ç†å‚æ•°
    batch_size = int(params.get('batch_size', '1000'))
    show_progress = params.get('show_progress', 'true').lower() in ['true', '1', 'yes']
    skip_errors = params.get('skip_errors', 'true').lower() in ['true', '1', 'yes']
    
    # å‡†å¤‡ç‰¹å¾
    print("\nğŸ”§ å‡†å¤‡ç‰¹å¾...")
    from core.feature_extractor import FeatureExtractor
    X = None
    df = None
    
    # å…è®¸é€šè¿‡å‘½ä»¤æŒ‡å®š morgan_bits/morgan_radiusï¼ˆå…¼å®¹åˆ«å bits/radiusï¼‰
    morgan_bits = params.get('morgan_bits', params.get('bits'))
    morgan_radius = params.get('morgan_radius', params.get('radius'))
    try:
        morgan_bits = int(morgan_bits) if morgan_bits is not None else None
    except ValueError:
        morgan_bits = None
    try:
        morgan_radius = int(morgan_radius) if morgan_radius is not None else None
    except ValueError:
        morgan_radius = None
    # è‹¥æœªæ˜¾å¼æä¾›ï¼Œåˆ™æŒ‰è®­ç»ƒé…ç½®è‡ªåŠ¨è®¾ç½®
    if morgan_bits is None and training_morgan_bits is not None:
        morgan_bits = int(training_morgan_bits)
        print(f"ğŸ” æŒ‰è®­ç»ƒé…ç½®è‡ªåŠ¨è®¾ç½® morgan_bits: {morgan_bits}")
    if morgan_radius is None and training_morgan_radius is not None:
        morgan_radius = int(training_morgan_radius)
        print(f"ğŸ” æŒ‰è®­ç»ƒé…ç½®è‡ªåŠ¨è®¾ç½® morgan_radius: {morgan_radius}")
    feature_extractor = FeatureExtractor(use_cache=True, morgan_bits=morgan_bits, morgan_radius=morgan_radius)
    
    if 'input' in params:
        raw_input = params['input']
        user_input = None
        if isinstance(raw_input, list):
            user_input = raw_input
        else:
            try:
                user_input = json.loads(raw_input)
            except Exception:
                # é€€åŒ–å¤„ç†ï¼šæŒ‰é€—å·æ‹†åˆ†å­—ç¬¦ä¸²
                user_input = [s.strip() for s in str(raw_input).split(',') if s.strip()]
        
        print("ğŸ“¥ ä½¿ç”¨ inline input è¿›è¡Œé¢„æµ‹")
        if feature_type in ['morgan', 'descriptors', 'combined']:
            # è§„èŒƒåŒ–ä¸ºæ¯ä¸ªæ ·æœ¬ä¸€ä¸ª SMILES åˆ—è¡¨
            samples = []
            if all(isinstance(x, str) for x in user_input):
                samples = [[s] for s in user_input]
            elif all(isinstance(x, (list, tuple)) for x in user_input):
                samples = [list(sample) for sample in user_input]
            else:
                print("âŒ input æ ¼å¼ä¸æ”¯æŒã€‚å¯¹äºåˆ†å­ç‰¹å¾ï¼Œä½¿ç”¨ ['SMI', ...] æˆ– [['L1','L2'], ...]")
                return 1
            
            # æŒ‰è®­ç»ƒéœ€è¦çš„é…ä½“æ•°è‡ªåŠ¨è¡¥é½/æˆªæ–­
            if expected_ligand_count > 0:
                adjusted = False
                for i in range(len(samples)):
                    if len(samples[i]) < expected_ligand_count:
                        samples[i] = samples[i] + [None] * (expected_ligand_count - len(samples[i]))
                        adjusted = True
                    elif len(samples[i]) > expected_ligand_count:
                        samples[i] = samples[i][:expected_ligand_count]
                        adjusted = True
                if adjusted:
                    print(f"â„¹ï¸ å·²æŒ‰è®­ç»ƒé…ç½®å¯¹é½é…ä½“æ•°: æœŸæœ› {expected_ligand_count}ï¼Œå·²è‡ªåŠ¨è¡¥é½/æˆªæ–­")

            features = []
            for smiles_list in samples:
                feat = feature_extractor.extract_combination(
                    smiles_list,
                    feature_type=feature_type,
                    combination_method='mean'
                )
                features.append(feat)
            X = np.array(features)
            # ä¸ºäº†å¯¼å‡ºç»“æœï¼Œä¿ç•™ä¸€ä¸ªæœ€å° df
            df = pd.DataFrame({'L1_L2_L3': [','.join([s for s in sm if s is not None]) for sm in samples]})
        else:
            # tabular/auto: ç›´æ¥ä½¿ç”¨æ•°å€¼/æ•°ç»„
            arr = np.array(user_input, dtype=float)
            if arr.ndim == 1:
                arr = arr.reshape(1, -1)
            X = arr
            df = pd.DataFrame({'row': list(range(len(X)))})
    else:
        # ä» CSV è¯»å– - ä½¿ç”¨æ‰¹å¤„ç†ä¼˜åŒ–
        print(f"ğŸ“Š åŠ è½½æ•°æ®: {params['data']}")
        try:
            df = pd.read_csv(params['data'])
            print(f"   æ•°æ®å½¢çŠ¶: {df.shape}")
            print(f"   åˆ—å: {', '.join(df.columns[:10])}{'...' if len(df.columns) > 10 else ''}")
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return 1
        
        # æ£€æŸ¥SMILESåˆ—æ˜¯å¦å­˜åœ¨
        missing_cols = [col for col in resolved_smiles_cols if col not in df.columns]
        if missing_cols:
            print(f"âš ï¸  è­¦å‘Š: ç¼ºå°‘åˆ— {missing_cols}, å°†ä½¿ç”¨ None å€¼")
        
        if feature_type in ['morgan', 'descriptors', 'combined']:
            # ä½¿ç”¨å¢å¼ºç‰ˆæ‰¹å¤„ç†é¢„æµ‹ï¼ˆå¸¦æ–‡ä»¶ç¼“å­˜ï¼‰
            print(f"\nğŸš€ ä½¿ç”¨æ‰¹å¤„ç†æ¨¡å¼ (batch_size={batch_size})")
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ–‡ä»¶ç¼“å­˜
            use_file_cache = params.get('use_file_cache', 'true').lower() in ['true', '1', 'yes']
            file_cache_dir = params.get('file_cache_dir', 'file_feature_cache')
            
            # ä½¿ç”¨V2ç‰ˆæœ¬çš„æ‰¹å¤„ç†å™¨
            from utils.batch_predictor_v2 import BatchPredictorV2
            
            predictor = BatchPredictorV2(
                batch_size=batch_size,
                show_progress=show_progress,
                skip_errors=skip_errors,
                use_file_cache=use_file_cache,
                file_cache_dir=file_cache_dir
            )
            
            predictions, failed_indices = predictor.predict_with_cache(
                df=df,
                model=model,
                feature_extractor=feature_extractor,
                smiles_columns=resolved_smiles_cols,
                feature_type=feature_type,
                combination_method='mean',
                input_file=params['data']  # ä¼ é€’æ–‡ä»¶è·¯å¾„ç”¨äºç¼“å­˜
            )
            
            # æ·»åŠ é¢„æµ‹åˆ—åˆ°åŸå§‹æ•°æ®æ¡†
            df[output_column] = predictions
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            stats = predictor.get_statistics(predictions)
            print(f"\nğŸ“Š é¢„æµ‹ç»Ÿè®¡:")
            print(f"   æˆåŠŸ: {stats['count']} / {len(df)} ({stats['success_rate']:.1f}%)")
            if stats['count'] > 0:
                print(f"   æœ€å°å€¼: {stats['min']:.4f}")
                print(f"   æœ€å¤§å€¼: {stats['max']:.4f}")
                print(f"   å¹³å‡å€¼: {stats['mean']:.4f}")
                print(f"   æ ‡å‡†å·®: {stats['std']:.4f}")
            
            # ä¿å­˜é”™è¯¯æ—¥å¿—
            if failed_indices and skip_errors:
                error_file = params.get('output', 'predictions.csv').replace('.csv', '_errors.log')
                predictor.save_error_log(error_file)
            
            # è·³è¿‡åç»­çš„é¢„æµ‹æ­¥éª¤ï¼Œç›´æ¥ä¿å­˜
            output_path = params.get('output', None)
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºæ–‡ä»¶ï¼Œä½¿ç”¨å›ºå®šæ–‡ä»¶åå¹¶è¦†ç›–
            if output_path is None:
                output_path = 'predictions.csv'
            
            df.to_csv(output_path, index=False)
            
            # è·å–ç»å¯¹è·¯å¾„
            from pathlib import Path
            abs_path = Path(output_path).absolute()
            
            print(f"\nğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜:")
            print(f"   æ–‡ä»¶: {output_path}")
            print(f"   å®Œæ•´è·¯å¾„: {abs_path}")
            print(f"   ä¿ç•™äº†æ‰€æœ‰ {len(df.columns)} åˆ—")
            
            # æ˜¾ç¤ºé¢„è§ˆ
            print(f"\nğŸ“‹ é¢„æµ‹ç»“æœé¢„è§ˆ:")
            preview_df = df.copy()
            
            # é™åˆ¶SMILESæ˜¾ç¤ºé•¿åº¦
            for col in resolved_smiles_cols:
                if col in preview_df.columns:
                    preview_df[col] = preview_df[col].apply(
                        lambda x: str(x)[:30] + '...' if isinstance(x, str) and len(str(x)) > 30 else x
                    )
            
            # æ˜¾ç¤ºå‰åå‡ è¡Œ
            print("-" * 80)
            if len(preview_df) <= 20:
                print(preview_df.to_string(index=False))
            else:
                print("å‰5è¡Œ:")
                print(preview_df.head(5).to_string(index=False))
                print("\nå5è¡Œ:")
                print(preview_df.tail(5).to_string(index=False))
                print(f"\n(å…± {len(preview_df)} è¡Œ)")
            print("-" * 80)
            
            return 0
        else:
            # tabular æˆ– auto æ¨¡å¼
            target_cols = []
            if 'target' in params:
                target_cols = [t.strip() for t in str(params['target']).split(',') if t.strip()]
            X = feature_extractor.extract_from_dataframe(
                df,
                target_columns=target_cols or None,
                feature_type=feature_type
            )
    
    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
    print(f"   ç‰¹å¾ç»´åº¦: {X.shape}")
    
    # é¢„æµ‹
    print("\nğŸ¯ æ‰§è¡Œé¢„æµ‹...")
    try:
        predictions = model.predict(X)
        print(f"   é¢„æµ‹å®Œæˆ: {len(predictions)} ä¸ªæ ·æœ¬")
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
        return 1
    
    # ä¿å­˜ç»“æœ - ä¿ç•™æ‰€æœ‰åŸå§‹åˆ—
    output_path = params.get('output', None)
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºæ–‡ä»¶ï¼Œä½¿ç”¨å›ºå®šæ–‡ä»¶åå¹¶è¦†ç›–
    if output_path is None:
        output_path = 'predictions.csv'
    
    if df is None:
        df = pd.DataFrame()
    
    # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„è¾“å‡ºåˆ—å
    df[output_column] = predictions
    df.to_csv(output_path, index=False)
    
    # è·å–ç»å¯¹è·¯å¾„
    from pathlib import Path
    abs_path = Path(output_path).absolute()
    
    print(f"\nğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜:")
    print(f"   æ–‡ä»¶: {output_path}")
    print(f"   å®Œæ•´è·¯å¾„: {abs_path}")
    print(f"   ä¿ç•™äº†æ‰€æœ‰ {len(df.columns)} åˆ—")
    
    # æ˜¾ç¤ºç»Ÿè®¡
    print(f"\nğŸ“Š é¢„æµ‹ç»Ÿè®¡:")
    print(f"   æœ€å°å€¼: {predictions.min():.4f}")
    print(f"   æœ€å¤§å€¼: {predictions.max():.4f}")
    print(f"   å¹³å‡å€¼: {predictions.mean():.4f}")
    print(f"   æ ‡å‡†å·®: {predictions.std():.4f}")
    
    # æ˜¾ç¤ºé¢„æµ‹ç»“æœè¡¨æ ¼
    print(f"\nğŸ“‹ é¢„æµ‹ç»“æœé¢„è§ˆ:")
    # å¦‚æœæœ‰åŸå§‹æ•°æ®çš„æ ‡è¯†ä¿¡æ¯ï¼Œä¸€èµ·æ˜¾ç¤º
    preview_df = df.copy() if df is not None else pd.DataFrame()
    
    # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    display_cols = []
    for col in ['Unnamed: 0', 'Abbreviation_in_the_article', 'L1', 'L2', 'L3']:
        if col in preview_df.columns:
            display_cols.append(col)
    
    # é™åˆ¶SMILESæ˜¾ç¤ºé•¿åº¦
    if display_cols:
        preview_df = preview_df[display_cols].copy()
        for col in ['L1', 'L2', 'L3']:
            if col in preview_df.columns:
                preview_df[col] = preview_df[col].apply(lambda x: str(x)[:30] + '...' if isinstance(x, str) and len(str(x)) > 30 else x)
    
    preview_df['Prediction'] = predictions
    preview_df['Prediction'] = preview_df['Prediction'].round(4)
    
    # æ‰“å°è¡¨æ ¼
    print("-" * 80)
    if len(preview_df) <= 20:
        print(preview_df.to_string(index=False))
    else:
        print("å‰10è¡Œ:")
        print(preview_df.head(10).to_string(index=False))
        print("\nå10è¡Œ:")
        print(preview_df.tail(10).to_string(index=False))
        print(f"\n(å…± {len(preview_df)} è¡Œ)")
    print("-" * 80)
    
    return 0


# ========================================
#           éªŒè¯å‘½ä»¤
# ========================================

def validate_command(args: List[str]):
    """éªŒè¯å‘½ä»¤ - æ”¯æŒéªŒè¯é…ç½®æ–‡ä»¶æˆ–æ•°æ®æ–‡ä»¶"""
    print("\n" + "="*60)
    print("AutoML Validator")
    print("="*60)
    
    # è§£æå‚æ•°
    params = {}
    for arg in args:
        if '=' in arg:
            key, value = arg.split('=', 1)
            params[key] = value
    
    # æ£€æŸ¥æ˜¯éªŒè¯æ•°æ®è¿˜æ˜¯é…ç½®
    data_path = params.get('data')
    config_path = params.get('config')
    
    if data_path:
        # éªŒè¯æ•°æ®æ–‡ä»¶
        print(f"\nğŸ“Š éªŒè¯æ•°æ®æ–‡ä»¶: {data_path}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(data_path).exists():
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
            return 1
        
        try:
            # åŠ è½½æ•°æ®
            import pandas as pd
            df = pd.read_csv(data_path)
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ")
            
            # æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
            print("\næ•°æ®ä¿¡æ¯:")
            print("-" * 40)
            print(f"è¡Œæ•°: {len(df)}")
            print(f"åˆ—æ•°: {len(df.columns)}")
            print(f"åˆ—å: {', '.join(df.columns[:10])}")
            if len(df.columns) > 10:
                print(f"      ... è¿˜æœ‰ {len(df.columns)-10} åˆ—")
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—
            smiles_cols = ['L1', 'L2', 'L3']
            target_cols = ['Max_wavelength(nm)', 'PLQY', 'tau(s*10^-6)']
            
            print("\nğŸ” æ£€æŸ¥å¿…è¦åˆ—...")
            
            # æ£€æŸ¥SMILESåˆ—
            has_smiles = any(col in df.columns for col in smiles_cols)
            if has_smiles:
                found_smiles = [col for col in smiles_cols if col in df.columns]
                print(f"âœ… SMILESåˆ—: {', '.join(found_smiles)}")
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ°SMILESåˆ— (æœŸæœ›: {', '.join(smiles_cols)})")
            
            # æ£€æŸ¥ç›®æ ‡åˆ—
            has_targets = any(col in df.columns for col in target_cols)
            if has_targets:
                found_targets = [col for col in target_cols if col in df.columns]
                print(f"âœ… ç›®æ ‡åˆ—: {', '.join(found_targets)}")
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ°ç›®æ ‡åˆ— (æœŸæœ›: {', '.join(target_cols)})")
            
            # æ£€æŸ¥æ•°æ®è´¨é‡
            print("\nğŸ“ˆ æ•°æ®è´¨é‡æ£€æŸ¥:")
            print(f"ç¼ºå¤±å€¼æ€»æ•°: {df.isnull().sum().sum()}")
            print(f"é‡å¤è¡Œæ•°: {df.duplicated().sum()}")
            
            # å¦‚æœæœ‰SMILESåˆ—ï¼Œæ£€æŸ¥SMILESæœ‰æ•ˆæ€§
            if has_smiles:
                try:
                    from rdkit import Chem
                    invalid_count = 0
                    for col in found_smiles:
                        if col in df.columns:
                            # å–æ ·æ£€æŸ¥ï¼ˆæœ€å¤š100ä¸ªï¼‰
                            sample = df[col].dropna().head(100)
                            for smiles in sample:
                                if pd.notna(smiles) and smiles != '':
                                    mol = Chem.MolFromSmiles(str(smiles))
                                    if mol is None:
                                        invalid_count += 1
                    if invalid_count > 0:
                        print(f"âš ï¸  å‘ç° {invalid_count} ä¸ªæ— æ•ˆSMILES")
                    else:
                        print(f"âœ… SMILESæ ¼å¼æ£€æŸ¥é€šè¿‡")
                except ImportError:
                    print("â„¹ï¸  RDKitæœªå®‰è£…ï¼Œè·³è¿‡SMILESéªŒè¯")
            
            print("\nâœ… æ•°æ®éªŒè¯å®Œæˆ!")
            return 0
            
        except Exception as e:
            print(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
            return 1
    
    elif config_path:
        # éªŒè¯é…ç½®æ–‡ä»¶
        print(f"\nğŸ“‹ éªŒè¯é…ç½®æ–‡ä»¶: {config_path}")
        
        if not Path(config_path).exists():
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return 1
        
        try:
            if config_path.endswith('.yaml'):
                config = ExperimentConfig.from_yaml(config_path)
            else:
                config = ExperimentConfig.from_json(config_path)
            
            # æ˜¾ç¤ºé…ç½®
            print("\né…ç½®å†…å®¹:")
            print("-" * 40)
            print(f"åç§°: {config.name}")
            print(f"æè¿°: {config.description}")
            print(f"æ¨¡å‹: {config.model.model_type}")
            print(f"ç‰¹å¾: {config.feature.feature_type}")
            print(f"æ•°æ®: {config.data.data_path}")
            print(f"ç›®æ ‡: {config.data.target_columns}")
            print(f"äº¤å‰éªŒè¯: {config.training.n_folds}æŠ˜")
            
            # éªŒè¯é…ç½®
            print("\nğŸ” éªŒè¯é…ç½®...")
            if ConfigValidator.validate_all(config):
                print("âœ… é…ç½®éªŒè¯é€šè¿‡!")
                return 0
            else:
                print("âŒ é…ç½®éªŒè¯å¤±è´¥!")
                return 1
                
        except Exception as e:
            print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
            return 1
    
    else:
        # é»˜è®¤æŸ¥æ‰¾é…ç½®æ–‡ä»¶
        if Path('config.yaml').exists():
            return validate_command(['config=config.yaml'])
        elif Path('config.json').exists():
            return validate_command(['config=config.json'])
        else:
            print("âŒ è¯·æŒ‡å®šè¦éªŒè¯çš„æ–‡ä»¶:")
            print("   éªŒè¯æ•°æ®: automl validate data=<æ•°æ®æ–‡ä»¶>")
            print("   éªŒè¯é…ç½®: automl validate config=<é…ç½®æ–‡ä»¶>")
            return 1


# ========================================
#           å¯¼å‡ºå‘½ä»¤
# ========================================

def export_command(args: List[str]):
    """å¯¼å‡ºå‘½ä»¤"""
    print("\n" + "="*60)
    print("AutoML Model Export System")
    print("="*60)
    
    # è§£æå‚æ•°
    params = {}
    for arg in args:
        if '=' in arg:
            key, value = arg.split('=', 1)
            params[key] = value
    
    model_path = params.get('model')
    format_type = params.get('format', 'onnx')
    output_path = params.get('output', 'exported_model')
    
    if not model_path:
        print("âŒ ç¼ºå°‘æ¨¡å‹å‚æ•°: model=path/to/model.joblib")
        return 1
    
    # åŠ è½½æ¨¡å‹
    print(f"\nğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
    try:
        model = load_model(model_path)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return 1
    
    # å¯¼å‡ºæ¨¡å‹
    print(f"ğŸ“¤ å¯¼å‡ºä¸º {format_type} æ ¼å¼...")
    
    if format_type == 'onnx':
        try:
            import skl2onnx
            from skl2onnx import convert_sklearn
            
            # éœ€è¦è¾“å…¥å½¢çŠ¶ä¿¡æ¯
            n_features = int(params.get('n_features', 1109))
            initial_type = [('float_input', skl2onnx.common.data_types.FloatTensorType([None, n_features]))]
            
            onx = convert_sklearn(model, initial_types=initial_type)
            
            with open(f"{output_path}.onnx", "wb") as f:
                f.write(onx.SerializeToString())
            
            print(f"âœ… æ¨¡å‹å·²å¯¼å‡º: {output_path}.onnx")
            
        except ImportError:
            print("âŒ éœ€è¦å®‰è£… skl2onnx: pip install skl2onnx")
            return 1
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
            return 1
    
    elif format_type == 'pmml':
        print("âŒ PMMLå¯¼å‡ºæš‚æœªå®ç°")
        return 1
    
    elif format_type == 'pickle':
        import pickle
        with open(f"{output_path}.pkl", 'wb') as f:
            pickle.dump(model, f)
        print(f"âœ… æ¨¡å‹å·²å¯¼å‡º: {output_path}.pkl")
    
    else:
        print(f"âŒ ä¸æ”¯æŒçš„æ ¼å¼: {format_type}")
        return 1
    
    return 0


# ========================================
#           åˆ†æå‘½ä»¤
# ========================================

def analyze_command(args: List[str]):
    """åˆ†æå®éªŒç»“æœ"""
    print("\n" + "="*60)
    print("AutoML Results Analysis")
    print("="*60)
    
    # è§£æå‚æ•°
    params = {}
    for arg in args:
        if '=' in arg:
            key, value = arg.split('=', 1)
            params[key] = value
    
    # è·å–è¿è¡Œç›®å½•
    run_dir = params.get('run_dir', params.get('dir', 'runs/train'))
    output_format = params.get('format', 'text')
    output_path = params.get('output')
    print_results = params.get('print', 'true').lower() == 'true'
    
    # è½¬æ¢ä¸ºPathå¯¹è±¡
    run_dir = Path(run_dir)
    
    # å¦‚æœä½¿ç”¨ 'last' å…³é”®å­—ï¼ŒæŸ¥æ‰¾æœ€æ–°çš„è¿è¡Œ
    if str(run_dir) == 'last':
        # æŸ¥æ‰¾æœ€æ–°çš„è¿è¡Œç›®å½•
        if Path('runs/train').exists():
            run_dirs = sorted([d for d in Path('runs/train').iterdir() if d.is_dir() and d.name != 'last'])
            if run_dirs:
                run_dir = run_dirs[-1]
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒè¿è¡Œè®°å½•")
                return 1
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒè¿è¡Œè®°å½•")
            return 1
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not run_dir.exists():
        print(f"âŒ è¿è¡Œç›®å½•ä¸å­˜åœ¨: {run_dir}")
        print("\nå¯ç”¨çš„è¿è¡Œç›®å½•:")
        
        # åˆ—å‡ºå¯ç”¨çš„è¿è¡Œç›®å½•
        for base_dir in ['runs', '.']:
            base_path = Path(base_dir)
            if base_path.exists():
                for task_dir in base_path.iterdir():
                    if task_dir.is_dir() and not task_dir.name.startswith('.'):
                        sub_dirs = [d for d in task_dir.iterdir() if d.is_dir() and d.name != 'last']
                        if sub_dirs:
                            print(f"  {task_dir}:")
                            for d in sorted(sub_dirs)[-5:]:  # æ˜¾ç¤ºæœ€è¿‘5ä¸ª
                                print(f"    - {d}")
        return 1
    
    print(f"\nğŸ“‚ åˆ†æç›®å½•: {run_dir}")
    
    # åˆ›å»ºåˆ†æå™¨
    try:
        analyzer = ResultsAnalyzer(run_dir)
    except Exception as e:
        print(f"âŒ åˆ›å»ºåˆ†æå™¨å¤±è´¥: {e}")
        return 1
    
    # ç”ŸæˆæŠ¥å‘Š
    print(f"ğŸ“Š ç”Ÿæˆ{output_format.upper()}æ ¼å¼æŠ¥å‘Š...")
    
    try:
        # ä¿å­˜æŠ¥å‘Š
        if output_path:
            output_path = Path(output_path)
        analyzer.save_report(output_path=output_path, output_format=output_format)
        
        # æ‰“å°åˆ°æ§åˆ¶å°
        if print_results:
            print("\n" + "="*60)
            print(analyzer.generate_report('text'))
            print("="*60)
        
        print("\nâœ… åˆ†æå®Œæˆ!")
        return 0
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


# ========================================
#           ä¿¡æ¯å‘½ä»¤
# ========================================

def info_command(args: List[str]):
    """æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯"""
    print("\n" + "="*60)
    print("AutoML System Information")
    print("="*60)
    
    # ç³»ç»Ÿä¿¡æ¯
    print("\nğŸ“Š ç³»ç»Ÿä¿¡æ¯:")
    print(f"   Pythonç‰ˆæœ¬: {sys.version.split()[0]}")
    print(f"   å¹³å°: {sys.platform}")
    
    # å¯ç”¨æ¨¡å‹
    from models import ModelFactory
    print("\nğŸ¤– å¯ç”¨æ¨¡å‹:")
    for model in ModelFactory.get_supported_models():
        print(f"   - {model}")
    
    # å¯ç”¨æ¨¡æ¿
    manager = ConfigManager()
    print("\nğŸ“‹ é…ç½®æ¨¡æ¿:")
    for template in manager.list_templates():
        desc = manager.templates[template].description
        print(f"   - {template}: {desc}")
    
    # ç‰¹å¾ç±»å‹
    print("\nğŸ”§ ç‰¹å¾ç±»å‹:")
    print("   - morgan: MorganæŒ‡çº¹")
    print("   - descriptors: åˆ†å­æè¿°ç¬¦")
    print("   - combined: ç»„åˆç‰¹å¾")
    
    # ä½¿ç”¨ç¤ºä¾‹
    print("\nğŸ’¡ ä½¿ç”¨ç¤ºä¾‹:")
    print("   è®­ç»ƒ: automl train model=xgboost data=data.csv config=config.yaml")
    print("   åˆ†æ: automl analyze dir=quick_test format=html")
    print("   é¢„æµ‹: automl predict model=model.joblib data=test.csv")
    print("   éªŒè¯: automl validate config=config.yaml")
    print("   å¯¼å‡º: automl export model=model.joblib format=onnx")
    
    return 0


# ========================================
#           NUMAå’Œå¹¶è¡Œæ”¯æŒ
# ========================================

def setup_cpu_affinity(task_id: int, cores_per_task: int, bind_cpu: bool = False):
    """
    è®¾ç½®CPUäº²å’Œæ€§å’ŒNUMAç»‘å®š
    
    Args:
        task_id: ä»»åŠ¡ID
        cores_per_task: æ¯ä¸ªä»»åŠ¡ä½¿ç”¨çš„æ ¸å¿ƒæ•°
        bind_cpu: æ˜¯å¦ç»‘å®šCPU
    """
    if not bind_cpu:
        return
    
    try:
        # è·å–ç³»ç»ŸCPUä¿¡æ¯
        cpu_count = psutil.cpu_count(logical=True)
        
        # è®¡ç®—æ ¸å¿ƒèŒƒå›´
        core_start = (task_id * cores_per_task) % cpu_count
        core_end = min(core_start + cores_per_task, cpu_count)
        cores = list(range(core_start, core_end))
        
        # è®¾ç½®CPUäº²å’Œæ€§
        p = psutil.Process()
        p.cpu_affinity(cores)
        
        print(f"   âœ… CPUäº²å’Œæ€§è®¾ç½®: ä»»åŠ¡{task_id} -> æ ¸å¿ƒ{cores}")
        
    except Exception as e:
        print(f"   âš ï¸ æ— æ³•è®¾ç½®CPUäº²å’Œæ€§: {e}")


def get_numa_info():
    """è·å–NUMAä¿¡æ¯"""
    try:
        import subprocess
        result = subprocess.run(['numactl', '--hardware'], 
                              capture_output=True, text=True, check=False)
        if result.returncode == 0:
            lines = result.stdout.split('\n')
            for line in lines:
                if 'available:' in line and 'nodes' in line:
                    numa_nodes = int(line.split()[1])
                    return numa_nodes
    except:
        pass
    return 1


# ========================================
#           é¢„çƒ­ç¼“å­˜å‘½ä»¤
# ========================================

def warmup_command(args: List[str]):
    """é¢„è®¡ç®—å¹¶å†™å…¥ç‰¹å¾ç¼“å­˜ï¼ˆæ”¯æŒåˆ†å­/è¡¨æ ¼ï¼‰ï¼Œé¿å…è®­ç»ƒé˜¶æ®µå¹¶å‘æå–å¼€é”€"""
    print("\n" + "="*60)
    print("AutoML Cache Warmup")
    print("="*60)

    # è§£æå‚æ•°ï¼ˆkey=valueï¼‰
    params = {}
    for arg in args:
        if '=' in arg:
            k, v = arg.split('=', 1)
            params[k] = v

    # å¿…è¦å‚æ•°
    data_path = params.get('data')
    if not data_path:
        print("âŒ ç¼ºå°‘å‚æ•°: data=path/to.csv")
        return 1

    feature_type = str(params.get('feature', 'auto')).lower()
    smiles_columns = params.get('smiles_columns')
    if smiles_columns:
        smiles_columns = [c.strip() for c in smiles_columns.split(',') if c.strip()]
    morgan_bits = params.get('morgan_bits', params.get('bits'))
    morgan_radius = params.get('morgan_radius', params.get('radius'))
    try:
        morgan_bits = int(morgan_bits) if morgan_bits is not None else None
        morgan_radius = int(morgan_radius) if morgan_radius is not None else None
    except Exception:
        morgan_bits = None
        morgan_radius = None

    # å¹¶å‘å‚æ•°ï¼ˆé¢„çƒ­é˜¶æ®µæœ¬å‘½ä»¤å†…éƒ¨ä¸²è¡Œå†™ç¼“å­˜ï¼Œé¿å…ç«äº‰ï¼›å¯åŠ  n_jobs åšè¡Œå†…å¹¶è¡Œï¼‰
    n_jobs = int(params.get('n_jobs', 0))

    # åŠ è½½æ•°æ®
    import pandas as pd
    import numpy as np
    from core.feature_extractor import FeatureExtractor

    print(f"\nğŸ“Š åŠ è½½æ•°æ®: {data_path}")
    try:
        df = pd.read_csv(data_path)
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return 1
    print(f"   å½¢çŠ¶: {df.shape}")

    # æ„å»ºæå–å™¨
    extractor = FeatureExtractor(
        feature_type=feature_type,
        use_cache=True,
        morgan_bits=morgan_bits,
        morgan_radius=morgan_radius
    )

    # è‡ªåŠ¨è¯†åˆ« smiles åˆ—
    if feature_type in ['morgan', 'descriptors', 'combined', 'auto']:
        if not smiles_columns:
            # è‹¥ auto/molecularï¼Œå°è¯•ä» DF çŒœæµ‹
            guessed = [col for col in df.columns if any(ind in col.lower() for ind in ['smiles','l1','l2','l3'])]
            smiles_columns = guessed or ['L1','L2','L3']

    print(f"   ç‰¹å¾ç±»å‹: {feature_type}")
    if smiles_columns:
        print(f"   SMILESåˆ—: {','.join(smiles_columns)}")
    if morgan_bits:
        print(f"   morgan_bits: {morgan_bits}")
    if morgan_radius:
        print(f"   morgan_radius: {morgan_radius}")

    # é¢„çƒ­ï¼šé€è¡Œæå–ï¼ˆå¿…è¦æ—¶å¯åŠ å…¥ tqdmï¼‰
    from tqdm import tqdm
    total = len(df)
    errors = 0

    if feature_type in ['morgan', 'descriptors', 'combined'] or (
        feature_type == 'auto' and extractor.detect_data_type(df) == 'molecular'
    ):
        # åˆ†å­è·¯å¾„
        for _, row in tqdm(df.iterrows(), total=total, desc='é¢„çƒ­åˆ†å­ç‰¹å¾ç¼“å­˜'):
            smiles_list = [row[col] if col in row and pd.notna(row[col]) else None for col in smiles_columns]
            try:
                _ = extractor.extract_combination(smiles_list, feature_type=feature_type if feature_type!='auto' else 'combined')
            except Exception:
                errors += 1
                continue
    else:
        # è¡¨æ ¼è·¯å¾„ï¼šä¸€æ¬¡æ€§å†™å…¥ï¼ˆå†…éƒ¨ä¼šç¼“å­˜åˆ—çº§ç‰¹å¾åï¼Œä¸é€è¡Œï¼‰
        try:
            _ = extractor.extract_from_dataframe(df, target_columns=[] if 'target' not in params else [params['target']])
        except Exception:
            errors += 1

    print(f"\nâœ… é¢„çƒ­å®Œæˆ: {total - errors}/{total} æ¡è®°å½•å·²å†™å…¥/å‘½ä¸­ç¼“å­˜")
    return 0

def train_single_model_parallel(args):
    """
    å¹¶è¡Œè®­ç»ƒå•ä¸ªæ¨¡å‹çš„å·¥ä½œå‡½æ•°
    
    Args:
        args: (config, model_type, task_id, numa_enabled, cores_per_task, bind_cpu)
    """
    config, model_type, task_id, numa_enabled, cores_per_task, bind_cpu = args
    
    # è®¾ç½®CPUäº²å’Œæ€§
    if numa_enabled and cores_per_task:
        setup_cpu_affinity(task_id, cores_per_task, bind_cpu)
    
    # é‡å»ºé…ç½®å¯¹è±¡ï¼ˆä»å­—å…¸æˆ–é…ç½®å¯¹è±¡ï¼‰
    from config.system import ExperimentConfig
    if isinstance(config, dict):
        config = ExperimentConfig.from_dict(config)
    else:
        config = ExperimentConfig.from_dict(config.to_dict())  # æ·±æ‹·è´
    
    config.model.model_type = model_type
    
    # é‡è¦ï¼šé‡ç½®è¶…å‚æ•°ä¸ºæ¨¡å‹ç‰¹å®šçš„é»˜è®¤å€¼ï¼Œé¿å…ä½¿ç”¨å…¶ä»–æ¨¡å‹çš„å‚æ•°
    from models.base import MODEL_PARAMS
    if model_type in MODEL_PARAMS:
        config.model.hyperparameters = MODEL_PARAMS[model_type].copy()
    else:
        config.model.hyperparameters = {}
    
    config.logging.project_name = f"{config.logging.project_name}_{model_type}"
    
    # è®¾ç½®n_jobs
    if cores_per_task and 'n_jobs' in config.model.hyperparameters:
        config.model.hyperparameters['n_jobs'] = cores_per_task
    
    # æ‰§è¡Œè®­ç»ƒ
    try:
        from training.pipeline import TrainingPipeline
        pipeline = TrainingPipeline(config)
        results = pipeline.run()
        return {'model': model_type, 'success': True, 'results': results}
    except Exception as e:
        return {'model': model_type, 'success': False, 'error': str(e)}


def parallel_train_models(config, run_dir, numa_enabled=False, 
                         cores_per_task=None, parallel_tasks=8, bind_cpu=False):
    """
    å¹¶è¡Œè®­ç»ƒå¤šä¸ªæ¨¡å‹
    
    Args:
        config: å®éªŒé…ç½®
        run_dir: è¿è¡Œç›®å½•
        numa_enabled: æ˜¯å¦å¯ç”¨NUMAä¼˜åŒ–
        cores_per_task: æ¯ä¸ªä»»åŠ¡çš„æ ¸å¿ƒæ•°
        parallel_tasks: å¹¶è¡Œä»»åŠ¡æ•°
        bind_cpu: æ˜¯å¦ç»‘å®šCPU
    """
    models = config.models_to_train if hasattr(config, 'models_to_train') else []
    
    # å‡†å¤‡ä»»åŠ¡å‚æ•°ï¼ˆåºåˆ—åŒ–é…ç½®ä¸ºå­—å…¸ï¼‰
    tasks = []
    config_dict = config.to_dict()  # è½¬æ¢ä¸ºå­—å…¸ä»¥ä¾¿åºåˆ—åŒ–
    for i, model in enumerate(models):
        task_args = (config_dict, model, i, numa_enabled, cores_per_task, bind_cpu)
        tasks.append(task_args)
    
    # æ˜¾ç¤ºNUMAä¿¡æ¯
    if numa_enabled:
        numa_nodes = get_numa_info()
        print(f"   NUMAèŠ‚ç‚¹æ•°: {numa_nodes}")
        print(f"   CPUæ€»æ ¸å¿ƒæ•°: {psutil.cpu_count(logical=True)}")
    
    # å¹¶è¡Œæ‰§è¡Œ
    results = []
    with ProcessPoolExecutor(max_workers=parallel_tasks) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_model = {
            executor.submit(train_single_model_parallel, task): task[1]
            for task in tasks
        }
        
        # æ”¶é›†ç»“æœ
        for future in as_completed(future_to_model):
            model = future_to_model[future]
            try:
                result = future.result()
                results.append(result)
                if result['success']:
                    print(f"   âœ… {model} è®­ç»ƒå®Œæˆ")
                else:
                    print(f"   âŒ {model} è®­ç»ƒå¤±è´¥: {result.get('error', 'Unknown')}")
            except Exception as e:
                print(f"   âŒ {model} æ‰§è¡Œå¼‚å¸¸: {e}")
                results.append({'model': model, 'success': False, 'error': str(e)})
    
    # æ±‡æ€»ç»“æœ
    successful = [r for r in results if r['success']]
    failed = [r for r in results if not r['success']]
    
    print(f"\nğŸ“Š å¹¶è¡Œè®­ç»ƒç»“æœ:")
    print(f"   æˆåŠŸ: {len(successful)}/{len(models)}")
    if failed:
        print(f"   å¤±è´¥: {', '.join([r['model'] for r in failed])}")
    
    return results


# ========================================
#           ä¸»å…¥å£
# ========================================

def config_command(args: List[str]):
    """é…ç½®ç®¡ç†å‘½ä»¤"""
    print("\n" + "="*60)
    print("AutoML Configuration Manager")
    print("="*60)
    
    # è§£æå­å‘½ä»¤
    if not args or args[0] == 'list':
        # åˆ—å‡ºæ‰€æœ‰å¯ç”¨é…ç½®
        manager = DynamicConfigManager()
        manager.print_config_summary()
        return 0
    
    elif args[0] == 'show':
        # æ˜¾ç¤ºç‰¹å®šé…ç½®è¯¦æƒ…
        if len(args) < 2:
            print("âŒ è¯·æŒ‡å®šé…ç½®åç§°: config show <name>")
            return 1
        
        config_name = args[1]
        manager = DynamicConfigManager()
        config = manager.get_config(config_name)
        
        if not config:
            print(f"âŒ é…ç½®ä¸å­˜åœ¨: {config_name}")
            return 1
        
        print(f"\nğŸ“‹ é…ç½®: {config_name}")
        print("-" * 40)
        print(f"æè¿°: {config.description}")
        print(f"æ¨¡å‹: {config.model.model_type}")
        print(f"ç‰¹å¾: {config.feature.feature_type}")
        print(f"æŠ˜æ•°: {config.training.n_folds}")
        print(f"ä¼˜åŒ–: {'å¯ç”¨' if config.optimization.enable else 'ç¦ç”¨'}")
        
        if config.model.hyperparameters:
            print("\nè¶…å‚æ•°:")
            for k, v in config.model.hyperparameters.items():
                print(f"  {k}: {v}")
        
        return 0
    
    else:
        print(f"âŒ æœªçŸ¥å­å‘½ä»¤: {args[0]}")
        print("å¯ç”¨å­å‘½ä»¤: list, show")
        return 1


def cache_command(args: List[str]):
    """ç¼“å­˜ç®¡ç†å‘½ä»¤"""
    print("\n" + "="*60)
    print("Cache Management System")
    print("="*60)
    
    # å¯¼å…¥ç¼“å­˜ç®¡ç†å™¨
    from utils.file_feature_cache import FileFeatureCache
    
    # è§£æå­å‘½ä»¤
    if not args or args[0] == 'stats':
        # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
        cache = FileFeatureCache()
        stats = cache.get_cache_stats()
        
        print("\nğŸ“Š ç¼“å­˜ç»Ÿè®¡:")
        print(f"   ç¼“å­˜ç›®å½•: {stats['cache_dir']}")
        print(f"   ç¼“å­˜æ–‡ä»¶æ•°: {stats['total_files']}")
        print(f"   æ€»å¤§å°: {stats['total_size_mb']:.2f} MB")
        print(f"   æ€»è®¿é—®æ¬¡æ•°: {stats['total_accesses']}")
        
        if stats['most_accessed']:
            print("\nğŸ”¥ æœ€å¸¸è®¿é—®:")
            for item in stats['most_accessed']:
                print(f"   - {item['file']}: {item['accesses']} æ¬¡ ({item['feature_type']})")
        
        if stats['largest_files']:
            print("\nğŸ’¾ æœ€å¤§æ–‡ä»¶:")
            for item in stats['largest_files']:
                print(f"   - {item['file']}: {item['size_mb']:.2f} MB ({item['feature_type']})")
        
        return 0
    
    elif args[0] == 'clear':
        # æ¸…ç†ç¼“å­˜
        cache = FileFeatureCache()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å‚æ•°
        if len(args) > 1 and args[1].isdigit():
            days = int(args[1])
            print(f"\nğŸ—‘ï¸  æ¸…ç† {days} å¤©å‰çš„ç¼“å­˜...")
            count, size = cache.clear_cache(older_than_days=days)
        else:
            print("\nğŸ—‘ï¸  æ¸…ç†æ‰€æœ‰ç¼“å­˜...")
            confirm = input("ç¡®è®¤æ¸…ç†æ‰€æœ‰ç¼“å­˜? (y/n): ")
            if confirm.lower() != 'y':
                print("å–æ¶ˆæ¸…ç†")
                return 0
            count, size = cache.clear_cache()
        
        print(f"âœ… å·²æ¸…ç† {count} ä¸ªæ–‡ä»¶ ({size / 1024 / 1024:.2f} MB)")
        return 0
    
    elif args[0] == 'verify':
        # éªŒè¯ç¼“å­˜å®Œæ•´æ€§
        cache = FileFeatureCache()
        print("\nğŸ” éªŒè¯ç¼“å­˜å®Œæ•´æ€§...")
        valid, invalid = cache.verify_cache()
        print(f"   æœ‰æ•ˆ: {valid} ä¸ªæ–‡ä»¶")
        print(f"   æ— æ•ˆ: {invalid} ä¸ªæ–‡ä»¶")
        if invalid > 0:
            print(f"   å·²è‡ªåŠ¨æ¸…ç†æ— æ•ˆç¼“å­˜")
        return 0
    
    else:
        print(f"âŒ æœªçŸ¥å­å‘½ä»¤: {args[0]}")
        print("\nå¯ç”¨å­å‘½ä»¤:")
        print("  stats  - æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡")
        print("  clear  - æ¸…ç†ç¼“å­˜")
        print("  verify - éªŒè¯ç¼“å­˜å®Œæ•´æ€§")
        print("\nç¤ºä¾‹:")
        print("  automl cache stats")
        print("  automl cache clear")
        print("  automl cache clear 30  # æ¸…ç†30å¤©å‰çš„ç¼“å­˜")
        print("  automl cache verify")
        return 1


def project_command(args: List[str]):
    """
    é¡¹ç›®ç®¡ç†å‘½ä»¤
    
    ä½¿ç”¨ç¤ºä¾‹:
        automl project list                        # åˆ—å‡ºæ‰€æœ‰é¡¹ç›®
        automl project info project=test           # é¡¹ç›®è¯¦æƒ…
        automl project predict project=test data=test.csv mode=best  # æ‰¹é‡é¢„æµ‹
        automl project export project=test format=zip  # å¯¼å‡ºé¡¹ç›®
    """
    if not args:
        print("ğŸ“¦ é¡¹ç›®ç®¡ç†å‘½ä»¤")
        print("\nå­å‘½ä»¤:")
        print("  list    - åˆ—å‡ºæ‰€æœ‰é¡¹ç›®")
        print("  info    - æ˜¾ç¤ºé¡¹ç›®ä¿¡æ¯")
        print("  predict - ä½¿ç”¨é¡¹ç›®æ¨¡å‹è¿›è¡Œæ‰¹é‡é¢„æµ‹")
        print("  export  - å¯¼å‡ºé¡¹ç›®")
        print("  report  - ç”Ÿæˆé¡¹ç›®æŠ¥å‘Š")
        print("\nç¤ºä¾‹:")
        print("  automl project list")
        print("  automl project info project=TestPaperComparison")
        print("  automl project predict project=test data=test.csv mode=best")
        print("  automl project export project=test format=zip")
        return 0
    
    subcommand = args[0].lower()
    params = MLArgumentParser.parse_args_string(' '.join(args[1:]))
    
    # å¯¼å…¥é¡¹ç›®ç®¡ç†å™¨
    from utils.project_manager import ProjectManager
    from utils.project_predictor import ProjectPredictor
    
    manager = ProjectManager()
    
    if subcommand == 'list':
        # åˆ—å‡ºæ‰€æœ‰é¡¹ç›®
        projects = manager.list_projects()
        if projects:
            print("\nğŸ“ é¡¹ç›®åˆ—è¡¨:")
            for p in projects:
                print(f"\n  ğŸ“¦ {p['name']}")
                print(f"     è·¯å¾„: {p['path']}")
                print(f"     åˆ›å»º: {p['created']}")
                print(f"     æ¨¡å‹: {p['models']}, è¿è¡Œ: {p['runs']}")
        else:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•é¡¹ç›®")
        return 0
    
    elif subcommand == 'info':
        # æ˜¾ç¤ºé¡¹ç›®ä¿¡æ¯
        project = params.get('project')
        if not project:
            print("âŒ è¯·æŒ‡å®šé¡¹ç›®: project=<name>")
            return 1
        
        try:
            info = manager.get_project_info(project)
            predictor = ProjectPredictor(project, verbose=False)
            
            print(f"\nğŸ“¦ é¡¹ç›®ä¿¡æ¯: {info['project_name']}")
            print(f"   åˆ›å»ºæ—¶é—´: {info.get('created_at', 'Unknown')}")
            print(f"   è·¯å¾„: {info['path']}")
            
            # æ˜¾ç¤ºæ¨¡å‹åˆ—è¡¨
            df = predictor.list_models()
            
            # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹
            if info.get('best_models'):
                print("\nğŸ† æœ€ä½³æ¨¡å‹:")
                for target, best in info['best_models'].items():
                    print(f"   {target}: {best['model']} (RÂ²={best['r2']:.4f})")
            
        except Exception as e:
            print(f"âŒ æ— æ³•è·å–é¡¹ç›®ä¿¡æ¯: {e}")
            return 1
        
        return 0
    
    elif subcommand == 'predict':
        # æ‰¹é‡é¢„æµ‹
        project = params.get('project')
        data = params.get('data')
        mode = params.get('mode', 'all')  # all, best, ensemble
        output = params.get('output')
        
        if not project:
            print("âŒ è¯·æŒ‡å®šé¡¹ç›®: project=<name>")
            return 1
        if not data:
            print("âŒ è¯·æŒ‡å®šæ•°æ®æ–‡ä»¶: data=<file>")
            return 1
        
        try:
            predictor = ProjectPredictor(project)
            
            if mode == 'all':
                predictor.predict_all_models(
                    data_path=data,
                    output_dir=output
                )
            elif mode == 'best':
                predictor.predict_best_models(
                    data_path=data,
                    output_path=output
                )
            elif mode == 'ensemble':
                method = params.get('method', 'mean')
                predictor.predict_ensemble(
                    data_path=data,
                    output_path=output,
                    method=method
                )
            else:
                print(f"âŒ æœªçŸ¥é¢„æµ‹æ¨¡å¼: {mode}")
                print("   å¯ç”¨æ¨¡å¼: all, best, ensemble")
                return 1
                
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return 1
        
        return 0
    
    elif subcommand == 'export':
        # å¯¼å‡ºé¡¹ç›®
        project = params.get('project')
        output = params.get('output')
        format = params.get('format', 'zip')
        
        if not project:
            print("âŒ è¯·æŒ‡å®šé¡¹ç›®: project=<name>")
            return 1
        
        try:
            manager.export_project(project, output, format)
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
            return 1
        
        return 0
    
    elif subcommand == 'report':
        # ç”Ÿæˆé¡¹ç›®æŠ¥å‘Š
        project = params.get('project')
        output = params.get('output')
        
        if not project:
            print("âŒ è¯·æŒ‡å®šé¡¹ç›®: project=<name>")
            return 1
        
        try:
            manager.generate_project_report(project, output)
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return 1
        
        return 0
    
    else:
        print(f"âŒ æœªçŸ¥å­å‘½ä»¤: {subcommand}")
        return 1


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("AutoML - è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ å‘½ä»¤è¡Œå·¥å…·")
        print("\nä½¿ç”¨æ–¹å¼:")
        print("  automl <command> [options]")
        print("\nå¯ç”¨å‘½ä»¤:")
        print("  train       - è®­ç»ƒæ¨¡å‹")
        print("  analyze     - åˆ†æå®éªŒç»“æœ")
        print("  predict     - æ‰§è¡Œé¢„æµ‹")
        print("  project     - é¡¹ç›®ç®¡ç†ï¼ˆæ‰¹é‡é¢„æµ‹ï¼‰")
        print("  interactive - ğŸ¯ äº¤äº’å¼ç®¡ç†ç•Œé¢")
        print("  validate    - éªŒè¯é…ç½®")
        print("  config      - ç®¡ç†é…ç½®æ¨¡æ¿")
        print("  cache       - ç®¡ç†ç‰¹å¾ç¼“å­˜")
        print("  export      - å¯¼å‡ºæ¨¡å‹")
        print("  warmup      - é¢„è®¡ç®—å¹¶å†™å…¥ç‰¹å¾ç¼“å­˜")
        print("  info        - æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯")
        print("\nç¤ºä¾‹:")
        print("  automl interactive                    # å¯åŠ¨äº¤äº’å¼ç•Œé¢")
        print("  automl train model=xgboost data=data.csv")
        print("  automl analyze dir=runs/train format=html")
        print("  automl project list")
        print("  automl project predict project=test data=test.csv mode=best")
        print("  automl config list")
        print("  automl train config=xgboost_standard")
        print("  automl predict model=model.joblib data=test.csv")
        print("\næ›´å¤šä¿¡æ¯: automl info")
        return 0
    
    command = sys.argv[1].lower()
    args = sys.argv[2:]
    
    # è·¯ç”±åˆ°å¯¹åº”å‘½ä»¤
    if command == 'train':
        return train_command(args)
    elif command == 'analyze':
        return analyze_command(args)
    elif command == 'predict':
        return predict_command(args)
    elif command == 'project':
        return project_command(args)
    elif command == 'interactive':
        # å¯åŠ¨äº¤äº’å¼ç•Œé¢
        from interactive_cli import InteractiveCLI
        cli = InteractiveCLI()
        cli.run()
        return 0
    elif command == 'validate':
        return validate_command(args)
    elif command == 'config':
        return config_command(args)
    elif command == 'cache':
        return cache_command(args)
    elif command == 'export':
        return export_command(args)
    elif command == 'warmup':
        return warmup_command(args)
    elif command == 'info':
        return info_command(args)
    else:
        print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
        print("ä½¿ç”¨ 'automl info' æŸ¥çœ‹å¸®åŠ©")
        return 1


if __name__ == "__main__":
    sys.exit(main())
