# Nature é¡¹ç›®å¿«é€ŸæŒ‡å—ï¼ˆå¤åˆ¶å³ç”¨ï¼‰

## ðŸš€ æœ€å¿«é€Ÿå¼€å§‹ï¼ˆ5åˆ†é’Ÿï¼‰

```bash
# 1. è®­ç»ƒæ¨¡åž‹ï¼ˆä½¿ç”¨å¿«é€Ÿé…ç½®ï¼‰
python automl.py train config=xgboost_quick data=../data/Database_normalized.csv project=Nature

# 2. æŸ¥çœ‹æ¨¡åž‹
ls Nature/train1/models/

# 3. é¢„æµ‹ï¼ˆè‡ªåŠ¨ä¿å­˜åˆ°å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶ï¼‰
python automl.py predict model=Nature/train1/models/*_Max_wavelength_*.joblib data=ours.csv
```

## ðŸ“‹ å®Œæ•´è®­ç»ƒå‘½ä»¤ï¼ˆç›´æŽ¥å¤åˆ¶ï¼‰

### XGBoost æ ‡å‡†è®­ç»ƒï¼ˆæŽ¨èï¼‰
```bash
python automl.py train \
    model=xgboost \
    data=../data/Database_normalized.csv \
    test_data=ours.csv \
    project=Nature \
    name=xgboost_standard \
    n_folds=10 \
    model.hyperparameters.n_estimators=500 \
    model.hyperparameters.max_depth=8 \
    model.hyperparameters.learning_rate=0.05 \
    training.save_final_model=true
```

### LightGBM æ ‡å‡†è®­ç»ƒ
```bash
python automl.py train \
    model=lightgbm \
    data=../data/Database_normalized.csv \
    test_data=ours.csv \
    project=Nature \
    name=lightgbm_standard \
    n_folds=10 \
    model.hyperparameters.n_estimators=500 \
    model.hyperparameters.num_leaves=50 \
    model.hyperparameters.learning_rate=0.05 \
    training.save_final_model=true
```

### CatBoost æ ‡å‡†è®­ç»ƒ
```bash
python automl.py train \
    model=catboost \
    data=../data/Database_normalized.csv \
    test_data=ours.csv \
    project=Nature \
    name=catboost_standard \
    n_folds=10 \
    model.hyperparameters.iterations=500 \
    model.hyperparameters.depth=8 \
    model.hyperparameters.learning_rate=0.05 \
    training.save_final_model=true
```

## ðŸŽ¯ é¢„æµ‹å‘½ä»¤ï¼ˆç›´æŽ¥å¤åˆ¶ï¼‰

### é¢„æµ‹æœ€å¤§æ³¢é•¿
```bash
python automl.py predict \
    model=Nature/train1/models/xgboost_Max_wavelength_nm_final*.joblib \
    data=ours.csv \
    output=predictions_wavelength.csv \
    output_column=Predicted_Max_wavelength
```

### é¢„æµ‹PLQY
```bash
python automl.py predict \
    model=Nature/train1/models/xgboost_PLQY_final*.joblib \
    data=ours.csv \
    output=predictions_plqy.csv \
    output_column=Predicted_PLQY
```


## ðŸ“Š ä¸€é”®æ‰¹é‡è„šæœ¬

åˆ›å»ºå¹¶è¿è¡Œä»¥ä¸‹è„šæœ¬ï¼š

```bash
cat > run_all.sh << 'EOF'
#!/bin/bash
echo "=== Nature é¡¹ç›®è‡ªåŠ¨åŒ–è„šæœ¬ ==="

# è®­ç»ƒ
echo "å¼€å§‹è®­ç»ƒ..."
python automl.py train \
    config=xgboost_standard \
    data=../data/Database_normalized.csv \
    test_data=ours.csv \
    project=Nature

# ç­‰å¾…è®­ç»ƒå®Œæˆ
echo "è®­ç»ƒå®Œæˆï¼"

# æ‰¾åˆ°æœ€æ–°çš„æ¨¡åž‹ç›®å½•
MODEL_DIR=$(ls -td Nature/train* | head -1)/models
echo "ä½¿ç”¨æ¨¡åž‹ç›®å½•: $MODEL_DIR"

# é¢„æµ‹æ³¢é•¿å’ŒPLQY
echo "é¢„æµ‹ Max_wavelength..."
python automl.py predict \
    model=$MODEL_DIR/*Max_wavelength*.joblib \
    data=ours.csv \
    output=pred_wavelength.csv

echo "é¢„æµ‹ PLQY..."
python automl.py predict \
    model=$MODEL_DIR/*PLQY*.joblib \
    data=ours.csv \
    output=pred_plqy.csv

echo "=== å®Œæˆï¼==="
echo "ç»“æžœæ–‡ä»¶ï¼š"
ls pred_*.csv
EOF

chmod +x run_all.sh
./run_all.sh
```

## ðŸ” æŸ¥çœ‹ç»“æžœ

```bash
# æŸ¥çœ‹è®­ç»ƒç»“æžœ
python automl.py analyze dir=Nature/train1 format=text

# æŸ¥çœ‹ç¼“å­˜
python automl.py cache stats

# åˆ—å‡ºæ‰€æœ‰é¢„æµ‹ç»“æžœ
ls predictions_*.csv pred_*.csv
```

## âš¡ æ€§èƒ½æç¤º

1. **ä½¿ç”¨ç¼“å­˜**ï¼šç¬¬äºŒæ¬¡é¢„æµ‹ç›¸åŒæ–‡ä»¶å¿«100å€
2. **æ‰¹é‡å¤„ç†**ï¼š`batch_size=5000` å¤„ç†å¤§æ–‡ä»¶
3. **è‡ªåŠ¨å‘½å**ï¼šä¸æŒ‡å®šoutputé¿å…è¦†ç›–

## ðŸ“ æ–‡ä»¶æ ¼å¼è¦æ±‚

è¾“å…¥CSVå¿…é¡»åŒ…å«ï¼š
- `L1` - ç¬¬ä¸€ä¸ªé…ä½“SMILES
- `L2` - ç¬¬äºŒä¸ªé…ä½“SMILES  
- `L3` - ç¬¬ä¸‰ä¸ªé…ä½“SMILES

å¯é€‰ç›®æ ‡åˆ—ï¼š
- `Max_wavelength(nm)` - æœ€å¤§æ³¢é•¿
- `PLQY` - é‡å­äº§çŽ‡

## ðŸ†˜ é—®é¢˜æŽ’æŸ¥

```bash
# æ£€æŸ¥æ–‡ä»¶
ls ../data/Database_normalized.csv
ls ours.csv

# æ£€æŸ¥æ¨¡åž‹
ls Nature/*/models/*.joblib

# æ£€æŸ¥PythonçŽ¯å¢ƒ
python -c "import rdkit, xgboost, lightgbm; print('çŽ¯å¢ƒOK')"
```